{"meta":{"title":"WizardLQ’s | 魔法师の小茶馆","subtitle":"Keep moving, never give up. | 锲而不舍，金石可镂.","description":"远不止魔法......","author":"liuqidev","url":"https://www.blankspace.cn"},"pages":[{"title":"404 Not Found","date":"2018-08-04T05:55:12.000Z","updated":"2018-08-06T07:40:12.006Z","comments":true,"path":"404.html","permalink":"https://www.blankspace.cn/404.html","excerpt":"","text":""},{"title":"categories","date":"2018-08-09T13:16:34.000Z","updated":"2018-08-09T13:16:51.810Z","comments":true,"path":"categories/index.html","permalink":"https://www.blankspace.cn/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2018-08-09T13:17:50.000Z","updated":"2018-08-09T13:17:50.369Z","comments":true,"path":"about/index.html","permalink":"https://www.blankspace.cn/about/index.html","excerpt":"","text":""},{"title":"projects","date":"2018-08-09T07:56:23.000Z","updated":"2018-08-09T07:56:51.194Z","comments":true,"path":"projects/index.html","permalink":"https://www.blankspace.cn/projects/index.html","excerpt":"","text":""}],"posts":[{"title":"MNIST pros","slug":"MNIST-pros","date":"2018-08-12T02:11:47.000Z","updated":"2018-08-12T02:16:34.195Z","comments":true,"path":"2018/08/12/MNIST-pros/","link":"","permalink":"https://www.blankspace.cn/2018/08/12/MNIST-pros/","excerpt":"运行TensorFlow的InteractiveSession/交互式会话sess = tf.InteractiveSession()用来创建交互式的会话，其余使用同Session 12import numpy as npimport tensorflow as tf D:\\Anaconda3\\Anaconda3_py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters 准备工作和上一节类似 1234567# http://yann.lecun.com/exdb/mnist/ to download mnist dataset# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/input_data.py# to read datasetfrom load_mnist import *import tensorflow.examples.tutorials.mnist.input_data as input_dataminst_dir = \"MNIST_data/\"mnist = input_data.read_data_sets(minst_dir, one_hot=True) 12x = tf.placeholder(\"float\", shape=[None, 784]) y_ = tf.placeholder(\"float\", shape=[None, 10]) # true label 构建一个多层卷积网络权重初始化12345678def weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) # The generated values follow a normal distribution with specified mean and # standard deviation.从截断的正态分布中输出随机值，中如果x的取值在区间（μ-2σ，μ+2σ）之外则重新进行选择 return tf.Variable(initial)def bias_variable(shape): initial = tf.constant(0.1, shape=shape) # Constant 2-D tensor populated with scalar value 0.1. 初始值为0.1，广播到shape形状的二维数组 return tf.Variable(initial) 卷积和汇聚（池化）由于Pooling翻译成池化让人不明所以，个人习惯依据其作用，而称之为汇聚。 简单起见，卷积使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。我们的池化用简单传统的2x2大小的模板做max pooling. 12345def conv2d(x, W): return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')def max_pool_2x2(x): return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')","text":"运行TensorFlow的InteractiveSession/交互式会话sess = tf.InteractiveSession()用来创建交互式的会话，其余使用同Session 12import numpy as npimport tensorflow as tf D:\\Anaconda3\\Anaconda3_py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters 准备工作和上一节类似 1234567# http://yann.lecun.com/exdb/mnist/ to download mnist dataset# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/input_data.py# to read datasetfrom load_mnist import *import tensorflow.examples.tutorials.mnist.input_data as input_dataminst_dir = \"MNIST_data/\"mnist = input_data.read_data_sets(minst_dir, one_hot=True) 12x = tf.placeholder(\"float\", shape=[None, 784]) y_ = tf.placeholder(\"float\", shape=[None, 10]) # true label 构建一个多层卷积网络权重初始化12345678def weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) # The generated values follow a normal distribution with specified mean and # standard deviation.从截断的正态分布中输出随机值，中如果x的取值在区间（μ-2σ，μ+2σ）之外则重新进行选择 return tf.Variable(initial)def bias_variable(shape): initial = tf.constant(0.1, shape=shape) # Constant 2-D tensor populated with scalar value 0.1. 初始值为0.1，广播到shape形状的二维数组 return tf.Variable(initial) 卷积和汇聚（池化）由于Pooling翻译成池化让人不明所以，个人习惯依据其作用，而称之为汇聚。 简单起见，卷积使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。我们的池化用简单传统的2x2大小的模板做max pooling. 12345def conv2d(x, W): return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')def max_pool_2x2(x): return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') 第一层卷积它由一个卷积接一个max pooling完成。卷积在每个5x5的patch中算出32个特征。卷积的权重张量形状是[5, 5, 1, 32]，前两个维度是patch的大小，接着是输入的通道数目，最后是输出的通道数目。 而对于每一个输出通道都有一个对应的偏置量。 12345678910W_conv1 = weight_variable([5, 5, 1, 32])b_conv1 = bias_variable([32])# convert x to 4d vectorx_image = tf.reshape(x, [-1, 28,28, 1])# num x height x width x channel# We then convolve x_image with the weight tensor, add the bias, apply the ReLU function, and finally max pool. # 我们把x_image和权值向量进行卷积，加上偏置项，然后应用ReLU激活函数，最后进行max pooling。h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1)+b_conv1)h_pool1 = max_pool_2x2(h_conv1) 第二层卷积为了构建一个更深的网络，我们会把几个类似的层堆叠起来。第二层中，每个5x5的patch会得到64个特征。 12345W_conv2 = weight_variable([5, 5, 32, 64])b_conv2 = bias_variable([64])h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2)+b_conv2)h_pool2 = max_pool_2x2(h_conv2) 密集连接（全连接）层经过两层卷积（激活）汇聚组合拳，原本的28x28的图像，特征图的尺寸减小到7x7（主要得益于汇聚）。并且一张图片有64个特征图（得益于卷积）。引入一个有1024个神经元的全连接层，来处理整个图片。 12345W_fc1 = weight_variable([7*7*64, 1024])b_fc1 = bias_variable([1024])h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1)+b_fc1) Dropout好像还没有官方中文翻译，那就叫它断电吧。使用TensorFlow构建计算图和使用vhdl构建电路有很多相似之处 减少过拟合。用一个placeholder来代表一个神经元的输出在dropout中保持不变的概率。这样我们可以在训练过程中启用dropout，在测试过程中关闭dropout。 TensorFlow的tf.nn.dropout操作除了可以屏蔽神经元的输出外，还会自动处理神经元输出值的scale。所以用dropout的时候可以不用考虑scale。 12keep_prob = tf.placeholder(\"float\")h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) 输出层最后添加一个softmax层，如同前一节的softmax回归一样。 1234W_fc2 = weight_variable([1024, 10])b_fc2 = bias_variable([10])y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2)+b_fc2) # 输出层不需要激活函数 训练和评估我们会用更加复杂的ADAM优化器来做梯度最速下降，在feed_dict中加入额外的参数keep_prob来控制dropout比例。然后每100次迭代输出一次日志。 1import time 12345678910111213141516171819202122232425cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy) # 优化器只是按照规则（参数更新算法）来更新参数的correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) # acc ratesess = tf.InteractiveSession()sess.run(tf.global_variables_initializer())print('Training...')start_t = time.clock()for step in range(20001): batch = mnist.train.next_batch(50) if step%100==0: train_accuracy = accuracy.eval(feed_dict=&#123;x:batch[0], y_:batch[1], keep_prob:1.0&#125;) print(\"Step %d, training accuracy %f\"%(step, train_accuracy)) train_step.run(feed_dict=&#123;x:batch[0], y_:batch[1], keep_prob:0.5&#125;)end_t = time.clock()print(\"Train Time Cost: \", end_t-start_t)print('Testing...')print(\"Test accuracy %f\"%accuracy.eval(feed_dict=&#123;x:mnist.test.images, y_:mnist.test.labels, keep_prob:1.0&#125;))sess.close() Training... Step 0, training accuracy 0.120000 Step 100, training accuracy 0.780000 Step 200, training accuracy 0.860000 Step 300, training accuracy 0.860000 Step 400, training accuracy 0.980000 Step 500, training accuracy 0.860000 Step 600, training accuracy 0.940000 Step 700, training accuracy 0.940000 Step 800, training accuracy 0.960000 Step 900, training accuracy 0.940000 Step 1000, training accuracy 0.960000 Step 1100, training accuracy 1.000000 Step 1200, training accuracy 0.960000 Step 1300, training accuracy 0.980000 Step 1400, training accuracy 1.000000 Step 1500, training accuracy 0.960000 Step 1600, training accuracy 0.940000 Step 1700, training accuracy 0.940000 Step 1800, training accuracy 0.940000 Step 1900, training accuracy 0.980000 Step 2000, training accuracy 0.980000 Step 2100, training accuracy 0.960000 Step 2200, training accuracy 0.940000 Step 2300, training accuracy 0.980000 Step 2400, training accuracy 0.980000 Step 2500, training accuracy 0.960000 Step 2600, training accuracy 1.000000 Step 2700, training accuracy 1.000000 Step 2800, training accuracy 0.980000 Step 2900, training accuracy 1.000000 Step 3000, training accuracy 0.980000 Step 3100, training accuracy 1.000000 Step 3200, training accuracy 0.980000 Step 3300, training accuracy 1.000000 Step 3400, training accuracy 1.000000 Step 3500, training accuracy 0.960000 Step 3600, training accuracy 1.000000 Step 3700, training accuracy 0.980000 Step 3800, training accuracy 1.000000 Step 3900, training accuracy 0.980000 Step 4000, training accuracy 0.980000 Step 4100, training accuracy 1.000000 Step 4200, training accuracy 0.980000 Step 4300, training accuracy 0.960000 Step 4400, training accuracy 1.000000 Step 4500, training accuracy 1.000000 Step 4600, training accuracy 1.000000 Step 4700, training accuracy 1.000000 Step 4800, training accuracy 1.000000 Step 4900, training accuracy 0.980000 Step 5000, training accuracy 0.980000 Step 5100, training accuracy 0.980000 Step 5200, training accuracy 1.000000 Step 5300, training accuracy 1.000000 Step 5400, training accuracy 1.000000 Step 5500, training accuracy 1.000000 Step 5600, training accuracy 1.000000 Step 5700, training accuracy 0.980000 Step 5800, training accuracy 1.000000 Step 5900, training accuracy 0.980000 Step 6000, training accuracy 0.980000 Step 6100, training accuracy 0.980000 Step 6200, training accuracy 1.000000 Step 6300, training accuracy 0.980000 Step 6400, training accuracy 0.980000 Step 6500, training accuracy 1.000000 Step 6600, training accuracy 0.980000 Step 6700, training accuracy 1.000000 Step 6800, training accuracy 1.000000 Step 6900, training accuracy 1.000000 Step 7000, training accuracy 1.000000 Step 7100, training accuracy 0.980000 Step 7200, training accuracy 1.000000 Step 7300, training accuracy 1.000000 Step 7400, training accuracy 0.980000 Step 7500, training accuracy 1.000000 Step 7600, training accuracy 0.980000 Step 7700, training accuracy 0.980000 Step 7800, training accuracy 1.000000 Step 7900, training accuracy 0.980000 Step 8000, training accuracy 1.000000 Step 8100, training accuracy 1.000000 Step 8200, training accuracy 0.980000 Step 8300, training accuracy 0.980000 Step 8400, training accuracy 1.000000 Step 8500, training accuracy 0.980000 Step 8600, training accuracy 1.000000 Step 8700, training accuracy 0.980000 Step 8800, training accuracy 0.980000 Step 8900, training accuracy 1.000000 Step 9000, training accuracy 1.000000 Step 9100, training accuracy 1.000000 Step 9200, training accuracy 1.000000 Step 9300, training accuracy 0.980000 Step 9400, training accuracy 1.000000 Step 9500, training accuracy 0.960000 Step 9600, training accuracy 0.980000 Step 9700, training accuracy 1.000000 Step 9800, training accuracy 1.000000 Step 9900, training accuracy 1.000000 Step 10000, training accuracy 1.000000 Step 10100, training accuracy 1.000000 Step 10200, training accuracy 1.000000 Step 10300, training accuracy 1.000000 Step 10400, training accuracy 1.000000 Step 10500, training accuracy 1.000000 Step 10600, training accuracy 1.000000 Step 10700, training accuracy 1.000000 Step 10800, training accuracy 0.980000 Step 10900, training accuracy 1.000000 Step 11000, training accuracy 1.000000 Step 11100, training accuracy 1.000000 Step 11200, training accuracy 0.980000 Step 11300, training accuracy 1.000000 Step 11400, training accuracy 1.000000 Step 11500, training accuracy 0.980000 Step 11600, training accuracy 0.980000 Step 11700, training accuracy 0.960000 Step 11800, training accuracy 1.000000 Step 11900, training accuracy 1.000000 Step 12000, training accuracy 0.980000 Step 12100, training accuracy 1.000000 Step 12200, training accuracy 0.980000 Step 12300, training accuracy 1.000000 Step 12400, training accuracy 1.000000 Step 12500, training accuracy 1.000000 Step 12600, training accuracy 1.000000 Step 12700, training accuracy 1.000000 Step 12800, training accuracy 1.000000 Step 12900, training accuracy 1.000000 Step 13000, training accuracy 1.000000 Step 13100, training accuracy 1.000000 Step 13200, training accuracy 1.000000 Step 13300, training accuracy 1.000000 Step 13400, training accuracy 1.000000 Step 13500, training accuracy 1.000000 Step 13600, training accuracy 1.000000 Step 13700, training accuracy 1.000000 Step 13800, training accuracy 1.000000 Step 13900, training accuracy 1.000000 Step 14000, training accuracy 1.000000 Step 14100, training accuracy 1.000000 Step 14200, training accuracy 1.000000 Step 14300, training accuracy 1.000000 Step 14400, training accuracy 1.000000 Step 14500, training accuracy 1.000000 Step 14600, training accuracy 0.980000 Step 14700, training accuracy 1.000000 Step 14800, training accuracy 1.000000 Step 14900, training accuracy 1.000000 Step 15000, training accuracy 0.980000 Step 15100, training accuracy 1.000000 Step 15200, training accuracy 1.000000 Step 15300, training accuracy 1.000000 Step 15400, training accuracy 1.000000 Step 15500, training accuracy 1.000000 Step 15600, training accuracy 1.000000 Step 15700, training accuracy 1.000000 Step 15800, training accuracy 1.000000 Step 15900, training accuracy 1.000000 Step 16000, training accuracy 1.000000 Step 16100, training accuracy 1.000000 Step 16200, training accuracy 1.000000 Step 16300, training accuracy 1.000000 Step 16400, training accuracy 1.000000 Step 16500, training accuracy 1.000000 Step 16600, training accuracy 1.000000 Step 16700, training accuracy 0.960000 Step 16800, training accuracy 1.000000 Step 16900, training accuracy 1.000000 Step 17000, training accuracy 1.000000 Step 17100, training accuracy 1.000000 Step 17200, training accuracy 0.980000 Step 17300, training accuracy 1.000000 Step 17400, training accuracy 1.000000 Step 17500, training accuracy 1.000000 Step 17600, training accuracy 1.000000 Step 17700, training accuracy 1.000000 Step 17800, training accuracy 1.000000 Step 17900, training accuracy 1.000000 Step 18000, training accuracy 1.000000 Step 18100, training accuracy 1.000000 Step 18200, training accuracy 1.000000 Step 18300, training accuracy 1.000000 Step 18400, training accuracy 1.000000 Step 18500, training accuracy 1.000000 Step 18600, training accuracy 1.000000 Step 18700, training accuracy 1.000000 Step 18800, training accuracy 1.000000 Step 18900, training accuracy 1.000000 Step 19000, training accuracy 1.000000 Step 19100, training accuracy 1.000000 Step 19200, training accuracy 1.000000 Step 19300, training accuracy 1.000000 Step 19400, training accuracy 1.000000 Step 19500, training accuracy 1.000000 Step 19600, training accuracy 1.000000 Step 19700, training accuracy 1.000000 Step 19800, training accuracy 1.000000 Step 19900, training accuracy 0.980000 Step 20000, training accuracy 1.000000 Train Time Cost: 205.04848637568546 Testing... Test accuracy 0.992300 总结本节对mnist数据集，使用TensorFlow构建了卷积池化API，并构建了两层卷积池化层，一层全连接层的神经网络，使用dropout来减少过拟合，最后输出到softmax回归层，从而构建了完整的卷积神经网络模型。优化器使用Adam，经过2万次迭代的训练，在测试集上精确度达到了(99%).","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://www.blankspace.cn/categories/Machine-Learning/"},{"name":"TensorFlow","slug":"Machine-Learning/TensorFlow","permalink":"https://www.blankspace.cn/categories/Machine-Learning/TensorFlow/"}],"tags":[{"name":"mnist","slug":"mnist","permalink":"https://www.blankspace.cn/tags/mnist/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://www.blankspace.cn/tags/TensorFlow/"}]},{"title":"TensorFlow tutorial mnist beginners","slug":"TensorFlow-tutorial-mnist-beginners","date":"2018-08-11T09:25:06.000Z","updated":"2018-08-12T02:12:56.707Z","comments":true,"path":"2018/08/11/TensorFlow-tutorial-mnist-beginners/","link":"","permalink":"https://www.blankspace.cn/2018/08/11/TensorFlow-tutorial-mnist-beginners/","excerpt":"","text":"从示例开始导入12import tensorflow as tfimport numpy as np # 和tf配合使用 D:\\Anaconda3\\Anaconda3_py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters 构造线性模型12345678910111213141516# generate phony data | 生成假数据# 实际应用应该是面对真实的数据# 100个点，（2x100）x_data = np.float32(np.random.rand(2, 100))y_data = np.dot([0.100, 0.200], x_data)+0.300# 构造线性模型b = tf.Variable(tf.zeros([1])) # tensor of shape 1W = tf.Variable(tf.random_uniform([1, 2], minval=-0.1, maxval=1.0)) # tensor of shape 1x2 whose values are from a uniform distribution # in the range of [minval, maxval)y = tf.matmul(W, x_data)+b# 最小化方差loss = tf.reduce_mean(tf.square(y-y_data))optimizer = tf.train.GradientDescentOptimizer(0.5)train = optimizer.minimize(loss) 123# 初始化变量# init = tf.initialize_all_variables()init = tf.global_variables_initializer() 123# 启动计算图(graph)sess = tf.Session() # 创建会话sess.run(init) 12345# 拟合平面for step in range(0, 201): sess.run(train) if step%20==0: print(\"Step: \", step, \" W= \",sess.run(W), \" b= \", sess.run(b)) Step: 0 W= [[0.4871506 0.41139394]] b= [-0.09778017] Step: 20 W= [[0.22539519 0.34252512]] b= [0.15573283] Step: 40 W= [[0.14763923 0.26675704]] b= [0.23892412] Step: 60 W= [[0.11975352 0.22945689]] b= [0.2737922] Step: 80 W= [[0.10842387 0.21279107]] b= [0.2887098] Step: 100 W= [[0.10362242 0.20552918]] b= [0.2951307] Step: 120 W= [[0.10156146 0.20238699]] b= [0.29789925] Step: 140 W= [[0.10067356 0.2010301 ]] b= [0.2990936] Step: 160 W= [[0.10029061 0.20044449]] b= [0.29960892] Step: 180 W= [[0.10012538 0.20019177]] b= [0.29983127] Step: 200 W= [[0.10005409 0.20008272]] b= [0.2999272] 12# 关闭会话sess.close() MNIST机器学习入门1234# http://yann.lecun.com/exdb/mnist/ to download mnist dataset# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/input_data.py# to read datasetfrom load_mnist import * 123import tensorflow.examples.tutorials.mnist.input_data as input_dataminst_dir = \"MNIST_data/\"mnist = input_data.read_data_sets(minst_dir, one_hot=True) Extracting MNIST_data/train-images-idx3-ubyte.gz Extracting MNIST_data/train-labels-idx1-ubyte.gz Extracting MNIST_data/t10k-images-idx3-ubyte.gz Extracting MNIST_data/t10k-labels-idx1-ubyte.gz WARNING:tensorflow:From D:\\Anaconda3\\Anaconda3_py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version. Instructions for updating: Please use alternatives such as official/mnist/dataset.py from tensorflow/models. 下载下来的数据集被分成两部分：60000行的训练数据集（mnist.train）和10000行的测试数据集（mnist.test）. 每一个MNIST数据单元有两部分组成：一张包含手写数字的图片和一个对应的标签。我们把这些图片设为“xs”，把这些标签设为“ys”。训练数据集和测试数据集都包含xs和ys，比如训练数据集的图片是 mnist.train.images ，训练数据集的标签是 mnist.train.labels. 每一张图片包含28像素X28像素。我们可以用一个数字数组来表示这张图片： 我们把这个数组展开成一个向量，长度是 28x28 = 784。如何展开这个数组（数字间的顺序）不重要，只要保持各个图片采用相同的方式展开。从这个角度来看，MNIST数据集的图片就是在784维向量空间里面的点, 并且拥有比较复杂的结构 (提醒: 此类数据的可视化是计算密集型的)。 在MNIST训练数据集中，mnist.train.images 是一个形状为 [60000, 784]的张量，第一个维度数字用来索引图片，第二个维度数字用来索引每张图片中的像素点。在此张量里的每一个元素，都表示某张图片里的某个像素的强度值，值介于0和1之间。 相对应的MNIST数据集的标签是介于0到9的数字，用来描述给定图片里表示的数字。为了用于这个教程，我们使标签数据是”one-hot vectors”。 一个one-hot向量除了某一位的数字是1以外其余各维度数字都是0。所以在此教程中，数字n将表示成一个只有在第n维度（从0开始）数字为1的10维向量。比如，标签0将表示成([1,0,0,0,0,0,0,0,0,0,0])。因此， mnist.train.labels 是一个[60000, 10]的数字矩阵。 1234567# x represent the input# None means number of images is adaptable# a 28x28 image is flatten to a vector of 784x = tf.placeholder(\"float\", [None, 784])W = tf.Variable(tf.zeros([784, 10]))b = tf.Variable(tf.zeros([10])) Softmax regression关于Softmax可以阅读这篇或者这篇. 整个回归模型： 12# softmaxy = tf.nn.softmax(tf.matmul(x, W)+b) 训练模型使用交叉熵损失函数，更多介绍看这篇. 1234y_ = tf.placeholder(\"float\", [None, 10])# 注意，这里的交叉熵不仅仅用来衡量单一的一对预测和真实值，而是所有100幅图片的交叉熵的总和cross_entropy = -tf.reduce_sum(y_*tf.log(y)) 12# gradient descent and backprapagationtrain_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy) 更多优化算法点击这里. 12# init graphinit = tf.global_variables_initializer() 123456with tf.Session() as sess: sess.run(init) for step in range(1001): batch_xs, batch_ys = mnist.train.next_batch(100) feed_dict =&#123;x: batch_xs, y_:batch_ys&#125; sess.run(train_step, feed_dict) 评估我们的模型tf.argmax 是一个非常有用的函数，它能给出某个tensor对象在某一维上的其数据最大值所在的索引值。由于标签向量是由0,1组成，因此最大值1所在的索引位置就是类别标签，比如tf.argmax(y,1)返回的是模型对于任一输入x预测到的标签值，而 tf.argmax(y_,1) 代表正确的标签，我们可以用 tf.equal 来检测我们的预测是否真实标签匹配(索引位置一样表示匹配)。 12345678910with tf.Session() as sess: sess.run(init) for step in range(1001): batch_xs, batch_ys = mnist.train.next_batch(100) feed_dict =&#123;x: batch_xs, y_:batch_ys&#125; sess.run(train_step, feed_dict) if step%100==0: correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) print(step, \" train acc: \", sess.run(accuracy, feed_dict)) 0 train acc: 0.48 100 train acc: 0.94 200 train acc: 0.96 300 train acc: 0.93 400 train acc: 0.93 500 train acc: 0.89 600 train acc: 0.96 700 train acc: 0.94 800 train acc: 0.94 900 train acc: 0.95 1000 train acc: 0.98 1234567891011121314with tf.Session() as sess: sess.run(init) for step in range(1001): batch_xs, batch_ys = mnist.train.next_batch(100) feed_dict =&#123;x: batch_xs, y_:batch_ys&#125; sess.run(train_step, feed_dict)# if step%100==0:# correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))# accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))# print(step, \" train acc: \", sess.run(accuracy, feed_dict))# # for test set correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) print(\"Test acc:\", sess.run(accuracy, feed_dict=&#123;x:mnist.test.images, y_:mnist.test.labels&#125;)) Test acc: 0.9138 更多内容https://www.tensorflow.org/tutorials/ 总结本文首先通过一个完整的线性回归的例子，展示了TensorFlow的基本使用，首先构造计算图graph，其中包含诸如Variable、placeholder等节点，以及节点之间的数学运算如矩阵乘法；接着对计算图初始化，tf.global_variables_initializer()，其中TensorFlow中很重要的就是回话session机制，通过会话来运行计算图；随后，通过会话进行训练，拟合并德大检测结果。 其次，使用TensorFlow完成了基于MNIST数据集，进行手写体识别的任务，并在测试集上实现了91%的正确率。其完整过程，首先是准备数据，下载的数据被分为训练数据和测试数据。每种数据的基本单元都包含两部分，一部分是手写体图片，统一规格28x28，另一部分是对应的标记，来指出对应的数字，将原始图片展开向量表示，标记采用one-hot表示；接着，构建softmax回归模型。使用梯度下降算法进行反向传播，最小化交叉熵损失进行训练。最后，在测试机上测试，得到实验正确率指标，可以达到91%以上。","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://www.blankspace.cn/categories/Machine-Learning/"},{"name":"TensorFlow","slug":"Machine-Learning/TensorFlow","permalink":"https://www.blankspace.cn/categories/Machine-Learning/TensorFlow/"}],"tags":[{"name":"mnist","slug":"mnist","permalink":"https://www.blankspace.cn/tags/mnist/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://www.blankspace.cn/tags/TensorFlow/"}]},{"title":"Code Highlight","slug":"code-hightlight","date":"2018-08-11T04:30:03.000Z","updated":"2018-08-11T06:04:04.219Z","comments":true,"path":"2018/08/11/code-hightlight/","link":"","permalink":"https://www.blankspace.cn/2018/08/11/code-hightlight/","excerpt":"","text":"123456789101112131415161718192021/* * This is some sample code to illustrate how things look! */import Musician from './liverpool';class Paul extends Musician &#123; constructor(bass) &#123; super(bass); &#125; get fullName() &#123; return 'Paul McCartney'; &#125; perform() &#123; this.play(this.instrument); this.sing(); &#125;&#125;export default Paul;","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.blankspace.cn/tags/Hexo/"},{"name":"Code","slug":"Code","permalink":"https://www.blankspace.cn/tags/Code/"}]},{"title":"Numpy随机数1","slug":"Numpy随机数","date":"2018-08-11T02:45:00.000Z","updated":"2018-08-11T11:37:44.854Z","comments":true,"path":"2018/08/11/Numpy随机数/","link":"","permalink":"https://www.blankspace.cn/2018/08/11/Numpy随机数/","excerpt":"","text":"更多内容查看这里 Simple random data | 常用随机函数1import numpy as np 123# rand(d0, d1, …, dn)# random values in a given shapenp.random.rand(1) array([0.15771123]) 1np.random.rand(3, 4) array([[0.17303082, 0.13546342, 0.96790769, 0.54289967], [0.47752797, 0.3163813 , 0.33804729, 0.63760302], 更多内容查看这里 Simple random data | 常用随机函数1import numpy as np rand(d0, d1, …, dn)123# rand(d0, d1, …, dn)# random values in a given shapenp.random.rand(1) array([0.97299322]) 1np.random.rand(3, 4) array([[0.81969546, 0.63076449, 0.70050141, 0.28701361], [0.5909755 , 0.10265285, 0.03841936, 0.04747027], [0.50586629, 0.33692611, 0.18006999, 0.37508064]]) 1np.random.rand(5) array([0.4027442 , 0.29275407, 0.15175853, 0.76296697, 0.84970737]) 正态分布随机数 randn(d0, d1, …, dn)123# randn(d0, d1, …, dn)# return a sample or samples from standard norma sidtributionnp.random.randn(1) array([0.68010349]) 1np.random.randn(4) array([-0.22561174, -0.12611506, 1.42778485, 0.69267162]) 1np.random.randn(2, 2) array([[ 1.09486998, -0.12217683], [-0.26184258, 0.70775913]]) Note: We can use matplotlib to show the distrubution 随机整数randint(low[, high, size, dtype]) / np.random.random_integers(2) 123# randint(low[, high, size, dtype])# return random integers from low(inclusive) to high(exclusive)np.random.randint(1) 0 1np.random.randint(3) 2 1np.random.randint(100, 1000) 945 1np.random.randint(0, 100, 5) array([76, 86, 29, 40, 76]) 1np.random.randint(0, 100, (3, 3)) array([[88, 50, 90], [64, 69, 57], [ 2, 10, 95]]) 12345# random_integers(low[, high, size])# random integers of type np.int between low and high, inclusivenp.random.random_integers(2)# This function is deprecated. Please call randint(l, r + 1) instead D:\\Anaconda3\\Anaconda3_py36\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: This function is deprecated. Please call randint(1, 2 + 1) instead This is separate from the ipykernel package so we can avoid doing imports until 1 随机小数 random_sample([size]) random([size]) ranf([size]) sample([size]) 123# random_sample([size])# return random floats in the half-open interval[0.0, 1.0)np.random.random_sample(1) array([0.42922028]) 1np.random.random_sample((3,3)) array([[0.13911191, 0.29153576, 0.38330187], [0.39095818, 0.37114282, 0.69224038], [0.3664121 , 0.02533538, 0.76235701]]) 123# random([size])# return random floats in the half-open interval[0.0, 1.0)np.random.random(1) array([0.57758511]) 1np.random.random((2, 2)) array([[0.89365816, 0.10505705], [0.76704421, 0.27889437]]) 123# ranf([size])# return random floats int the half-open interval [0.0, 1.0)np.random.ranf(1) array([0.64518204]) 1np.random.ranf((3,4)) array([[0.10753966, 0.70902024, 0.63834775, 0.65623879], [0.71709776, 0.34437971, 0.42639926, 0.70715686], [0.12977266, 0.20338805, 0.94316098, 0.3082274 ]]) 123# sample([size])# return random floats int the half-open interval [0.0, 1.0)np.random.sample(2) array([0.95896772, 0.64870791]) 1np.random.sample((2, 2)) array([[0.91634732, 0.95899658], [0.59189998, 0.53045256]]) 自定义随机 choice(a[, size, replace, p]) 123# choice(a[, size, replace, p])# generate a random sample from a given 1-D arraynp.random.choice([3, 2, 1, 0],3) array([3, 1, 3]) 1np.random.choice([3, 2, 1, 0],3, replace=False) array([1, 2, 3]) 1np.random.choice([\"cat\", \"dog\", \"fish\", \"mouse\", \"bird\"],(2, 2), replace=True) array([[&#39;cat&#39;, &#39;dog&#39;], [&#39;bird&#39;, &#39;dog&#39;]], dtype=&#39;&lt;U5&#39;) 1234# p represents properties of the elements of the 1-D array# sum of p must be 1.0np.random.choice([\"cat\", \"dog\", \"fish\", \"mouse\", \"bird\"],(2, 2), replace=True, p=[0.1, 0.5, 0.3, 0.05, 0.05]) array([[&#39;fish&#39;, &#39;dog&#39;], [&#39;dog&#39;, &#39;fish&#39;]], dtype=&#39;&lt;U5&#39;) 123# bytes(length)# return random bytesnp.random.bytes(1) b&#39;\\x8c&#39; Permutations | 排列 shuffle(x) permutation(x) 123456789# shuffle(x)# modify a sequence in-place by shuffling its contents# 将序列在原地打乱x = np.arange(11)print('----befor shuffle x----')print(x)print('----after shuffle x----')np.random.shuffle(x)print(x) ----befor shuffle x---- [ 0 1 2 3 4 5 6 7 8 9 10] ----after shuffle x---- [ 8 1 5 4 0 2 3 9 7 6 10] 1234567# permutation(x)# randomly permute a sequence, or return a permuted rangex = np.arange(11)print(\"---permutation----\")print(np.random.permutation(x))print(\"---x----\")print(x) ---permutation---- [ 9 4 6 0 5 10 8 3 7 2 1] ---x---- [ 0 1 2 3 4 5 6 7 8 9 10] Random generator | 随机数生成器如果设置了seed，每次重新运行时生成的随机数都是确定和上次相同的。 1234# RandomState([seed])# container for the Mersenne Twister pseudo-random number generatornp.random.RandomState(1)np.random.random(5) array([0.58048047, 0.57948883, 0.82388234, 0.77501925, 0.70183176]) 1234# seed([seed])# seed the generatornp.random.seed(0)np.random.random(5) array([0.5488135 , 0.71518937, 0.60276338, 0.54488318, 0.4236548 ]) 123456# get_state()# return a tuple representing the internal state of the generator # np.random.get_state()# set_state(state)# set the interna state of the generator from a tuple","categories":[{"name":"Languages","slug":"Languages","permalink":"https://www.blankspace.cn/categories/Languages/"},{"name":"Python","slug":"Languages/Python","permalink":"https://www.blankspace.cn/categories/Languages/Python/"},{"name":"Numpy","slug":"Languages/Python/Numpy","permalink":"https://www.blankspace.cn/categories/Languages/Python/Numpy/"}],"tags":[{"name":"Numpy","slug":"Numpy","permalink":"https://www.blankspace.cn/tags/Numpy/"},{"name":"random","slug":"random","permalink":"https://www.blankspace.cn/tags/random/"}]},{"title":"Emoji","slug":"emoji-text","date":"2018-08-10T12:20:02.000Z","updated":"2018-08-11T06:04:25.620Z","comments":true,"path":"2018/08/10/emoji-text/","link":"","permalink":"https://www.blankspace.cn/2018/08/10/emoji-text/","excerpt":"","text":"Input emoji with syntax :smile:. Sad, it is failed. 😂😁 Use inputs(eg. MS default input) which can input emoji directly, this is the easiest way. Here to know more.","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.blankspace.cn/tags/Hexo/"},{"name":"Emoji","slug":"Emoji","permalink":"https://www.blankspace.cn/tags/Emoji/"}]},{"title":"Mathjax","slug":"mathjax-test","date":"2018-08-10T11:53:22.000Z","updated":"2018-08-10T12:41:46.743Z","comments":true,"path":"2018/08/10/mathjax-test/","link":"","permalink":"https://www.blankspace.cn/2018/08/10/mathjax-test/","excerpt":"","text":"This post is used for testing mathjax(latex) support. Inline mathUse $...$, example: 1$\\lim_&#123;x \\to \\infty&#125; \\exp(-x) = 0$ Writing LaTex like: \\lim_{x \\to \\infty} \\exp(-x) = 0 Displayed formulasUse $$...$$ , example: 1$$\\sum_&#123;i=0&#125;^n i^2 = \\frac&#123;(n^2+n)(2n+1)&#125;&#123;6&#125;$$ \\sum_{i=0}^n i^2 = \\frac{(n^2+n)(2n+1)}{6}1234567$$ \\begin&#123;matrix&#125; 1 &amp; x &amp; x^2 \\\\ 1 &amp; y &amp; y^2 \\\\ 1 &amp; z &amp; z^2 \\\\ \\end&#123;matrix&#125;$$ \\begin{matrix} 1 & x & x^2 \\\\ 1 & y & y^2 \\\\ 1 & z & z^2 \\\\ \\end{matrix}1234567\\begin&#123;align&#125;\\sqrt&#123;37&#125; &amp; = \\sqrt&#123;\\frac&#123;73^2-1&#125;&#123;12^2&#125;&#125; \\\\ &amp; = \\sqrt&#123;\\frac&#123;73^2&#125;&#123;12^2&#125;\\cdot\\frac&#123;73^2-1&#125;&#123;73^2&#125;&#125; \\\\ &amp; = \\sqrt&#123;\\frac&#123;73^2&#125;&#123;12^2&#125;&#125;\\sqrt&#123;\\frac&#123;73^2-1&#125;&#123;73^2&#125;&#125; \\\\ &amp; = \\frac&#123;73&#125;&#123;12&#125;\\sqrt&#123;1 - \\frac&#123;1&#125;&#123;73^2&#125;&#125; \\\\ &amp; \\approx \\frac&#123;73&#125;&#123;12&#125;\\left(1 - \\frac&#123;1&#125;&#123;2\\cdot73^2&#125;\\right)\\end&#123;align&#125; \\begin{align} \\sqrt{37} & = \\sqrt{\\frac{73^2-1}{12^2}} \\\\ & = \\sqrt{\\frac{73^2}{12^2}\\cdot\\frac{73^2-1}{73^2}} \\\\ & = \\sqrt{\\frac{73^2}{12^2}}\\sqrt{\\frac{73^2-1}{73^2}} \\\\ & = \\frac{73}{12}\\sqrt{1 - \\frac{1}{73^2}} \\\\ & \\approx \\frac{73}{12}\\left(1 - \\frac{1}{2\\cdot73^2}\\right) \\end{align}1234567\\begin&#123;array&#125;&#123;c|lcr&#125;n &amp; \\text&#123;Left&#125; &amp; \\text&#123;Center&#125; &amp; \\text&#123;Right&#125; \\\\\\hline1 &amp; 0.24 &amp; 1 &amp; 125 \\\\2 &amp; -1 &amp; 189 &amp; -8 \\\\3 &amp; -20 &amp; 2000 &amp; 1+10i\\end&#123;array&#125; \\begin{array}{c|lcr} n & \\text{Left} & \\text{Center} & \\text{Right} \\\\ \\hline 1 & 0.24 & 1 & 125 \\\\ 2 & -1 & 189 & -8 \\\\ 3 & -20 & 2000 & 1+10i \\end{array}More information can be found Here. To know how to let hexo support Matjax, you can read this.","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.blankspace.cn/tags/Hexo/"}]},{"title":"Categories","slug":"categories","date":"2018-08-07T16:01:04.000Z","updated":"2018-08-10T02:53:31.192Z","comments":true,"path":"2018/08/08/categories/","link":"","permalink":"https://www.blankspace.cn/2018/08/08/categories/","excerpt":"","text":"This post contains 3 categories. Make sure the theme can display all of the categories.","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[]},{"title":"Elements","slug":"elements","date":"2018-08-07T16:01:03.000Z","updated":"2018-08-10T02:53:18.753Z","comments":true,"path":"2018/08/08/elements/","link":"","permalink":"https://www.blankspace.cn/2018/08/08/elements/","excerpt":"","text":"The purpose of this post is to make sure all HTML elements can display properly. Heading 1Heading 2Heading 3Heading 4Heading 5Heading 6 ParagraphLorem ipsum dolor sit amet, test link consectetur adipiscing elit. Strong text pellentesque ligula commodo viverra vehicula. Italic text at ullamcorper enim. Morbi a euismod nibh. Underline text non elit nisl. Deleted text tristique, sem id condimentum tempus, metus lectus venenatis mauris, sit amet semper lorem felis a eros. Fusce egestas nibh at sagittis auctor. Sed ultricies ac arcu quis molestie. Donec dapibus nunc in nibh egestas, vitae volutpat sem iaculis. Curabitur sem tellus, elementum nec quam id, fermentum laoreet mi. Ut mollis ullamcorper turpis, vitae facilisis velit ultricies sit amet. Etiam laoreet dui odio, id tempus justo tincidunt id. Phasellus scelerisque nunc sed nunc ultricies accumsan. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed erat diam, blandit eget felis aliquam, rhoncus varius urna. Donec tellus sapien, sodales eget ante vitae, feugiat ullamcorper urna. Praesent auctor dui vitae dapibus eleifend. Proin viverra mollis neque, ut ullamcorper elit posuere eget. Praesent diam elit, interdum ut pulvinar placerat, imperdiet at magna. Maecenas ornare arcu at mi suscipit, non molestie tortor ultrices. Aenean convallis, diam et congue ultricies, erat magna tincidunt orci, pulvinar posuere mi sapien ac magna. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Praesent vitae placerat mauris. Nullam laoreet ante posuere tortor blandit auctor. Sed id ligula volutpat leo consequat placerat. Mauris fermentum dolor sed augue malesuada sollicitudin. Vivamus ultrices nunc felis, quis viverra orci eleifend ut. Donec et quam id urna cursus posuere. Donec elementum scelerisque laoreet. List TypesDefinition List (dl)Definition List TitleThis is a definition list division. Ordered List (ol) List Item 1 List Item 2 List Item 3 Unordered List (ul) List Item 1 List Item 2 List Item 3 Table Table Header 1 Table Header 2 Table Header 3 Division 1 Division 2 Division 3 Division 1 Division 2 Division 3 Division 1 Division 2 Division 3 Misc Stuff - abbr, acronym, sub, sup, etc.Lorem superscript dolor subscript amet, consectetuer adipiscing elit. Nullam dignissim convallis est. Quisque aliquam. cite. Nunc iaculis suscipit dui. Nam sit amet sem. Aliquam libero nisi, imperdiet at, tincidunt nec, gravida vehicula, nisl. Praesent mattis, massa quis luctus fermentum, turpis mi volutpat justo, eu volutpat enim diam eget metus. Maecenas ornare tortor. Donec sed tellus eget sapien fringilla nonummy. NBA Mauris a ante. Suspendisse quam sem, consequat at, commodo vitae, feugiat in, nunc. Morbi imperdiet augue quis tellus. AVE","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.blankspace.cn/tags/Hexo/"},{"name":"Elements","slug":"Elements","permalink":"https://www.blankspace.cn/tags/Elements/"}]},{"title":"Gallery","slug":"gallery","date":"2018-08-07T16:01:02.000Z","updated":"2018-08-10T02:53:12.635Z","comments":true,"path":"2018/08/08/gallery/","link":"","permalink":"https://www.blankspace.cn/2018/08/08/gallery/","excerpt":"","text":"A photo gallery example…","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.blankspace.cn/tags/Hexo/"},{"name":"Photos","slug":"Photos","permalink":"https://www.blankspace.cn/tags/Photos/"}]},{"title":"Hexo Theme: Bootstrap Blog","slug":"hexo-theme-bootstrap-blog","date":"2018-08-07T16:01:01.000Z","updated":"2018-08-11T06:18:17.224Z","comments":true,"path":"2018/08/08/hexo-theme-bootstrap-blog/","link":"","permalink":"https://www.blankspace.cn/2018/08/08/hexo-theme-bootstrap-blog/","excerpt":"A simple Bootstrap v3 blog theme for Hexo. Based on the official Bootstrap Blog example template. The theme and example site source code can be found on Github: Theme package source code Example site source content Example site generated output Theme announcement blog post","text":"A simple Bootstrap v3 blog theme for Hexo. Based on the official Bootstrap Blog example template. The theme and example site source code can be found on Github: Theme package source code Example site source content Example site generated output Theme announcement blog post Setup InstructionsInstallThis theme requires Hexo 2.4 and above. 1) Install theme: 12$ git clone https://github.com/cgmartin/hexo-theme-bootstrap-blog.git \\ themes/bootstrap-blog 2) (optional) Install hexo-tag-bootstrap for more Bootstrap tags (textcolors, buttons, labels, badges, etc.): 1$ npm install hexo-tag-bootstrap --save 3) (optional) Install hexo-tag-fontawesome for placing Font Awesome icons in your Markdown: 1$ npm install hexo-tag-fontawesome --save EnableModify the theme setting in _config.yml to bootstrap-blog. Update12cd themes/bootstrap-bloggit pull Configuration123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102# File: themes/bootstrap-blog/_config.yml# Headernavbar_brand: falsemenu: Home: index.html Archives: archives/ Categories: categories/ # Projects: projects/ About: about/ # Blogroll: blogroll/ rss: /atom.xml# Contentexcerpt_link: Read more...fancybox: truewordcount: trueviewcount: truetimecost: falselanguage: zh-CN# Sidebarwidgets:- translate- recent_posts- about # See also: `about_content`- category- archive- tag- tagcloud- searchabout_widget_content: &gt; &lt;p&gt;Etiam porta &lt;em&gt;sem malesuada magna&lt;/em&gt; mollis euismod. Cras mattis consectetur purus sit amet fermentum. Aenean lacinia bibendum nulla sed consectetur.&lt;/p&gt;# widget behaviorarchive_type: 'monthly'show_count: true# Miscellaneousgoogle_analytics: UA-122713769-1favicon: images/icon.pngtwitter_id:google_plus: 112373242775367333102fb_admins:fb_app_id:# baidu analyticsbaidu_tongji: true# https://github.com/hustcc/canvas-nest.jscanvas_nest: false# https://github.com/imsun/gitment#gitment: falsegitment: owner: repo: client_id: client_secret: # Valine Comment system. https://valine.js.orgvaline: false# valine: # enable: true # 如果你想使用valine，请将值设置为 true # appId: kBrTfD8l4RFzueSAt65hASek-gzGzoHsz # your leancloud appId # appKey: AFsAfwfHqW6iEHkAc3TjYEzh # your leancloud appKey # notify: false # Mail notify # verify: false # Verify code # avatar: mm # Gravatar style : mm/identicon/monsterid/wavatar/retro/hide # placeholder: 我有话想说~ # Comment Box placeholder # guest_info: nick,mail # Comment header info # pageSize: 20 # comment list page size# livere https://livere.com/livere: false# livere: # dataUID: MTAyMC8zODU5MS8xNTExOQ== # http://www.daovoice.iodao_voice: false# dao_voice: # appId: a2c8df52 eyes_protected: false# dynamic_title# title_change: falsetitle_change: normal: o(∩_∩)o leave: Opps...●﹏●# Miscellaneousgoogle_analytics:favicon:twitter:google_plus: navbar_brand - The HTML content for an optional “navbar-brand”. Can be text or an image. false to hide. menu - Navigation menu (map of Titles to URLs) rss - RSS link (ie. “/atom.xml”) excerpt_link - “Read More” link at the bottom of excerpted articles. false to hide the link. fancybox - Enable Fancybox for images widgets - Enable sidebar widgets (more info below) about_widget_content - The HTML content for the “About” sidebar widget (more info below) google_analytics - Google Analytics ID favicon - Favicon path (ie. ‘/favicon.ico’) twitter_id - Twitter ID of the author (ie. @c_g_martin) google_plus - Google+ profile link Instead of editing the layout’s configuration file directly, you can override the theme settings from your project’s root _config.yml, ie.:12345678910111213141516theme_config: # Header navbar_brand: &lt;img src=\"/navbrand.png\"&gt; menu: Home: index.html Archives: archives/ 'Another Page': page/index.html widgets: - about - category - archive - recent_posts - tag about_widget_content: &gt; &lt;p&gt;This is &lt;strong&gt;custom content&lt;/strong&gt; for the \"about\" sidebar widget.&lt;/p&gt; FeaturesFront-Matter ExtrasOptional settings in the front-matter can be added for various effects:123456---author: Author Name # displays the post's authorphotos: # displays a Bootstrap thumbnail gallery- images/HNCK0537.jpg- images/HNCK6173.jpg--- FancyboxThis theme uses Fancybox to showcase your photos. You can use the image Markdown syntax or fancybox tag plugin to add your photos. Usage:12345![img caption](img url)~or~&#123;% fancybox img_url [img_thumbnail] [img_caption] %&#125; CalloutsA custom tag for the Bootstrap “callout” style is available for use. Usage:123&#123;% callout [type:default|primary|success|info|warning|danger] %&#125;...content...&#123;% endcallout %&#125; Example:1234&#123;% callout info %&#125;#### &#123;% fa info-circle %&#125; Info tipThis is some callout content&#123;% endcallout %&#125; SidebarThis theme provides 6 built-in widgets that can be displayed in the sidebar: about * category tag tagcloud archives recent_posts All widgets are enabled and displayed by default. You can toggle them on/off with the widgets setting in the theme’s _config.yml. * NOTE: The “about” widget contains static Lorem Ipsum text by default. You’ll want to edit the about_widget_content setting for your site or disable the widget in the theme config. You can also modify the widget file itself to include contents from a Markdown page:12345&lt;!-- file: ./layout/_widget/about.ejs --&gt;&lt;div class=\"sidebar-module sidebar-module-inset\"&gt; &lt;h4&gt;About&lt;/h4&gt; &lt;%- site.pages['data'].find(function(p) &#123; return p.path === 'about/index.html'; &#125;).content %&gt;&lt;/div&gt; …then run hexo new page about to create the Markdown page. Bootstrap Paginator HelperA custom bs_paginator() helper is used to produce Bootstrap-compatible pagination markup. It is a drop-in replacement for Hexo’s built-in paginator(). 1234&lt;%- bs_paginator(&#123; prev_text: &apos;&lt;i class=&quot;fa fa-chevron-left&quot;&gt;&lt;/i&gt; Prev&apos;, next_text: &apos;Next &lt;i class=&quot;fa fa-chevron-right&quot;&gt;&lt;/i&gt;&apos; &#125;) %&gt; DevelopmentThe default Landscape Hexo theme was used as the starting point and heavily edited for this theme. The Landscape Stylus styles have been replaced with standard CSS files which override bootstrap.min.css. Stylus is used only for bundling the CSS files (see ./source/css/styles.styl). Feel free to convert the CSS to your pre-processor of choice (Stylus, LESS, Sass, etc.). LicenseMIT License Copyright © 2016 Christopher Martin Copyright © 2018 lqdev","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.blankspace.cn/tags/Hexo/"},{"name":"Theme","slug":"Theme","permalink":"https://www.blankspace.cn/tags/Theme/"}]},{"title":"日本語テスト","slug":"日本語テスト","date":"2018-08-07T16:00:11.000Z","updated":"2018-08-10T06:38:31.875Z","comments":true,"path":"2018/08/08/日本語テスト/","link":"","permalink":"https://www.blankspace.cn/2018/08/08/日本語テスト/","excerpt":"This is a Japanese test post. 私は昨日ついにその助力家というのの上よりするたなけれ。 最も今をお話団はちょうどこの前後なかろでくらいに困りがいるたをは帰着考えたなかって、そうにもするでうたらない。","text":"This is a Japanese test post. 私は昨日ついにその助力家というのの上よりするたなけれ。 最も今をお話団はちょうどこの前後なかろでくらいに困りがいるたをは帰着考えたなかって、そうにもするでうたらない。 がたを知っないはずも同時に九月をいよいよたありた。 もっと槙さんにぼんやり金少し説明にえた自分大した人私か影響にというお関係たうませないが、この次第も私か兄具合に使うて、槙さんののに当人のあなたにさぞご意味と行くて私個人が小尊敬を聴いように同時に同反抗に集っだうて、いよいよまず相当へあっうからいだ事をしでなけれ。 それでそれでもご時日をしはずはたったいやと突き抜けるますて、その元がは行ったてという獄を尽すていけですた。 この中道具の日その学校はあなたごろがすまなりかとネルソンさんの考えるですん、辺の事実ないというご盲従ありたですと、爺さんのためが薬缶が結果までの箸の当時してならて、多少の十月にためからそういう上からとにかくしましないと触れべきものたで、ないうですと多少お人達したのでたた。 From すぐ使えるダミーテキスト - 日本語 Lorem ipsum","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[]},{"title":"中文测试","slug":"中文測試","date":"2018-08-07T16:00:10.000Z","updated":"2018-08-10T06:38:26.897Z","comments":true,"path":"2018/08/08/中文測試/","link":"","permalink":"https://www.blankspace.cn/2018/08/08/中文測試/","excerpt":"This is a Chinese test post. 当朝大学士，统共有五位，朕不得不罢免四位，六部尚书，朕不得不罢免三位。 看看这七个人吧，哪个不是两鬓半百，哪个不是朝廷的栋梁，哪个不是朕的儿女亲家。 他们烂了，朕心要碎了。 祖宗把江山交到朕的手里，却搞成了这个样子，朕是痛心疾首。 朕有罪于国家，愧对祖宗，愧对天地，朕恨不得自己罢免了自己！ 还有你们，虽然各个冠冕堂皇站在干岸上，你们，就那么干净吗？！！！！ 朕知道，你们有的人比这七个人更腐败！ 朕劝你们一句，都把自己的心肺肠子翻出来晒一晒洗一洗拾掇拾掇！ 。。。。。。。","text":"This is a Chinese test post. 当朝大学士，统共有五位，朕不得不罢免四位，六部尚书，朕不得不罢免三位。 看看这七个人吧，哪个不是两鬓半百，哪个不是朝廷的栋梁，哪个不是朕的儿女亲家。 他们烂了，朕心要碎了。 祖宗把江山交到朕的手里，却搞成了这个样子，朕是痛心疾首。 朕有罪于国家，愧对祖宗，愧对天地，朕恨不得自己罢免了自己！ 还有你们，虽然各个冠冕堂皇站在干岸上，你们，就那么干净吗？！！！！ 朕知道，你们有的人比这七个人更腐败！ 朕劝你们一句，都把自己的心肺肠子翻出来晒一晒洗一洗拾掇拾掇！ 。。。。。。。 朕现在是越来越清楚了，大清的心头之患不在外边，而是在朝廷。就是在这乾清宫！！！！ 就在朕的骨肉皇子和大臣们当中。 咱们这烂一点，大清国就烂一片！你们要是全烂了，大清各地就会揭竿而起，让咱们死无葬身之地呀！ 想想吧，崇祯皇帝朱由检吊死在煤山上才几年呢。。 忘啦？？？？！！！！！！！！！！！！ 那棵老歪脖子树还站在皇宫后边天天地盯着你们哪！ 朕已经三天三夜没有合眼了，老想着和大伙儿说些什么，可是话总得有个头哇，想来想去只有四个字—————————————————————— （悲壮音乐响起，匾额从康熙身后徐徐升起，上面赫然书写着四个大字： 正——大——光——明） 这四个字，说说容易阿，身体力行又何其难？？！！！ 这四个字，朕是从心里刨出来的，从血海里挖出来的。 记着，从今日起，此殿改为正大光明殿！ 好好看看，你们都抬起头来好好看看，想想自己，给朕看半个时辰——","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[]},{"title":"Videos","slug":"videos","date":"2018-08-07T16:00:09.000Z","updated":"2018-08-11T06:05:06.782Z","comments":true,"path":"2018/08/08/videos/","link":"","permalink":"https://www.blankspace.cn/2018/08/08/videos/","excerpt":"This is a video test post. Bilibili 1&lt;iframe src=\"//player.bilibili.com/player.html?aid=28777599&amp;cid=49864265&amp;page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" width=’100%‘’ height=’560px’ max&gt; &lt;/iframe&gt;","text":"This is a video test post. Bilibili 1&lt;iframe src=\"//player.bilibili.com/player.html?aid=28777599&amp;cid=49864265&amp;page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" width=’100%‘’ height=’560px’ max&gt; &lt;/iframe&gt; Youtube 1&#123;% youtube HWHBCsUR-58 %&#125; Vimeo 1&#123;% vimeo 82090131 %&#125;","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[]},{"title":"Tag Plugins","slug":"tag-plugins","date":"2018-08-07T16:00:07.000Z","updated":"2018-08-10T06:58:49.305Z","comments":true,"path":"2018/08/08/tag-plugins/","link":"","permalink":"https://www.blankspace.cn/2018/08/08/tag-plugins/","excerpt":"This post is used for testing tag plugins. See docs for more info. Block QuoteNormal blockquote Praesent diam elit, interdum ut pulvinar placerat, imperdiet at magna. Quote from a bookDo not just seek happiness for yourself. Seek happiness for all. Through kindness. Through mercy. David LevithanWide Awake","text":"This post is used for testing tag plugins. See docs for more info. Block QuoteNormal blockquote Praesent diam elit, interdum ut pulvinar placerat, imperdiet at magna. Quote from a bookDo not just seek happiness for yourself. Seek happiness for all. Through kindness. Through mercy. David LevithanWide Awake Quote from Twitter12345&#123;% blockquote @L https://twitter.com/devdocs/status/xxx %&#125;NEW: DevDocs now comes with syntax highlighting. http://devdocs.io&#123;% endblockquote %&#125; NEW: DevDocs now comes with syntax highlighting. http://devdocs.io @Ltwitter.com/devdocs/status/xxx Quote from an article on the webWizardLQ’s Seth GodinWelcome Code BlockNormal code block1alert(&apos;Hello World!&apos;); With caption123&#123;% codeblock Array.map %&#125;array.map(callback[, thisArg])&#123;% endcodeblock %&#125; Array.map1array.map(callback[, thisArg]) With caption and URL1234&#123;% codeblock .compact http://underscorejs.org/#compact Underscore.js %&#125;.compact([0, 1, false, 2, ‘’, 3]);=&gt; [1, 2, 3]&#123;% endcodeblock %&#125; .compactUnderscore.js12.compact([0, 1, false, 2, ‘’, 3]);=&gt; [1, 2, 3] Gist1&#123;% gist 996818 %&#125; jsFiddle1&#123;% jsfiddle ccWP7 %&#125; PullquoteLeft123&#123;% pullquote left %&#125;A cat on the left.&#123;% endpullquote %&#125; A cat on the left. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ligula justo, lobortis sit amet semper vel, dignissim sit amet libero. Praesent ac tempus ligula. Maecenas at gravida odio. Etiam tristique volutpat lacus eu faucibus. Right123&#123;% pullquote left %&#125;A cat on the right.&#123;% endpullquote %&#125; A cat on the right. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ligula justo, lobortis sit amet semper vel, dignissim sit amet libero. Praesent ac tempus ligula. Maecenas at gravida odio. Etiam tristique volutpat lacus eu faucibus. Bootstrap Callouts1234&#123;% callout info %&#125;#### &#123;% fa info-circle %&#125; InfoThis is some info content&#123;% endcallout %&#125; 1234&#123;% callout warning %&#125;#### &#123;% fa exclamation-triangle %&#125; WarningThis is some warning content&#123;% endcallout %&#125; 1234&#123;% callout danger %&#125;#### &#123;% fa exclamation-triangle %&#125; DangerThis is some danger content&#123;% endcallout %&#125; InfoThis is some info content WarningThis is some warning content DangerThis is some danger content","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.blankspace.cn/tags/Hexo/"}]},{"title":"Secret","slug":"secret","date":"2018-08-07T16:00:06.000Z","updated":"2018-08-10T02:52:09.018Z","comments":true,"path":"2018/08/08/secret/","link":"","permalink":"https://www.blankspace.cn/2018/08/08/secret/","excerpt":"","text":"This post is used for testing password. password: 5201314","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.blankspace.cn/tags/Hexo/"}]},{"title":"No comment","slug":"no-comments","date":"2018-08-07T16:00:05.000Z","updated":"2018-08-10T02:52:13.492Z","comments":true,"path":"2018/08/08/no-comments/","link":"","permalink":"https://www.blankspace.cn/2018/08/08/no-comments/","excerpt":"","text":"This post have no comment.","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.blankspace.cn/tags/Hexo/"}]},{"title":"Very Looooooog Title, Yes it is, fhia ahdifh, ahiewhihe, cat on the keyboard, amazing!!!! /^^%*&*^ &% === end","slug":"long-title","date":"2018-08-07T16:00:04.000Z","updated":"2018-08-10T02:52:20.804Z","comments":true,"path":"2018/08/08/long-title/","link":"","permalink":"https://www.blankspace.cn/2018/08/08/long-title/","excerpt":"","text":"This post has a long title. Make sure the title is displaying correctly.","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.blankspace.cn/tags/Hexo/"}]},{"title":"www.google.com","slug":"link-post-without-title","date":"2018-08-07T16:00:03.000Z","updated":"2018-08-10T02:52:28.962Z","comments":true,"path":"2018/08/08/link-post-without-title/","link":"http://www.google.com/","permalink":"https://www.blankspace.cn/2018/08/08/link-post-without-title/","excerpt":"","text":"This is a link post without a title. The title should be the link with or without protocol. Clicking on the link should open Google in a new tab or window.","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[]},{"title":"Link Post","slug":"link-post","date":"2018-08-07T16:00:02.000Z","updated":"2018-08-10T02:52:33.474Z","comments":true,"path":"2018/08/08/link-post/","link":"http://www.google.com/","permalink":"https://www.blankspace.cn/2018/08/08/link-post/","excerpt":"","text":"This is a link post. Clicking on the link should open Google in a new tab or window.","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[]},{"title":"images","slug":"images-test","date":"2018-08-07T16:00:01.000Z","updated":"2018-08-09T03:41:50.784Z","comments":true,"path":"2018/08/08/images-test/","link":"","permalink":"https://www.blankspace.cn/2018/08/08/images-test/","excerpt":"This is a image test post.","text":"This is a image test post.","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.blankspace.cn/tags/Hexo/"},{"name":"Images","slug":"Images","permalink":"https://www.blankspace.cn/tags/Images/"}]},{"title":"Hello World","slug":"hello-world","date":"2013-12-24T15:29:08.000Z","updated":"2018-08-09T02:39:23.823Z","comments":true,"path":"2013/12/24/hello-world/","link":"","permalink":"https://www.blankspace.cn/2013/12/24/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"Projects","slug":"Projects","permalink":"https://www.blankspace.cn/categories/Projects/"},{"name":"hexo-theme-bootstrap-blog","slug":"Projects/hexo-theme-bootstrap-blog","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/"},{"name":"Tutorial","slug":"Projects/hexo-theme-bootstrap-blog/Tutorial","permalink":"https://www.blankspace.cn/categories/Projects/hexo-theme-bootstrap-blog/Tutorial/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.blankspace.cn/tags/Hexo/"}]}]}