<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>WizardLQ’s | 魔法师の小茶馆</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="远不止魔法......">
<meta name="keywords" content="Blog">
<meta property="og:type" content="website">
<meta property="og:title" content="WizardLQ’s | 魔法师の小茶馆">
<meta property="og:url" content="https://www.blankspace.cn/page/2/index.html">
<meta property="og:site_name" content="WizardLQ’s | 魔法师の小茶馆">
<meta property="og:description" content="远不止魔法......">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="WizardLQ’s | 魔法师の小茶馆">
<meta name="twitter:description" content="远不止魔法......">
<link rel="publisher" href="112373242775367340000">
  
    <link rel="alternate" href="../../atom.xml" title="WizardLQ’s | 魔法师の小茶馆" type="application/atom+xml">
  
  
    <link rel="icon" href="../../images/icon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
<link href="https://cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet"><link href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet">
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.slim.min.js"></script><script src="https://cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script type="text/javascript" src="//ajax.aspnetcdn.com/ajax/jQuery/jquery-2.0.3.min.js"></script>

<link rel="stylesheet" href="../../css/styles.css">

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script src="https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>


</head>

<body>

	
<div class="bg bg-blur" style="background:url('/images/bg/bg-4.jpg');background-position:center"></div>


<nav class="navbar navbar-inverse navbar-fixed-top">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
    </div>
	

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class=""
                 href="../../index.html">Home</a></li>
        
          <li><a class=""
                 href="../../archives/">Archives</a></li>
        
          <li><a class=""
                 href="../../categories/">Categories</a></li>
        
          <li><a class=""
                 href="../../about/">About</a></li>
        
          <li><a class=""
                 href="../../comments/">Comments</a></li>
        

      </ul>
		


    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
  

</nav>


<div class="container">

<div class="blog-header">
 <h1 class="blog-title">WizardLQ’s | 魔法师の小茶馆</h1>
  
    <p class="lead blog-description">Keep moving, never give up. | 锲而不舍，金石可镂.</p>
  
</div>



<div class="row">
    <div class="col-sm-9 blog-main">
	
	
	  
		

<article id="post-Tensor-Control" class="article article-type-post" itemscope itemprop="blogPost">
	


<header class="article-header">

  
    <h1 itemprop="name">
      <a class="article-title" href="../../2018/08/13/Tensor-Control/">Tensor Control</a>
    </h1>
  


	

<div class="article-meta"> 
	

   <div class="article-datetime">
  <a href="../../2018/08/13/Tensor-Control/" class="article-date"><time datetime="2018-08-13T02:06:14.000Z" itemprop="datePublished">2018-08-13</time></a>
</div>



	
	  
	
      <div class="post-meta">
            <span class="glyphicon glyphicon-pencil"></span>
            <span class="post-meta-item-text">&nbsp;Total&nbsp;</span>
            <span class="post-count">1,696&nbsp;words</span>
      </div>


 
	
  <div class="article-category">
    <a class="article-category-link" href="../../categories/Machine-Learning/">Machine Learning</a> / <a class="article-category-link" href="../../categories/Machine-Learning/TensorFlow/">TensorFlow</a>
  </div>


</div>
	   

</header>

<div class="article-inner">
<div class="article-entry" itemprop="articleBody">
  
  
	<!-- Table of Contents -->

	
	
	<h2 id="张量形状"><a href="#张量形状" class="headerlink" title="张量形状"></a>张量形状</h2><p>形状shape，用来描述张量的大小和数量。张量的形状表示为列表的形式，其中第i个元素表示维度i的大小，列表的长度标书张量的阶（维数）。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>阶</th>
<th>形状</th>
<th>维数</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>[]</td>
<td>0-D</td>
<td>0 维张量。标量。</td>
</tr>
<tr>
<td>1</td>
<td>[D0]</td>
<td>1-D</td>
<td>形状为 [6] 的 1 维张量。</td>
</tr>
<tr>
<td>2</td>
<td>[D0, D1]</td>
<td>2-D</td>
<td>形状为 [4, 3] 的 2 维张量。</td>
</tr>
<tr>
<td>3</td>
<td>[D0, D1, D2]</td>
<td>3-D</td>
<td>形状为 [1, 2, 3] 的 3 维张量。</td>
</tr>
<tr>
<td>n</td>
<td>[D0, D1, … Dn-1]</td>
<td>n 维</td>
<td>形状为 [D0, D1, … Dn-1] 的张量。</td>
</tr>
</tbody>
</table>
</div>
<p><a href="https://www.tensorflow.org/programmers_guide/tensors#shape" target="_blank" rel="noopener">文档</a>中介绍得更详细。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># show the shape of tensor</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">g = tf.Graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> g.as_default():</span><br><span class="line">    scalar = tf.ones([]) <span class="comment"># a scalar / 0-D tensor :1</span></span><br><span class="line">    vector = tf.ones([<span class="number">6</span>]) <span class="comment"># a vector with 6 elements: [1,1,1 ,1,1,1]</span></span><br><span class="line">    matrix = tf.ones([<span class="number">2</span>, <span class="number">3</span>]) <span class="comment"># a matrix with 2 rows and 3 columns</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment"># use tf.get_shape() </span></span><br><span class="line">        print(<span class="string">"Scalar shape: "</span>,scalar.get_shape(), <span class="string">" value: "</span>, sess.run(scalar))</span><br><span class="line">        print(<span class="string">"Vector shape: "</span>,vector.get_shape(), <span class="string">" value: "</span>, sess.run(vector))</span><br><span class="line">        print(<span class="string">"Matrix shape: "</span>,matrix.get_shape(), <span class="string">" value: "</span>, sess.run(matrix))</span><br></pre></td></tr></table></figure>
<pre><code>D:\Anaconda3\Anaconda3_py36\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters


Scalar shape:  ()  value:  1.0
Vector shape:  (6,)  value:  [1. 1. 1. 1. 1. 1.]
Matrix shape:  (2, 3)  value:  [[1. 1. 1.]
 [1. 1. 1.]]
</code></pre><h3 id="获取张量形状"><a href="#获取张量形状" class="headerlink" title="获取张量形状"></a>获取张量形状</h3><p>可以通过查看张量对象的<code>shape</code>属性来获取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vector.shape</span><br></pre></td></tr></table></figure>
<pre><code>TensorShape([Dimension(6)])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">matrix.shape[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<pre><code>Dimension(3)
</code></pre><h3 id="获取张量的数据类型"><a href="#获取张量的数据类型" class="headerlink" title="获取张量的数据类型"></a>获取张量的数据类型</h3><p>查看张量对象的<code>dtype</code>属性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">matrix.dtype</span><br></pre></td></tr></table></figure>
<pre><code>tf.float32
</code></pre><h3 id="改变张量数据类型"><a href="#改变张量数据类型" class="headerlink" title="改变张量数据类型"></a>改变张量数据类型</h3><p><code>tf.cast</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">c = tf.constant([<span class="number">1</span>,<span class="number">9</span>,<span class="number">8</span>,<span class="number">3</span>])</span><br><span class="line">print(c.dtype)</span><br><span class="line">f = tf.cast(c, dtype=tf.float32)</span><br><span class="line">print(f.dtype)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;dtype: &#39;int32&#39;&gt;
&lt;dtype: &#39;float32&#39;&gt;
</code></pre><h3 id="获取张量的阶"><a href="#获取张量的阶" class="headerlink" title="获取张量的阶"></a>获取张量的阶</h3><p><code>tf.rank()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.rank(scalar)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;tf.Tensor &#39;Rank:0&#39; shape=() dtype=int32&gt;
</code></pre><h3 id="张量切片"><a href="#张量切片" class="headerlink" title="张量切片"></a>张量切片</h3><p>对于n阶张量，要访问其中某一元素，需要制定n个索引。</p>
<p><code>:</code>是Python切片语法，也意味着<strong>不要变更该维度</strong>。可以帮助访问张量的子向量，子矩阵和子张量。</p>
<h2 id="Broadcasting-广播"><a href="#Broadcasting-广播" class="headerlink" title="Broadcasting | 广播"></a>Broadcasting | 广播</h2><p>tensorflow支持广播，借鉴了Numpy中的做法，<a href="https://docs.scipy.org/doc/numpy-1.10.1/user/basics.broadcasting.html" target="_blank" rel="noopener">Numpy Broadcasting</a>.</p>
<p>数学中，相同形状的张量才能进行元素级的运算，例如相加和等于。由于广播，使得不同形状的张量运算可以像对标量进行运算一样。</p>
<p>当张量被广播时，相当于对张量进行复制，实际上并不复制，广播专门为实现性能优化而设计。</p>
<p>举例，假设你和四个小伙伴，年龄分别为[18, 17, 20, 22, 21],每年年龄+1,模拟这个过程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 向量加法</span></span><br><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    <span class="comment"># method 1</span></span><br><span class="line">    ages = tf.constant([<span class="number">18</span>, <span class="number">17</span>, <span class="number">20</span>, <span class="number">22</span>, <span class="number">21</span>])</span><br><span class="line">    one = tf.constant([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    new_ages = tf.add(ages, one)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        print(new_ages.eval())</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># method 2</span></span><br><span class="line">    one_ = tf.constant(<span class="number">1</span>)</span><br><span class="line">    new_ages_ = tf.add(ages, one_)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        print(new_ages_.eval())</span><br></pre></td></tr></table></figure>
<pre><code>[19 18 21 23 22]
[19 18 21 23 22]
</code></pre><h3 id="张量变形"><a href="#张量变形" class="headerlink" title="张量变形"></a>张量变形</h3><p>可以使用<code>tf.reshape()</code>来改变张量的形状。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"></span><br><span class="line">arr = np.arange(<span class="number">1</span>, <span class="number">13</span>).reshape(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">np.random.shuffle(arr)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    x = tf.constant(arr, dtype=tf.int32) <span class="comment"># create a 3x4 matrix/ 2-D tensor</span></span><br><span class="line">    reshaped_4x3_x = tf.reshape(x, [<span class="number">4</span>, <span class="number">3</span>])</span><br><span class="line">    reshaped_2x6_x = tf.reshape(x, [<span class="number">2</span>, <span class="number">6</span>])</span><br><span class="line">    reshaped_3x2x2_x = tf.reshape(x, [<span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>]) <span class="comment"># reshape the rank </span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        print(<span class="string">"Original matrix (3x4):"</span>)</span><br><span class="line">        print(x.eval())</span><br><span class="line">        </span><br><span class="line">        print(<span class="string">"Reshaped matrix (4x3)"</span>)</span><br><span class="line">        print(reshaped_4x3_x.eval())</span><br><span class="line">        </span><br><span class="line">        print(<span class="string">"Reshaped matrix (2x6)"</span>)</span><br><span class="line">        print(reshaped_2x6_x.eval())</span><br><span class="line">        </span><br><span class="line">        print(<span class="string">"Reshaped matrix (3x2x2)"</span>)</span><br><span class="line">        print(reshaped_3x2x2_x.eval())</span><br></pre></td></tr></table></figure>
<pre><code>Original matrix (3x4):
[[ 9 10 11 12]
 [ 1  2  3  4]
 [ 5  6  7  8]]
Reshaped matrix (4x3)
[[ 9 10 11]
 [12  1  2]
 [ 3  4  5]
 [ 6  7  8]]
Reshaped matrix (2x6)
[[ 9 10 11 12  1  2]
 [ 3  4  5  6  7  8]]
Reshaped matrix (3x2x2)
[[[ 9 10]
  [11 12]]

 [[ 1  2]
  [ 3  4]]

 [[ 5  6]
  [ 7  8]]]
</code></pre><h2 id="变量、初始化和赋值"><a href="#变量、初始化和赋值" class="headerlink" title="变量、初始化和赋值"></a>变量、初始化和赋值</h2><p>TensorFlow变量初始化不是自动进行的，调用<code>tf.global_variables_initializer()</code>。不初始化就会报错。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    v = tf.Variable([<span class="number">3</span>])</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            sess.run(v)</span><br><span class="line">        <span class="keyword">except</span> tf.errors.FailedPreconditionError <span class="keyword">as</span> e:</span><br><span class="line">            print(<span class="string">"Caught excepted error: "</span>, e)</span><br></pre></td></tr></table></figure>
<pre><code>Caught excepted error:  Attempting to use uninitialized value Variable
     [[Node: _retval_Variable_0_0 = _Retval[T=DT_INT32, index=0, _device=&quot;/job:localhost/replica:0/task:0/device:CPU:0&quot;](Variable)]]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    v = tf.Variable([<span class="number">3</span>])</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        init = tf.global_variables_initializer()</span><br><span class="line">        sess.run(init)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            print(sess.run(v))</span><br><span class="line">        <span class="keyword">except</span> tf.errors.FailedPreconditionError <span class="keyword">as</span> e:</span><br><span class="line">            print(<span class="string">"Caught excepted error: "</span>, e)</span><br></pre></td></tr></table></figure>
<pre><code>[3]
</code></pre><h3 id="assign"><a href="#assign" class="headerlink" title="assign"></a>assign</h3><p>要变更变量的值，使用<code>tf.assign()</code>指令，仅仅创建assign指令也不能起作用。和初始化一样，也需要运行赋值指令才能变更变量值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    v = tf.Variable([<span class="number">3</span>])</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        init = tf.global_variables_initializer()</span><br><span class="line">        sess.run(init)</span><br><span class="line">        assignment = tf.assign(v, [<span class="number">9</span>])</span><br><span class="line">        print(v.eval()) <span class="comment"># the variable has not been changed yet.</span></span><br><span class="line">        sess.run(assignment)</span><br><span class="line">        print(v.eval()) <span class="comment"># now the variable is updated</span></span><br></pre></td></tr></table></figure>
<pre><code>[3]
[9]
</code></pre><h3 id="评估张量"><a href="#评估张量" class="headerlink" title="评估张量"></a>评估张量</h3><p><code>eval()</code>。<br>方法仅在默认 tf.Session 处于活动状态时才起作用。<code>Tensor.eval()</code>会返回一个和张量内容相同的Numpy数组。</p>
<p>仅仅只有占位符的情况下无法进行评估。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    p = tf.placeholder(tf.float32)</span><br><span class="line">    t = p+<span class="number">1.0</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment"># t.eval() # this will fail, since the placeholder did not give a value</span></span><br><span class="line">        print(t.eval(feed_dict=&#123;p:<span class="number">23.3</span>&#125;) )<span class="comment"># this will success, because a value is fed to the placeholder</span></span><br></pre></td></tr></table></figure>
<pre><code>24.3
</code></pre><h2 id="举例：模拟投掷两个骰子10次"><a href="#举例：模拟投掷两个骰子10次" class="headerlink" title="举例：模拟投掷两个骰子10次"></a>举例：模拟投掷两个骰子10次</h2><p>素材来自<a href="https://colab.research.google.com/notebooks/mlcc/creating_and_manipulating_tensors.ipynb?hl=zh-cn#scrollTo=iFIOcnfz_Oqw" target="_blank" rel="noopener">这里</a>.</p>
<p>模拟<a href="https://book.douban.com/subject/1082154/" target="_blank" rel="noopener">《活着》</a>中富贵儿赌钱投骰子（6个面，点数从1到6）的过程，在模拟中生成一个 <code>10x4</code> 二维张量，其中：</p>
<ul>
<li>列 <code>1</code> 和 <code>2</code> 均存储一个骰子的一次投掷值。</li>
<li>列 <code>3</code> 存储同一行中列 <code>1</code> 和 <code>2</code> 的值的总和。</li>
<li>列 <code>4</code> 表示开大开小，若列 <code>3</code> 点数大于7，开大（如用1表示）；小于等于7开小（如用0表示）。</li>
</ul>
<p>例如，第一行中可能会包含以下值：</p>
<ul>
<li>列 <code>1</code> 存储 <code>4</code></li>
<li>列 <code>2</code> 存储 <code>3</code></li>
<li>列 <code>3</code> 存储 <code>7</code></li>
<li>列 <code>4</code> 存储 <code>0</code></li>
</ul>
<p>要完成此任务，可能需要浏览 <a href="https://www.tensorflow.org/api_guides/python/array_ops" target="_blank" rel="noopener">TensorFlow 文档</a>。</p>
<p><strong>问题</strong>：<br><em>如何随机并分配值给变量？（TensorFlow不支持动态计算图）</em><br><em>如何赋值十次，循环？最后张量结果如何表示？</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import numpy as np</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">g = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g.as_default():</span><br><span class="line">    <span class="comment"># 使用随机均匀分布 tf.random_uniform 来模拟投掷 n 次, 不需要循环。</span></span><br><span class="line">    dice1 = tf.Variable(tf.random_uniform([<span class="number">10</span>, <span class="number">1</span>],</span><br><span class="line">                                         minval=<span class="number">1</span>,</span><br><span class="line">                                         maxval=<span class="number">7</span>,</span><br><span class="line">                                         dtype=tf.int32))</span><br><span class="line">    </span><br><span class="line">    dice2 = tf.Variable(tf.random_uniform([<span class="number">10</span>, <span class="number">1</span>],</span><br><span class="line">                                         minval=<span class="number">1</span>, </span><br><span class="line">                                         maxval=<span class="number">7</span>, </span><br><span class="line">                                         dtype=tf.int32))</span><br><span class="line">    </span><br><span class="line">    dice_sum = tf.add(dice1, dice2)</span><br><span class="line">    </span><br><span class="line">    seven = tf.constant(<span class="number">7</span>)</span><br><span class="line">    <span class="comment"># 关于TensorFlow条件控制</span></span><br><span class="line">    <span class="comment"># https://www.tensorflow.org/versions/r1.8/api_guides/python/control_flow_ops#Control_Flow_Operations</span></span><br><span class="line">    comp = tf.cast(tf.greater(dice_sum, seven), tf.int32)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用 tf.concat 连接向量，axis=1 水平方向连接</span></span><br><span class="line">    result = tf.concat(values=[dice1, dice2, dice_sum, comp], axis=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        </span><br><span class="line">        print(result.eval())</span><br></pre></td></tr></table></figure>
<pre><code>[[ 4  4  8  1]
 [ 6  1  7  0]
 [ 5  6 11  1]
 [ 4  2  6  0]
 [ 4  1  5  0]
 [ 5  3  8  1]
 [ 6  2  8  1]
 [ 4  2  6  0]
 [ 4  6 10  1]
 [ 1  3  4  0]]
</code></pre>
	
  
</div>


  



<footer class="article-footer">
  <a data-url="https://www.blankspace.cn/2018/08/13/Tensor-Control/" data-id="cjl3ikdgh000qegfikw77er0v" class="article-share-link">
	<i class="fa fa-share"></i> Share
  </a>
  
  
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/Tensor/">Tensor</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/TensorFlow/">TensorFlow</a></li></ul>


</footer>


</div>

</article>





	  
		

<article id="post-Tensor" class="article article-type-post" itemscope itemprop="blogPost">
	


<header class="article-header">

  
    <h1 itemprop="name">
      <a class="article-title" href="../../2018/08/13/Tensor/">Tensor</a>
    </h1>
  


	

<div class="article-meta"> 
	

   <div class="article-datetime">
  <a href="../../2018/08/13/Tensor/" class="article-date"><time datetime="2018-08-13T02:05:48.000Z" itemprop="datePublished">2018-08-13</time></a>
</div>



	
	  
	
      <div class="post-meta">
            <span class="glyphicon glyphicon-pencil"></span>
            <span class="post-meta-item-text">&nbsp;Total&nbsp;</span>
            <span class="post-count">630&nbsp;words</span>
      </div>


 
	
  <div class="article-category">
    <a class="article-category-link" href="../../categories/Machine-Learning/">Machine Learning</a> / <a class="article-category-link" href="../../categories/Machine-Learning/TensorFlow/">TensorFlow</a>
  </div>


</div>
	   

</header>

<div class="article-inner">
<div class="article-entry" itemprop="articleBody">
  
	<h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><p>TensorFlow中的Tensor就是张量，张量是任意维的数组。常用的张量有：</p>
<ul>
<li><strong>constant（标量/常量）</strong>：零维数组，零阶张量。例如，0或一个字符串常量。</li>
<li><strong>vector（向量/矢量）</strong>：一维数组，一阶张量。例如，[0]或[0, 1, 1, 2, 3, 5].</li>
<li><strong>matrix（矩阵）</strong>:二维数组，二阶张量。例如，[[4, 9, 2], [3, 5, 7], [8, 1, 6]]</li>
</ul>
<p>在TensorFlow中，张量的创建、销毁和控制由<strong>指令</strong>完成。典型的TensorFlow代码大多数都是指令。</p>
<h2 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h2><p>TensorFlow中的图，也叫作计算图或数据流图（<del>数据库原理和软件工程中的数据流图看似百无一用</del>），是一种<a href="https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/1450" target="_blank" rel="noopener">数据结构</a>。</p>
<p>TensorFlow程序可以选择创建一张或者多张图。</p>
<p><strong><em>图的节点是指令；图的边是张量。</em></strong>（张量就像是在图中的流动，所以称为Tensor Flow）.</p>
<p>张量流经图，在每个节点由一个指令控制。<strong>一个指令的输出张量通常会变成后续指令的输入张量</strong>。</p>
<p>TensorFlow实现<strong>延迟执行模型</strong>，系统仅会根据相关节点的需求在需要时计算节点。</p>
<p><strong><em>常量和张量都是图中的一种指令</em></strong>，<strong>常量是始终会返回同一张量值的指令</strong>，<strong>变量是会返回分配给它的任何张量的指令</strong>。</p>
<p><strong><em>图必须要在TensorFlow会话Session中运行，会话存储了被会话运行的图的状态</em></strong>.</p>
<p>会话可以将图发布到多台设备上（假如程序在某个分布式计算框架上运行）。官方提供的<a href="https://www.tensorflow.org/deploy/distributed" target="_blank" rel="noopener">分布式TensorFlow文档</a>.</p>
<p> TensorFlow 提供了一个<strong>默认图</strong>。不过，我们建议您明确创建自己的 <code>Graph</code>，以便跟踪状态（例如，您可能希望在每个单元格中使用一个不同的 <code>Graph</code>）。</p>
<h3 id="举例，“海伦-秦九韶公式”三斜求积"><a href="#举例，“海伦-秦九韶公式”三斜求积" class="headerlink" title="举例，“海伦-秦九韶公式”三斜求积"></a>举例，“海伦-秦九韶公式”三斜求积</h3><script type="math/tex; mode=display">
S = \sqrt{p\left( p-a\right)\left( p-b\right)\left( p-c\right)}</script><script type="math/tex; mode=display">
p=\frac{a+b+c}{2}</script><p>相关<a href="https://www.tensorflow.org/api_docs/python/tf" target="_blank" rel="noopener">API</a>.</p>
	
	  <p class="article-more-link">
		<a class="btn btn-primary" href="../../2018/08/13/Tensor/#more">Read more...</a>
	  </p>
	
  
</div>



<footer class="article-footer">
  <a data-url="https://www.blankspace.cn/2018/08/13/Tensor/" data-id="cjl3ikdgj000tegfit12uqb1i" class="article-share-link">
	<i class="fa fa-share"></i> Share
  </a>
  
  
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/Tensor/">Tensor</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/TensorFlow/">TensorFlow</a></li></ul>


</footer>


</div>

</article>





	  
		

<article id="post-Variable" class="article article-type-post" itemscope itemprop="blogPost">
	


<header class="article-header">

  
    <h1 itemprop="name">
      <a class="article-title" href="../../2018/08/12/Variable/">Variable</a>
    </h1>
  


	

<div class="article-meta"> 
	

   <div class="article-datetime">
  <a href="../../2018/08/12/Variable/" class="article-date"><time datetime="2018-08-12T14:35:05.000Z" itemprop="datePublished">2018-08-12</time></a>
</div>



	
	  
	
      <div class="post-meta">
            <span class="glyphicon glyphicon-pencil"></span>
            <span class="post-meta-item-text">&nbsp;Total&nbsp;</span>
            <span class="post-count">382&nbsp;words</span>
      </div>


 
	
  <div class="article-category">
    <a class="article-category-link" href="../../categories/Machine-Learning/">Machine Learning</a> / <a class="article-category-link" href="../../categories/Machine-Learning/TensorFlow/">TensorFlow</a>
  </div>


</div>
	   

</header>

<div class="article-inner">
<div class="article-entry" itemprop="articleBody">
  
  
	<!-- Table of Contents -->

	
	
	<p><a href="https://www.gushiwen.org/GuShiWen_dd05a84e30.aspx" target="_blank" rel="noopener">《庄子·天下》</a>中说“一尺之棰，日取其半，万世不竭。”使用TensorFlow来模拟这个过程。</p>
<h3 id="Variable"><a href="#Variable" class="headerlink" title="Variable"></a>Variable</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义变量</span></span><br><span class="line">bar = tf.Variable(<span class="number">1.0</span>, name=<span class="string">"bar"</span>)</span><br><span class="line"></span><br><span class="line">two = tf.constant(<span class="number">2.0</span>) </span><br><span class="line">divided = tf.divide(bar, <span class="number">2.0</span>) <span class="comment"># 定义取半操作，这一步并没有直接计算</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将bar更新为新的长度</span></span><br><span class="line">update = tf.assign(bar, divided)</span><br></pre></td></tr></table></figure>
<h3 id="初始化变量"><a href="#初始化变量" class="headerlink" title="初始化变量"></a>初始化变量</h3><p><code>global_variables_initializer()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer() <span class="comment"># z定义了变量就必须要初始化</span></span><br></pre></td></tr></table></figure>
<h3 id="创建会话并运行"><a href="#创建会话并运行" class="headerlink" title="创建会话并运行"></a>创建会话并运行</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        sess.run(update)</span><br><span class="line">        print(<span class="string">'day %d len: '</span>%i, sess.run(bar))</span><br></pre></td></tr></table></figure>
<pre><code>day 0 len:  0.5
day 1 len:  0.25
day 2 len:  0.125
day 3 len:  0.0625
day 4 len:  0.03125
day 5 len:  0.015625
day 6 len:  0.0078125
day 7 len:  0.00390625
day 8 len:  0.001953125
day 9 len:  0.0009765625
</code></pre><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Variable就是变量，和变量相对的就是常量，常量就是不变的量，那么变量就是会变化的量。在TensorFlow中使用<code>tf.Variable()</code>来定义变量。定义了变量就必须要进行变量初始化，初始化使用<code>tf.global_variables_initializer()</code><del>tf.initialize_all_variables()</del>.变量在运行时也需依靠定义会话Session来run才行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 高斯的故事之高斯求和TensorFlow实现</span></span><br><span class="line">s = tf.Variable(<span class="number">0</span>, name=<span class="string">"sum"</span>)</span><br><span class="line">number = tf.Variable(<span class="number">0</span>, name=<span class="string">"number"</span>)</span><br><span class="line">one = tf.constant(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">new_number = tf.assign(number, tf.add(number, one))</span><br><span class="line">update = tf.assign(s, tf.add(s, new_number))</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">101</span>):</span><br><span class="line">    sess.run(update)</span><br><span class="line">print(sess.run(s))</span><br><span class="line"></span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure>
<pre><code>5050
</code></pre>
	
  
</div>


  



<footer class="article-footer">
  <a data-url="https://www.blankspace.cn/2018/08/12/Variable/" data-id="cjl3ikdgl000uegfi7x3p7nju" class="article-share-link">
	<i class="fa fa-share"></i> Share
  </a>
  
  
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/TensorFlow/">TensorFlow</a></li></ul>


</footer>


</div>

</article>





	  
		

<article id="post-Session" class="article article-type-post" itemscope itemprop="blogPost">
	


<header class="article-header">

  
    <h1 itemprop="name">
      <a class="article-title" href="../../2018/08/12/Session/">Session</a>
    </h1>
  


	

<div class="article-meta"> 
	

   <div class="article-datetime">
  <a href="../../2018/08/12/Session/" class="article-date"><time datetime="2018-08-12T14:28:06.000Z" itemprop="datePublished">2018-08-12</time></a>
</div>



	
	  
	
      <div class="post-meta">
            <span class="glyphicon glyphicon-pencil"></span>
            <span class="post-meta-item-text">&nbsp;Total&nbsp;</span>
            <span class="post-count">465&nbsp;words</span>
      </div>


 
	
  <div class="article-category">
    <a class="article-category-link" href="../../categories/Machine-Learning/">Machine Learning</a> / <a class="article-category-link" href="../../categories/Machine-Learning/TensorFlow/">TensorFlow</a>
  </div>


</div>
	   

</header>

<div class="article-inner">
<div class="article-entry" itemprop="articleBody">
  
  
	<!-- Table of Contents -->

	
	
	<p>举两个例子。</p>
<h3 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">node = tf.constant(<span class="string">"Hello, world!"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># method 1</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run(node))</span><br><span class="line">sess.close</span><br><span class="line"></span><br><span class="line"><span class="comment"># method 2</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> tf:</span><br><span class="line">    print(sess.run(node))</span><br></pre></td></tr></table></figure>
<pre><code>D:\Anaconda3\Anaconda3_py36\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters


b&#39;Hello, world!&#39;
b&#39;Hello, world!&#39;
</code></pre><h3 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h3><p>理解Session会话，并使用TensorFlow来解决买菜问题（矩阵乘法）。素材来自<a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE3OTk2Ng==&amp;mid=2657440935&amp;idx=1&amp;sn=5b968c80fb07df3005039ca1466cb0c5&amp;chksm=bdd943b68aaecaa0420e1f3f9a576b1b0256ac7165a2fcf9b0c84080a5b0b53250418be594c8&amp;mpshare=1&amp;scene=1&amp;srcid=0812pRYblN0eJVNurGxLbC4F#rd" target="_blank" rel="noopener">《如何让11岁表妹知道矩阵乘法的本质是什么？》</a>.</p>
<p>假设买肉和菜，农贸市场一斤肉25元，一斤菜3元。<br>第一天我去农贸买了1斤肉，3斤菜，问计算用了多少钱：答：$25\times1+3\times3=34$。表示成向量乘法：</p>
<script type="math/tex; mode=display">
\begin{bmatrix}
 25&3 \\
\end{bmatrix} 
\times 
\begin{bmatrix}
 1 \\
 3 \\
\end{bmatrix} 
= 34</script><p>第二天，又去农贸市场买了2斤肉，1斤菜,则两天的花销可以表示为：</p>
<script type="math/tex; mode=display">
\begin{bmatrix}
 25&3 \\
\end{bmatrix} 
\times 
\begin{bmatrix}
 1&2 \\
 3&1 \\
\end{bmatrix} 
= 
\begin{bmatrix}
34 & 53
\end{bmatrix}</script><p>左边矩阵形状为1x2，行就表示<code>农贸市场</code>，两列分别表示<code>肉的单价和菜的单价</code>.右边矩阵，第一列表示第一天，第二列表示第二天，依次类推。第一行表示买的肉的数量，第二行表示买的菜的数量。两者进行矩阵相乘，得到的就是农贸市场，第n天，买肉和菜的总和。</p>
<p>听说王大妈哪里肉一斤20，菜一斤2元，假如这两天在王大妈哪里买菜，表示成矩阵：</p>
<script type="math/tex; mode=display">
\begin{bmatrix}
25&3\\
20&2\\
\end{bmatrix}
\begin{bmatrix}
1&2\\
3&1\\
\end{bmatrix}
=
\begin{bmatrix}
34&53\\
26&42\\
\end{bmatrix}</script><p><img src="https://mmbiz.qpic.cn/mmbiz_png/pojyAtdhQhNM8WaSdOWGtLciaHKXKs4DrOkXwemKzA7p3AuHKhht3em8mV0hXDyNQeBU6geAQIGoFa3WX0ThoZg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 创建计算图</span></span><br><span class="line"></span><br><span class="line">mat1 = tf.constant(np.array([[<span class="number">25</span>, <span class="number">3</span>], [<span class="number">20</span>, <span class="number">2</span>]]))</span><br><span class="line">mat2 = tf.constant(np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">1</span>]]))</span><br><span class="line">product = tf.matmul(mat1, mat2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建会话和运行</span></span><br><span class="line"><span class="comment"># method 1</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">money = sess.run(product)</span><br><span class="line">print(money)</span><br><span class="line">sess.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># method 2</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    money = sess.run(product)</span><br><span class="line">    print(money)</span><br></pre></td></tr></table></figure>
<pre><code>[[34 53]
 [26 42]]
[[34 53]
 [26 42]]
</code></pre>
	
  
</div>


  



<footer class="article-footer">
  <a data-url="https://www.blankspace.cn/2018/08/12/Session/" data-id="cjl3ikdge000legfigvfw3ywl" class="article-share-link">
	<i class="fa fa-share"></i> Share
  </a>
  
  
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/TensorFlow/">TensorFlow</a></li></ul>


</footer>


</div>

</article>





	  
		

<article id="post-MNIST-pros" class="article article-type-post" itemscope itemprop="blogPost">
	


<header class="article-header">

  
    <h1 itemprop="name">
      <a class="article-title" href="../../2018/08/12/MNIST-pros/">MNIST pros</a>
    </h1>
  


	

<div class="article-meta"> 
	

   <div class="article-datetime">
  <a href="../../2018/08/12/MNIST-pros/" class="article-date"><time datetime="2018-08-12T02:11:47.000Z" itemprop="datePublished">2018-08-12</time></a>
</div>



	
	  
	
      <div class="post-meta">
            <span class="glyphicon glyphicon-pencil"></span>
            <span class="post-meta-item-text">&nbsp;Total&nbsp;</span>
            <span class="post-count">2,554&nbsp;words</span>
      </div>


 
	
  <div class="article-category">
    <a class="article-category-link" href="../../categories/Machine-Learning/">Machine Learning</a> / <a class="article-category-link" href="../../categories/Machine-Learning/TensorFlow/">TensorFlow</a>
  </div>


</div>
	   

</header>

<div class="article-inner">
<div class="article-entry" itemprop="articleBody">
  
	<h3 id="运行TensorFlow的InteractiveSession-交互式会话"><a href="#运行TensorFlow的InteractiveSession-交互式会话" class="headerlink" title="运行TensorFlow的InteractiveSession/交互式会话"></a>运行TensorFlow的InteractiveSession/交互式会话</h3><p><code>sess = tf.InteractiveSession()</code>用来创建交互式的会话，其余使用同Session</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure>
<pre><code>D:\Anaconda3\Anaconda3_py36\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
</code></pre><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><p>和上一节类似</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># http://yann.lecun.com/exdb/mnist/  to download mnist dataset</span></span><br><span class="line"><span class="comment"># https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/input_data.py</span></span><br><span class="line"><span class="comment"># to read dataset</span></span><br><span class="line"><span class="keyword">from</span> load_mnist <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> tensorflow.examples.tutorials.mnist.input_data <span class="keyword">as</span> input_data</span><br><span class="line">minst_dir = <span class="string">"MNIST_data/"</span></span><br><span class="line">mnist = input_data.read_data_sets(minst_dir, one_hot=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = tf.placeholder(<span class="string">"float"</span>, shape=[<span class="keyword">None</span>, <span class="number">784</span>]) </span><br><span class="line">y_ = tf.placeholder(<span class="string">"float"</span>, shape=[<span class="keyword">None</span>, <span class="number">10</span>]) <span class="comment"># true label</span></span><br></pre></td></tr></table></figure>
<h2 id="构建一个多层卷积网络"><a href="#构建一个多层卷积网络" class="headerlink" title="构建一个多层卷积网络"></a>构建一个多层卷积网络</h2><h3 id="权重初始化"><a href="#权重初始化" class="headerlink" title="权重初始化"></a>权重初始化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>) <span class="comment">#  The generated values follow a normal distribution with specified mean and</span></span><br><span class="line">    <span class="comment"># standard deviation.从截断的正态分布中输出随机值，中如果x的取值在区间（μ-2σ，μ+2σ）之外则重新进行选择</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.constant(<span class="number">0.1</span>, shape=shape) <span class="comment"># Constant 2-D tensor populated with scalar value 0.1. 初始值为0.1，广播到shape形状的二维数组</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br></pre></td></tr></table></figure>
<h3 id="卷积和汇聚（池化）"><a href="#卷积和汇聚（池化）" class="headerlink" title="卷积和汇聚（池化）"></a>卷积和汇聚（<del>池化</del>）</h3><p><em>由于Pooling翻译成池化让人不明所以，个人习惯依据其作用，而称之为汇聚。</em></p>
<p>简单起见，卷积使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。我们的池化用简单传统的2x2大小的模板做max pooling.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br></pre></td></tr></table></figure>
	
	  <p class="article-more-link">
		<a class="btn btn-primary" href="../../2018/08/12/MNIST-pros/#more">Read more...</a>
	  </p>
	
  
</div>



<footer class="article-footer">
  <a data-url="https://www.blankspace.cn/2018/08/12/MNIST-pros/" data-id="cjl3ikdga000jegfiiexm9fui" class="article-share-link">
	<i class="fa fa-share"></i> Share
  </a>
  
  
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/TensorFlow/">TensorFlow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/mnist/">mnist</a></li></ul>


</footer>


</div>

</article>





	  
	
	
	
	  <div id="page-nav">
		<nav><ul class="pagination"><li><a class="page-prev" rel="prev" href="../../index.html"><i class="fa fa-chevron-left"></i> Prev</a></li><li><a class="page-number" href="../../index.html">1</a></li><li class="active"><span class="page-number">2</span></li><li><a class="page-number" href="../../page/3/">3</a></li><li><a class="page-number" href="../../page/4/">4</a></li><li class="disabled"><span class="page-space">&hellip;</span></li><li><a class="page-number" href="../../page/7/">7</a></li><li><a class="page-next" rel="next" href="../../page/3/">Next <i class="fa fa-chevron-right"></i></a></li></ul></nav>
	  </div>
	

    </div>
    <div class="col-sm-3 col-sm-offset-0 blog-sidebar">
	  
  
  <div class="sidebar-module">
    <h4>Recents</h4>
    <ul class="sidebar-module-list">
      
        <li>
          <a href="../../2018/08/21/let-ubuntu-be-controled-by-windows/">通过SSH让Windows控制Ubuntu</a>
        </li>
      
        <li>
          <a href="../../2018/08/20/ubuntu-beginner/">Ubuntu 18.04.1 初学遇到的部分小问题和解决方法</a>
        </li>
      
        <li>
          <a href="../../2018/08/14/MathJax-basic-tutorial/">MathJax basic tutorial and quick reference</a>
        </li>
      
        <li>
          <a href="../../2018/08/13/activation-function/">Activation function</a>
        </li>
      
        <li>
          <a href="../../2018/08/13/placeholder/">Placeholder</a>
        </li>
      
    </ul>
  </div>


  <div class="sidebar-module sidebar-module-inset">
  <h4>About</h4>
  <a target="_blank" href="about"> <img  id="avatar-logo" width=100%  alt="WizardLQ" src="http://www.gravatar.com/avatar/d14c7c7faf5e1f3001c070f3141d698f?s=512"> </a> <p>Hi,我是一名魔法师，目前自动化硕士在读.<em><strong>“科技是普通人眼中的魔法”</strong></em>. 之前有在<a href="https://blog.csdn.net/icurious">CSDN</a>、博客园、简书等写过博客.关于我的更多介绍请见：<a href="/about">>>></a> </p>

</div>




  
  <div class="sidebar-module">
    <h4>Categories</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../categories/Languages/">Languages</a><span class="sidebar-module-list-count">1</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../categories/Languages/Python/">Python</a><span class="sidebar-module-list-count">1</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../categories/Languages/Python/Numpy/">Numpy</a><span class="sidebar-module-list-count">1</span></li></ul></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../categories/Linux/">Linux</a><span class="sidebar-module-list-count">2</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../categories/Linux/Ubuntu/">Ubuntu</a><span class="sidebar-module-list-count">2</span></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../categories/Machine-Learning/">Machine Learning</a><span class="sidebar-module-list-count">8</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../categories/Machine-Learning/TensorFlow/">TensorFlow</a><span class="sidebar-module-list-count">8</span></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../categories/Math/">Math</a><span class="sidebar-module-list-count">1</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../categories/Math/MathJax/">MathJax</a><span class="sidebar-module-list-count">1</span></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../categories/Projects/">Projects</a><span class="sidebar-module-list-count">19</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../categories/Projects/hexo-theme-bootstrap-blog/">hexo-theme-bootstrap-blog</a><span class="sidebar-module-list-count">19</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../categories/Projects/hexo-theme-bootstrap-blog/Tutorial/">Tutorial</a><span class="sidebar-module-list-count">19</span></li></ul></li></ul></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Archives</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../archives/2018/08/">八月 2018</a><span class="sidebar-module-list-count">30</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../archives/2013/12/">十二月 2013</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  <section>
	<h4>Search</h4>
	<div class="sidebar-module sidebar-module-inset">

	
	<div id="site_search">
	<input type="text" placeholder="Search in the site" class="form-control" id="local-search-input" results="0"/>
	<div id="local-search-result">
	</div>
	</div>
	
</section>


	</div>
		
</div>
	
	
</div>

<footer class="blog-footer">  
  <div class="container">
		<div >
	 <ul id="links" class="nav navbar-nav" style="display: inline-block;float: none;">
		<li><a href="https://weibo.com/liuqidev" title="Find me on Weibo" target="_blank"><i class="iconfont">&#xe655;</i></a></li>
		<li><a href="https://www.zhihu.com/people/wizardlq/" title="Find me on Zhihu" target="_blank"><i class="iconfont">&#xe61b;</i></a></li>
		<li><a href="https://blog.csdn.net/icurious" title="Find me on CSDN" target="_blank"><i class="iconfont">&#xe64f;</i></a></li>
		<li><a href="https://www.douban.com/people/icurious/" title="My Douban" target="_blank"><i class="iconfont">&#xe601;</i></a></li>
		<li><a href="https://space.bilibili.com/20204877/#/" title="Find me on Bilibili" target="_blank"><i class="iconfont">&#xe6b4;</i></a></li>
		<li><a href="https://github.com/liuqidev" title="My Linkedin" target="_blank"><i class="iconfont">&#xe663;</i></a></li>
		<li><a href="https://github.com/liuqidev" title="My Projects on Github" target="_blank"><i class="iconfont">&#xe7ab;</i></a></li>
		<li><a href="https://stackoverflow.com/users/9121113/qi-liu" title="My StackoverFlow" target="_blank"><i class="iconfont">&#xe711;</i></a></li>
		
		
		  <li><a href="/atom.xml" title="RSS Feed"><i class="fa fa-rss" target="_blank"></i></a></li>
		
	  </ul>
	 </div>
    <div id="footer-info" class="text-center">
        &copy; 2018. <em>All Rights Reserved by <a href="https://github.com/liuqidev" target="_blank">liuqidev</a></em><br>	
	</div>
	<div > 

	  </links>
  </div>

  
    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
  <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=XzXyQ1GOPdnOuiMHQmBZKolTWTBtRkFzmBoniAwXpMc&cl=ffffff&w=a"></script>

  <p>
  	<span id="busuanzi_container_site_uv">
  	    <span id="busuanzi_value_site_uv"></span> visitors  |  
  	</span>

      <span id="busuanzi_container_site_pv">
         <span id="busuanzi_value_site_pv"></span> visits
      </span>
	  
  </p>
    


</footer>



 
	   <script type="text/javascript">     
		  var searchFunc = function(path, search_id, content_id) {
		'use strict'; //使用严格模式
		$.ajax({
			url: path,
			dataType: "xml",
			success: function( xmlResponse ) {
				// 从xml中获取相应的标题等数据
				var datas = $( "entry", xmlResponse ).map(function() {
					return {
						title: $( "title", this ).text(),
						content: $("content",this).text(),
						url: $( "url" , this).text()
					};
				}).get();
				//ID选择器
				var $input = document.getElementById(search_id);
				var $resultContent = document.getElementById(content_id);
				$input.addEventListener('input', function(){
					var str='<ul class=\"search-result-list\">';                
					var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
					$resultContent.innerHTML = "";
					if (this.value.trim().length <= 0) {
						return;
					}
					// 本地搜索主要部分
					datas.forEach(function(data) {
						var isMatch = true;
						var content_index = [];
						var data_title = data.title.trim().toLowerCase();
						var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
						var data_url = data.url;
						var index_title = -1;
						var index_content = -1;
						var first_occur = -1;
						// 只匹配非空文章
						if(data_title != '' && data_content != '') {
							keywords.forEach(function(keyword, i) {
								index_title = data_title.indexOf(keyword);
								index_content = data_content.indexOf(keyword);
								if( index_title < 0 && index_content < 0 ){
									isMatch = false;
								} else {
									if (index_content < 0) {
										index_content = 0;
									}
									if (i == 0) {
										first_occur = index_content;
									}
								}
							});
						}
						// 返回搜索结果
						if (isMatch) {
						//结果标签
							str += "<li><a href='"+ data_url +"' class='search-result-title' target='_blank'>"+ "> " + data_title +"</a>";
							var content = data.content.trim().replace(/<[^>]+>/g,"");
							if (first_occur >= 0) {
								// 拿出含有搜索字的部分
								var start = first_occur - 6;
								var end = first_occur + 6;
								if(start < 0){
									start = 0;
								}
								if(start == 0){
									end = 10;
								}
								if(end > content.length){
									end = content.length;
								}
								var match_content = content.substr(start, end); 
								// 列出搜索关键字，定义class加高亮
								keywords.forEach(function(keyword){
									var regS = new RegExp(keyword, "gi");
									match_content = match_content.replace(regS, "<em class=\"search-keyword\">"+keyword+"</em>");
								})
								str += "<p class=\"search-result\">" + match_content +"...</p>"
							}
						}
					})
					$resultContent.innerHTML = str;
				})
			}
		})
	};
	var path = "../search.xml";
	searchFunc(path, 'local-search-input', 'local-search-result');
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>






	


<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?70a761ba668ab8571ac79968adcf6078";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>










<script src="https://cdn.bootcss.com/jquery/2.1.4/jquery.min.js"></script>
  <link rel="stylesheet" href="../../fancybox/jquery.fancybox.css">
  <script src="../../fancybox/jquery.fancybox.pack.js"></script>

<script src="../../js/script.js"></script>

<!--Back to top-->
<body id="top">
<p id="back-to-top"><a href="#top"><span></span></a></p>
</body>


<script>
$(document).ready(function() {
    //首先将#back-to-top隐藏
    $("#back-to-top").hide();
 
    //当滚动条的位置处于距顶部3600像素以下时，跳转链接出现，否则消失
    $(function() {
        $(window).scroll(function() {
            if ($(window).scrollTop() > 3600) {
                $("#back-to-top").fadeIn(1500);
            }
            else {
                $("#back-to-top").fadeOut(1500);
            }
        });
        //当点击跳转链接后，回到页面顶部位置
        $("#back-to-top").click(function() {
            $('body,html').animate({
                scrollTop: 0
            },
            500);
			
            return false;
        });
    });
});
</script>

</body>
</html>
