<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Activation function | WizardLQ’s | 魔法师の小茶馆</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Activation function（激活函数），是一类非线性函数，与之对应的就是线性函数。线性函数就是一条直线，形式化表示就是：  y=mx+b$m$是直线的斜率，$y$通常是预测的值，$x$是输入的特征值，$b$是$y$轴的截距。 由于现实世界的复杂性，输入特征和预测之间的关系通常不是简单的线性关系，换言之就是非线性关系。然后就发现一些非线性函数，满足一定的性质（这个得看人家的论文），通过非">
<meta name="keywords" content="TensorFlow,Activation">
<meta property="og:type" content="article">
<meta property="og:title" content="Activation function">
<meta property="og:url" content="https://www.blankspace.cn/2018/08/13/activation-function/index.html">
<meta property="og:site_name" content="WizardLQ’s | 魔法师の小茶馆">
<meta property="og:description" content="Activation function（激活函数），是一类非线性函数，与之对应的就是线性函数。线性函数就是一条直线，形式化表示就是：  y=mx+b$m$是直线的斜率，$y$通常是预测的值，$x$是输入的特征值，$b$是$y$轴的截距。 由于现实世界的复杂性，输入特征和预测之间的关系通常不是简单的线性关系，换言之就是非线性关系。然后就发现一些非线性函数，满足一定的性质（这个得看人家的论文），通过非">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://www.blankspace.cn/2018/08/13/activation-function/output_1_0.png">
<meta property="og:image" content="https://www.blankspace.cn/2018/08/13/activation-function/output_2_0.png">
<meta property="og:updated_time" content="2018-08-13T13:46:27.782Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Activation function">
<meta name="twitter:description" content="Activation function（激活函数），是一类非线性函数，与之对应的就是线性函数。线性函数就是一条直线，形式化表示就是：  y=mx+b$m$是直线的斜率，$y$通常是预测的值，$x$是输入的特征值，$b$是$y$轴的截距。 由于现实世界的复杂性，输入特征和预测之间的关系通常不是简单的线性关系，换言之就是非线性关系。然后就发现一些非线性函数，满足一定的性质（这个得看人家的论文），通过非">
<meta name="twitter:image" content="https://www.blankspace.cn/2018/08/13/activation-function/output_1_0.png">
<link rel="publisher" href="112373242775367340000">
  
    <link rel="alternate" href="../../../../atom.xml" title="WizardLQ’s | 魔法师の小茶馆" type="application/atom+xml">
  
  
    <link rel="icon" href="../../../../images/icon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  


  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js">
  </script>
  <link rel="stylesheet" href="../../../../css/styles.css">
  




</head>

<body>
	<div class="bg bg-blur"></div>
	<!-- Fixed navbar -->
<nav class="navbar navbar-inverse navbar-fixed-top">
  <div class="container">
	<div class="navbar-header">
	  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
		<span class="sr-only">Toggle navigation</span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
	  </button>
	  
	</div>
	<div id="navbar" class="navbar-collapse collapse">
	  <ul class="nav navbar-nav">
		  
			<li><a class="" href="../../../../index.html">Home</a></li>
          
			<li><a class="" href="../../../../archives/">Archives</a></li>
          
			<li><a class="" href="../../../../categories/">Categories</a></li>
          
			<li><a class="" href="../../../../about/">About</a></li>
          
	  </ul>
	  
	</div><!--/.nav-collapse -->
  </div>
</nav>
	<div class="container">
<article id="post-activation-function" class="article article-type-post" itemscope itemprop="blogPost">
	


	    <header class="article-header">
		
  
    <h1 class="article-title" itemprop="name">
      Activation function
    </h1>
  


			
		
		<div class="article-meta"> 
			
	  
		   <div class="article-datetime">
  <a href="" class="article-date"><time datetime="2018-08-13T13:24:57.000Z" itemprop="datePublished">2018-08-13</time></a>
</div>



			
			
			  <div class="post-meta">
<span class="glyphicon glyphicon-eye-open"></span>&nbsp;View <span id="busuanzi_value_page_pv"></span>&nbsp;times
</div> 
			  
			
      <div class="post-meta">
            <span class="glyphicon glyphicon-pencil"></span>
            <span class="post-meta-item-text">&nbsp;Total&nbsp;</span>
            <span class="post-count">648&nbsp;words</span>
      </div>


 
			
  <div class="article-category">
    <a class="article-category-link" href="../../../../categories/Machine-Learning/">Machine Learning</a> / <a class="article-category-link" href="../../../../categories/Machine-Learning/TensorFlow/">TensorFlow</a>
  </div>


	    </div>
	    </header>
	    
	  
	  <div class="article-inner">
		<div class="article-entry" itemprop="articleBody">
		  
		  
			<!-- Table of Contents -->

			
			
			<p>Activation function（激活函数），是一类非线性函数，与之对应的就是线性函数。线性函数就是一条直线，形式化表示就是：</p>
<script type="math/tex; mode=display">
y=mx+b</script><p>$m$是直线的斜率，$y$通常是预测的值，$x$是输入的特征值，$b$是$y$轴的截距。</p>
<p>由于现实世界的复杂性，输入特征和预测之间的关系通常不是简单的线性关系，换言之就是非线性关系。然后就发现一些非线性函数，满足一定的性质（这个得看人家的论文），通过非线性函数多层的组合，可以来拟合非常复杂的非线性函数。</p>
<p>更过关于激活函数的介绍，请看<a href="https://en.wikipedia.org/wiki/Activation_function" target="_blank" rel="noopener">这里</a>.</p>
<p>TensorFlow中更多激活函数，请看<a href="https://www.tensorflow.org/api_guides/python/nn#Activation_Functions" target="_blank" rel="noopener">TensorFlow Activation Function</a>.</p>
<h3 id="Binary-step"><a href="#Binary-step" class="headerlink" title="Binary step"></a>Binary step</h3><script type="math/tex; mode=display">
f(x) =
\begin{cases}
0,  & \text{for x $\lt$ 0} \\
1, & \text{for x $\geq$ 0}
\end{cases}</script><p>阶跃函数是理想的激活函数，但是不可导。</p>
<p>下面对几种常见的激活函数进行可视化。</p>
<h3 id="ReLu-rectified-linear-unit-ReLu"><a href="#ReLu-rectified-linear-unit-ReLu" class="headerlink" title="ReLu(rectified linear unit, ReLu)"></a>ReLu(rectified linear unit, ReLu)</h3><script type="math/tex; mode=display">
f(x) =
\begin{cases}
0,  & \text{for x $\lt$ 0} \\
x, & \text{for x $\geq$ 0}
\end{cases}</script><h3 id="Logistic-Sigmoid-or-Soft-step"><a href="#Logistic-Sigmoid-or-Soft-step" class="headerlink" title="Logistic(Sigmoid or Soft step)"></a>Logistic(Sigmoid or Soft step)</h3><script type="math/tex; mode=display">
f(x)=\sigma{(x)} = \frac{1}{1+e^{-x}}</script><h3 id="TanH"><a href="#TanH" class="headerlink" title="TanH"></a>TanH</h3><script type="math/tex; mode=display">
f(x)= \tanh{(x)}= \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}</script><h3 id="Softplus"><a href="#Softplus" class="headerlink" title="Softplus"></a>Softplus</h3><script type="math/tex; mode=display">
f(x)= \ln{(1+e^x)}</script><h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><script type="math/tex; mode=display">
f_{i}(x)= \frac{e^{x_{i}}}{\sum_{j=1}^{J}e^{x_j}}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf <span class="comment"># machine learning framwork</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># scientific computation</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># data visualization</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Graph().as_default(), tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    x_data = np.linspace(<span class="number">-6</span>, <span class="number">6</span>, <span class="number">256</span>)</span><br><span class="line"></span><br><span class="line">    y_relu = tf.nn.relu(x_data)</span><br><span class="line">    y_sigmoid = tf.nn.sigmoid(x_data)</span><br><span class="line">    y_tanh = tf.nn.tanh(x_data)</span><br><span class="line">    y_softplus = tf.nn.softplus(x_data)</span><br><span class="line">    y_softmax = tf.nn.softmax(x_data) <span class="comment"># softmax is a special kind of activation function, it is about probablity</span></span><br><span class="line"></span><br><span class="line">    y_relu, y_sigmoid, y_tanh, y_softplus, y_softmax = sess.run([y_relu, y_sigmoid, y_tanh, y_softplus, y_softmax])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># plot</span></span><br><span class="line">    fig = plt.figure(<span class="number">1</span>, figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">    plt.subplot(<span class="number">221</span>)</span><br><span class="line">    plt.plot(x_data, y_relu, c=<span class="string">'red'</span>, label=<span class="string">'relu'</span>)</span><br><span class="line">    plt.ylim(<span class="number">-1</span>, <span class="number">6</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">222</span>)</span><br><span class="line">    plt.plot(x_data, y_sigmoid, c=<span class="string">'green'</span>, label=<span class="string">'sigmoid'</span>)</span><br><span class="line">    plt.ylim(<span class="number">-0.3</span>, <span class="number">1.5</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">223</span>)</span><br><span class="line">    plt.plot(x_data, y_tanh, c=<span class="string">'blue'</span>, label=<span class="string">'tanh'</span>)</span><br><span class="line">    plt.ylim(<span class="number">-1.2</span>, <span class="number">1.2</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">224</span>)</span><br><span class="line">    plt.plot(x_data, y_softplus, c=<span class="string">'yellow'</span>, label=<span class="string">'softplus'</span>)</span><br><span class="line">    plt.ylim(<span class="number">-0.3</span>, <span class="number">6</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2018/08/13/activation-function/output_1_0.png" alt="Activation Functions-1"></p>
<a id="more"></a>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default(), tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    x_data = np.linspace(<span class="number">-6</span>, <span class="number">6</span>, <span class="number">256</span>)</span><br><span class="line"></span><br><span class="line">    y_relu = tf.nn.relu(x_data)</span><br><span class="line">    y_sigmoid = tf.nn.sigmoid(x_data)</span><br><span class="line">    y_tanh = tf.nn.tanh(x_data)</span><br><span class="line">    y_softplus = tf.nn.softplus(x_data)</span><br><span class="line">    y_softmax = tf.nn.softmax(x_data) <span class="comment"># softmax is a special kind of activation function, it is about probablity</span></span><br><span class="line"></span><br><span class="line">    y_relu, y_sigmoid, y_tanh, y_softplus, y_softmax = sess.run([y_relu, y_sigmoid, y_tanh, y_softplus, y_softmax])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># plot</span></span><br><span class="line">    fig = plt.figure(<span class="number">1</span>, figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">    plt.plot(x_data, y_relu, c=<span class="string">'red'</span>, label=<span class="string">'relu'</span>)    </span><br><span class="line">    plt.plot(x_data, y_sigmoid, c=<span class="string">'green'</span>, label=<span class="string">'sigmoid'</span>)</span><br><span class="line">    plt.plot(x_data, y_tanh, c=<span class="string">'blue'</span>, label=<span class="string">'tanh'</span>)</span><br><span class="line">    plt.plot(x_data, y_softplus, c=<span class="string">'yellow'</span>, label=<span class="string">'softplus'</span>)</span><br><span class="line">    plt.xlim(<span class="number">-4</span>, <span class="number">4</span>)</span><br><span class="line">    plt.ylim(<span class="number">-1.2</span>, <span class="number">4</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># gca get current axes</span></span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    ax.spines[<span class="string">'right'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line">    ax.spines[<span class="string">'top'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line"></span><br><span class="line">    ax.xaxis.set_ticks_position(<span class="string">'bottom'</span>)</span><br><span class="line">    ax.yaxis.set_ticks_position(<span class="string">'left'</span>)</span><br><span class="line">    ax.spines[<span class="string">'bottom'</span>].set_position((<span class="string">'data'</span>, <span class="number">0</span>)) <span class="comment"># outward, axes</span></span><br><span class="line">    ax.spines[<span class="string">'left'</span>].set_position((<span class="string">'data'</span>, <span class="number">0</span>))</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2018/08/13/activation-function/output_2_0.png" alt="Activation Functions-2"></p>

			
		  
		</div>

		
		  

		

		<footer class="article-footer">
		  <a data-url="https://www.blankspace.cn/2018/08/13/activation-function/" data-id="cjktnrn9l000ekcfixlhk8avx" class="article-share-link">
			<i class="fa fa-share"></i> Share
		  </a>
		  
		  
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/Activation/">Activation</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/TensorFlow/">TensorFlow</a></li></ul>


		</footer>
	  </div>
	  
		
<ul id="article-nav" class="nav nav-pills nav-justified">
  
  <li role="presentation">
    <a href="../placeholder/" id="article-nav-older" class="article-nav-link-wrap">
      <i class="fa fa-chevron-left pull-left"></i>
      <span class="article-nav-link-title">Placeholder</span>
    </a>
  </li>
  
  
  <li role="presentation">
    <a href="../../14/MathJax-basic-tutorial/" id="article-nav-newer" class="article-nav-link-wrap">
      <span class="article-nav-link-title">MathJax basic tutorial and quick reference</span>
      <i class="fa fa-chevron-right pull-right"></i>
    </a>
  </li>
  
</ul>


	  
	</article>

	
	
		
			
	
		
		
			<!--Gitment:https://github.com/imsun/gitment or https://imsun.net/posts/gitment-introduction/-->
			<div id="container"></div>
			<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
			<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
			<script>
			var gitment = new Gitment({
			  id: 'Mon Aug 13 2018 21:24:57 GMT+0800', // 可选。默认为 location.href
			  owner: 'liuqidev',
			  repo: 'liuqidev.github.io',
			  oauth: {
				client_id: '9db4a7f39961fa7531cc',  
				client_secret: 'bd23ffc25530e831d3dc6efc731bb9de4d8c6fd0'
			  },
			})
			gitment.render('container')
			</script>
		
	



	
			

		
	




		


</div>



	
<footer class="blog-footer">  
  <div class="container">
		<div >
	 <ul id="links" class="nav navbar-nav" style="display: inline-block;float: none;">
		<li><a href="https://weibo.com/liuqidev" title="Find me on Weibo" target="_blank"><i class="iconfont">&#xe655;</i></a></li>
		<li><a href="https://www.zhihu.com/people/wizardlq/" title="Find me on Zhihu" target="_blank"><i class="iconfont">&#xe61b;</i></a></li>
		<li><a href="https://blog.csdn.net/icurious" title="Find me on CSDN" target="_blank"><i class="iconfont">&#xe64f;</i></a></li>
		<li><a href="https://www.douban.com/people/icurious/" title="My Douban" target="_blank"><i class="iconfont">&#xe601;</i></a></li>
		<li><a href="https://space.bilibili.com/20204877/#/" title="Find me on Bilibili" target="_blank"><i class="iconfont">&#xe6e1;</i></a></li>
		<li><a href="https://github.com/liuqidev" title="My Linkedin" target="_blank"><i class="fab fa-linkedin-square"></i></a></li>
		<li><a href="https://github.com/liuqidev" title="My Projects on Github" target="_blank"><i class="fab fa-github"></i></a></li>
		<li><a href="https://stackoverflow.com/users/9121113/qi-liu" title="My StackoverFlow" target="_blank"><i class="fab fa-stack-overflow"></i></a></li>
		
		
		  <li><a href="/atom.xml" title="RSS Feed"><i class="fa fa-rss" target="_blank"></i></a></li>
		
	  </ul>
	 </div>
    <div id="footer-info" class="text-center">
        &copy; 2018. <em>All Rights Reserved by <a href="https://github.com/liuqidev" target="_blank">liuqidev</a></em><br>	
	</div>
	<div > 

	  </links>
  </div>

  <p>
  	<span id="busuanzi_container_site_uv">
  	    <span id="busuanzi_value_site_uv"></span> visitors  |  
  	</span>

      <span id="busuanzi_container_site_pv">
         <span id="busuanzi_value_site_pv"></span> visits
      </span>
	  
  </p>
  

  
  <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
  <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=XzXyQ1GOPdnOuiMHQmBZKolTWTBtRkFzmBoniAwXpMc&cl=ffffff&w=a"></script>
  <!--mini map-->
  <div id="minimap">
  <!--<script type="text/javascript" src="//ra.revolvermaps.com/0/0/8.js?i=0107o8m66de&amp;m=7&amp;c=eeeeee&amp;cr1=fff600&amp;f=arial&amp;l=0&amp;v0=30&amp;z=13&amp;rx=30&amp;lx=380&amp;ly=200&amp;hc=0a65c2&amp;rs=40" async="async"></script>-->
  <script type="text/javascript" src="//ra.revolvermaps.com/0/0/7.js?i=04xsrcfj1ee&amp;m=0c&amp;c=c7bdbd&amp;cr1=fff600&amp;lo=25&amp;oo=15&amp;sx=44&amp;ds=30&amp;cw=f9f9f9&amp;cb=000000" async="async"></script>  </div>
  

  
   
	   <script type="text/javascript">     
		  var searchFunc = function(path, search_id, content_id) {
		'use strict'; //使用严格模式
		$.ajax({
			url: path,
			dataType: "xml",
			success: function( xmlResponse ) {
				// 从xml中获取相应的标题等数据
				var datas = $( "entry", xmlResponse ).map(function() {
					return {
						title: $( "title", this ).text(),
						content: $("content",this).text(),
						url: $( "url" , this).text()
					};
				}).get();
				//ID选择器
				var $input = document.getElementById(search_id);
				var $resultContent = document.getElementById(content_id);
				$input.addEventListener('input', function(){
					var str='<ul class=\"search-result-list\">';                
					var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
					$resultContent.innerHTML = "";
					if (this.value.trim().length <= 0) {
						return;
					}
					// 本地搜索主要部分
					datas.forEach(function(data) {
						var isMatch = true;
						var content_index = [];
						var data_title = data.title.trim().toLowerCase();
						var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
						var data_url = data.url;
						var index_title = -1;
						var index_content = -1;
						var first_occur = -1;
						// 只匹配非空文章
						if(data_title != '' && data_content != '') {
							keywords.forEach(function(keyword, i) {
								index_title = data_title.indexOf(keyword);
								index_content = data_content.indexOf(keyword);
								if( index_title < 0 && index_content < 0 ){
									isMatch = false;
								} else {
									if (index_content < 0) {
										index_content = 0;
									}
									if (i == 0) {
										first_occur = index_content;
									}
								}
							});
						}
						// 返回搜索结果
						if (isMatch) {
						//结果标签
							str += "<li><a href='"+ data_url +"' class='search-result-title' target='_blank'>"+ "> " + data_title +"</a>";
							var content = data.content.trim().replace(/<[^>]+>/g,"");
							if (first_occur >= 0) {
								// 拿出含有搜索字的部分
								var start = first_occur - 6;
								var end = first_occur + 6;
								if(start < 0){
									start = 0;
								}
								if(start == 0){
									end = 10;
								}
								if(end > content.length){
									end = content.length;
								}
								var match_content = content.substr(start, end); 
								// 列出搜索关键字，定义class加高亮
								keywords.forEach(function(keyword){
									var regS = new RegExp(keyword, "gi");
									match_content = match_content.replace(regS, "<em class=\"search-keyword\">"+keyword+"</em>");
								})
								str += "<p class=\"search-result\">" + match_content +"...</p>"
							}
						}
					})
					$resultContent.innerHTML = str;
				})
			}
		})
	};
	var path = "../search.xml";
	searchFunc(path, 'local-search-input', 'local-search-result');
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


</footer>


	

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>


  <link rel="stylesheet" href="../../../../fancybox/jquery.fancybox.css">
  <script src="../../../../fancybox/jquery.fancybox.pack.js"></script>


<script src="../../../../js/script.js"></script>




	


<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?70a761ba668ab8571ac79968adcf6078";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>








	
<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = 'Opps...●﹏●';
            clearTimeout(titleTime);
        } else {
            document.title = 'o(∩_∩)o Welcome!';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>


	 <!--Back to top-->
<body id="top">
<p id="back-to-top"><a href="#top"><span></span></a></p>
</body>

<script>
$(document).ready(function() {
    //首先将#back-to-top隐藏
    $("#back-to-top").hide();
 
    //当滚动条的位置处于距顶部3600像素以下时，跳转链接出现，否则消失
    $(function() {
        $(window).scroll(function() {
            if ($(window).scrollTop() > 3600) {
                $("#back-to-top").fadeIn(1500);
            }
            else {
                $("#back-to-top").fadeOut(1500);
            }
        });
        //当点击跳转链接后，回到页面顶部位置
        $("#back-to-top").click(function() {
            $('body,html').animate({
                scrollTop: 0
            },
            500);
			
            return false;
        });
    });
});
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!--<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
