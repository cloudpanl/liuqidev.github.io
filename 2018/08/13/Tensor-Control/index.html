<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Tensor Control | WizardLQ’s | 魔法师の小茶馆</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="张量形状形状shape，用来描述张量的大小和数量。张量的形状表示为列表的形式，其中第i个元素表示维度i的大小，列表的长度标书张量的阶（维数）。     阶 形状 维数 示例     0 [] 0-D 0 维张量。标量。   1 [D0] 1-D 形状为 [6] 的 1 维张量。   2 [D0, D1] 2-D 形状为 [4, 3] 的 2 维张量。   3 [D0, D1, D2] 3-D 形状">
<meta name="keywords" content="TensorFlow,Tensor">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensor Control">
<meta property="og:url" content="https://www.blankspace.cn/2018/08/13/Tensor-Control/index.html">
<meta property="og:site_name" content="WizardLQ’s | 魔法师の小茶馆">
<meta property="og:description" content="张量形状形状shape，用来描述张量的大小和数量。张量的形状表示为列表的形式，其中第i个元素表示维度i的大小，列表的长度标书张量的阶（维数）。     阶 形状 维数 示例     0 [] 0-D 0 维张量。标量。   1 [D0] 1-D 形状为 [6] 的 1 维张量。   2 [D0, D1] 2-D 形状为 [4, 3] 的 2 维张量。   3 [D0, D1, D2] 3-D 形状">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-08-13T09:46:18.331Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tensor Control">
<meta name="twitter:description" content="张量形状形状shape，用来描述张量的大小和数量。张量的形状表示为列表的形式，其中第i个元素表示维度i的大小，列表的长度标书张量的阶（维数）。     阶 形状 维数 示例     0 [] 0-D 0 维张量。标量。   1 [D0] 1-D 形状为 [6] 的 1 维张量。   2 [D0, D1] 2-D 形状为 [4, 3] 的 2 维张量。   3 [D0, D1, D2] 3-D 形状">
  
    <link rel="alternate" href="../../../../atom.xml" title="WizardLQ’s | 魔法师の小茶馆" type="application/atom+xml">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">

  <link rel="stylesheet" href="../../../../css/styles.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-inverse">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class=""
                 href="../../../../index.html">Home</a></li>
        
          <li><a class=""
                 href="../../../../archives/">Archives</a></li>
        
      </ul>

      <!--
      <ul class="nav navbar-nav navbar-right">
        
          <li><a href="/atom.xml" title="RSS Feed"><i class="fa fa-rss"></i></a></li>
        
      </ul>
      -->
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

  <div class="container">
    <div class="blog-header">
  <h1 class="blog-title">WizardLQ’s | 魔法师の小茶馆</h1>
  
    <p class="lead blog-description">Keep moving, never give up. | 锲而不舍，金石可镂.</p>
  
</div>

    <div class="row">
        <div class="col-sm-8 blog-main">
          <article id="post-Tensor-Control" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 class="article-title" itemprop="name">
      Tensor Control
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="" class="article-date"><time datetime="2018-08-13T02:06:14.000Z" itemprop="datePublished">2018-08-13</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="../../../../categories/Machine-Learning/">Machine Learning</a> / <a class="article-category-link" href="../../../../categories/Machine-Learning/TensorFlow/">TensorFlow</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="张量形状"><a href="#张量形状" class="headerlink" title="张量形状"></a>张量形状</h2><p>形状shape，用来描述张量的大小和数量。张量的形状表示为列表的形式，其中第i个元素表示维度i的大小，列表的长度标书张量的阶（维数）。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>阶</th>
<th>形状</th>
<th>维数</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>[]</td>
<td>0-D</td>
<td>0 维张量。标量。</td>
</tr>
<tr>
<td>1</td>
<td>[D0]</td>
<td>1-D</td>
<td>形状为 [6] 的 1 维张量。</td>
</tr>
<tr>
<td>2</td>
<td>[D0, D1]</td>
<td>2-D</td>
<td>形状为 [4, 3] 的 2 维张量。</td>
</tr>
<tr>
<td>3</td>
<td>[D0, D1, D2]</td>
<td>3-D</td>
<td>形状为 [1, 2, 3] 的 3 维张量。</td>
</tr>
<tr>
<td>n</td>
<td>[D0, D1, … Dn-1]</td>
<td>n 维</td>
<td>形状为 [D0, D1, … Dn-1] 的张量。</td>
</tr>
</tbody>
</table>
</div>
<p><a href="https://www.tensorflow.org/programmers_guide/tensors#shape" target="_blank" rel="noopener">文档</a>中介绍得更详细。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># show the shape of tensor</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">g = tf.Graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> g.as_default():</span><br><span class="line">    scalar = tf.ones([]) <span class="comment"># a scalar / 0-D tensor :1</span></span><br><span class="line">    vector = tf.ones([<span class="number">6</span>]) <span class="comment"># a vector with 6 elements: [1,1,1 ,1,1,1]</span></span><br><span class="line">    matrix = tf.ones([<span class="number">2</span>, <span class="number">3</span>]) <span class="comment"># a matrix with 2 rows and 3 columns</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment"># use tf.get_shape() </span></span><br><span class="line">        print(<span class="string">"Scalar shape: "</span>,scalar.get_shape(), <span class="string">" value: "</span>, sess.run(scalar))</span><br><span class="line">        print(<span class="string">"Vector shape: "</span>,vector.get_shape(), <span class="string">" value: "</span>, sess.run(vector))</span><br><span class="line">        print(<span class="string">"Matrix shape: "</span>,matrix.get_shape(), <span class="string">" value: "</span>, sess.run(matrix))</span><br></pre></td></tr></table></figure>
<pre><code>D:\Anaconda3\Anaconda3_py36\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters


Scalar shape:  ()  value:  1.0
Vector shape:  (6,)  value:  [1. 1. 1. 1. 1. 1.]
Matrix shape:  (2, 3)  value:  [[1. 1. 1.]
 [1. 1. 1.]]
</code></pre><h3 id="获取张量形状"><a href="#获取张量形状" class="headerlink" title="获取张量形状"></a>获取张量形状</h3><p>可以通过查看张量对象的<code>shape</code>属性来获取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vector.shape</span><br></pre></td></tr></table></figure>
<pre><code>TensorShape([Dimension(6)])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">matrix.shape[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<pre><code>Dimension(3)
</code></pre><h3 id="获取张量的数据类型"><a href="#获取张量的数据类型" class="headerlink" title="获取张量的数据类型"></a>获取张量的数据类型</h3><p>查看张量对象的<code>dtype</code>属性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">matrix.dtype</span><br></pre></td></tr></table></figure>
<pre><code>tf.float32
</code></pre><h3 id="改变张量数据类型"><a href="#改变张量数据类型" class="headerlink" title="改变张量数据类型"></a>改变张量数据类型</h3><p><code>tf.cast</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">c = tf.constant([<span class="number">1</span>,<span class="number">9</span>,<span class="number">8</span>,<span class="number">3</span>])</span><br><span class="line">print(c.dtype)</span><br><span class="line">f = tf.cast(c, dtype=tf.float32)</span><br><span class="line">print(f.dtype)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;dtype: &#39;int32&#39;&gt;
&lt;dtype: &#39;float32&#39;&gt;
</code></pre><h3 id="获取张量的阶"><a href="#获取张量的阶" class="headerlink" title="获取张量的阶"></a>获取张量的阶</h3><p><code>tf.rank()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.rank(scalar)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;tf.Tensor &#39;Rank:0&#39; shape=() dtype=int32&gt;
</code></pre><h3 id="张量切片"><a href="#张量切片" class="headerlink" title="张量切片"></a>张量切片</h3><p>对于n阶张量，要访问其中某一元素，需要制定n个索引。</p>
<p><code>:</code>是Python切片语法，也意味着<strong>不要变更该维度</strong>。可以帮助访问张量的子向量，子矩阵和子张量。</p>
<h2 id="Broadcasting-广播"><a href="#Broadcasting-广播" class="headerlink" title="Broadcasting | 广播"></a>Broadcasting | 广播</h2><p>tensorflow支持广播，借鉴了Numpy中的做法，<a href="https://docs.scipy.org/doc/numpy-1.10.1/user/basics.broadcasting.html" target="_blank" rel="noopener">Numpy Broadcasting</a>.</p>
<p>数学中，相同形状的张量才能进行元素级的运算，例如相加和等于。由于广播，使得不同形状的张量运算可以像对标量进行运算一样。</p>
<p>当张量被广播时，相当于对张量进行复制，实际上并不复制，广播专门为实现性能优化而设计。</p>
<p>举例，假设你和四个小伙伴，年龄分别为[18, 17, 20, 22, 21],每年年龄+1,模拟这个过程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 向量加法</span></span><br><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    <span class="comment"># method 1</span></span><br><span class="line">    ages = tf.constant([<span class="number">18</span>, <span class="number">17</span>, <span class="number">20</span>, <span class="number">22</span>, <span class="number">21</span>])</span><br><span class="line">    one = tf.constant([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    new_ages = tf.add(ages, one)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        print(new_ages.eval())</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># method 2</span></span><br><span class="line">    one_ = tf.constant(<span class="number">1</span>)</span><br><span class="line">    new_ages_ = tf.add(ages, one_)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        print(new_ages_.eval())</span><br></pre></td></tr></table></figure>
<pre><code>[19 18 21 23 22]
[19 18 21 23 22]
</code></pre><h3 id="张量变形"><a href="#张量变形" class="headerlink" title="张量变形"></a>张量变形</h3><p>可以使用<code>tf.reshape()</code>来改变张量的形状。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"></span><br><span class="line">arr = np.arange(<span class="number">1</span>, <span class="number">13</span>).reshape(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">np.random.shuffle(arr)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    x = tf.constant(arr, dtype=tf.int32) <span class="comment"># create a 3x4 matrix/ 2-D tensor</span></span><br><span class="line">    reshaped_4x3_x = tf.reshape(x, [<span class="number">4</span>, <span class="number">3</span>])</span><br><span class="line">    reshaped_2x6_x = tf.reshape(x, [<span class="number">2</span>, <span class="number">6</span>])</span><br><span class="line">    reshaped_3x2x2_x = tf.reshape(x, [<span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>]) <span class="comment"># reshape the rank </span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        print(<span class="string">"Original matrix (3x4):"</span>)</span><br><span class="line">        print(x.eval())</span><br><span class="line">        </span><br><span class="line">        print(<span class="string">"Reshaped matrix (4x3)"</span>)</span><br><span class="line">        print(reshaped_4x3_x.eval())</span><br><span class="line">        </span><br><span class="line">        print(<span class="string">"Reshaped matrix (2x6)"</span>)</span><br><span class="line">        print(reshaped_2x6_x.eval())</span><br><span class="line">        </span><br><span class="line">        print(<span class="string">"Reshaped matrix (3x2x2)"</span>)</span><br><span class="line">        print(reshaped_3x2x2_x.eval())</span><br></pre></td></tr></table></figure>
<pre><code>Original matrix (3x4):
[[ 9 10 11 12]
 [ 1  2  3  4]
 [ 5  6  7  8]]
Reshaped matrix (4x3)
[[ 9 10 11]
 [12  1  2]
 [ 3  4  5]
 [ 6  7  8]]
Reshaped matrix (2x6)
[[ 9 10 11 12  1  2]
 [ 3  4  5  6  7  8]]
Reshaped matrix (3x2x2)
[[[ 9 10]
  [11 12]]

 [[ 1  2]
  [ 3  4]]

 [[ 5  6]
  [ 7  8]]]
</code></pre><h2 id="变量、初始化和赋值"><a href="#变量、初始化和赋值" class="headerlink" title="变量、初始化和赋值"></a>变量、初始化和赋值</h2><p>TensorFlow变量初始化不是自动进行的，调用<code>tf.global_variables_initializer()</code>。不初始化就会报错。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    v = tf.Variable([<span class="number">3</span>])</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            sess.run(v)</span><br><span class="line">        <span class="keyword">except</span> tf.errors.FailedPreconditionError <span class="keyword">as</span> e:</span><br><span class="line">            print(<span class="string">"Caught excepted error: "</span>, e)</span><br></pre></td></tr></table></figure>
<pre><code>Caught excepted error:  Attempting to use uninitialized value Variable
     [[Node: _retval_Variable_0_0 = _Retval[T=DT_INT32, index=0, _device=&quot;/job:localhost/replica:0/task:0/device:CPU:0&quot;](Variable)]]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    v = tf.Variable([<span class="number">3</span>])</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        init = tf.global_variables_initializer()</span><br><span class="line">        sess.run(init)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            print(sess.run(v))</span><br><span class="line">        <span class="keyword">except</span> tf.errors.FailedPreconditionError <span class="keyword">as</span> e:</span><br><span class="line">            print(<span class="string">"Caught excepted error: "</span>, e)</span><br></pre></td></tr></table></figure>
<pre><code>[3]
</code></pre><h3 id="assign"><a href="#assign" class="headerlink" title="assign"></a>assign</h3><p>要变更变量的值，使用<code>tf.assign()</code>指令，仅仅创建assign指令也不能起作用。和初始化一样，也需要运行赋值指令才能变更变量值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    v = tf.Variable([<span class="number">3</span>])</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        init = tf.global_variables_initializer()</span><br><span class="line">        sess.run(init)</span><br><span class="line">        assignment = tf.assign(v, [<span class="number">9</span>])</span><br><span class="line">        print(v.eval()) <span class="comment"># the variable has not been changed yet.</span></span><br><span class="line">        sess.run(assignment)</span><br><span class="line">        print(v.eval()) <span class="comment"># now the variable is updated</span></span><br></pre></td></tr></table></figure>
<pre><code>[3]
[9]
</code></pre><h3 id="评估张量"><a href="#评估张量" class="headerlink" title="评估张量"></a>评估张量</h3><p><code>eval()</code>。<br>方法仅在默认 tf.Session 处于活动状态时才起作用。<code>Tensor.eval()</code>会返回一个和张量内容相同的Numpy数组。</p>
<p>仅仅只有占位符的情况下无法进行评估。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    p = tf.placeholder(tf.float32)</span><br><span class="line">    t = p+<span class="number">1.0</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment"># t.eval() # this will fail, since the placeholder did not give a value</span></span><br><span class="line">        print(t.eval(feed_dict=&#123;p:<span class="number">23.3</span>&#125;) )<span class="comment"># this will success, because a value is fed to the placeholder</span></span><br></pre></td></tr></table></figure>
<pre><code>24.3
</code></pre><h2 id="举例：模拟投掷两个骰子10次"><a href="#举例：模拟投掷两个骰子10次" class="headerlink" title="举例：模拟投掷两个骰子10次"></a>举例：模拟投掷两个骰子10次</h2><p>素材来自<a href="https://colab.research.google.com/notebooks/mlcc/creating_and_manipulating_tensors.ipynb?hl=zh-cn#scrollTo=iFIOcnfz_Oqw" target="_blank" rel="noopener">这里</a>.</p>
<p>模拟<a href="https://book.douban.com/subject/1082154/" target="_blank" rel="noopener">《活着》</a>中富贵儿赌钱投骰子（6个面，点数从1到6）的过程，在模拟中生成一个 <code>10x4</code> 二维张量，其中：</p>
<ul>
<li>列 <code>1</code> 和 <code>2</code> 均存储一个骰子的一次投掷值。</li>
<li>列 <code>3</code> 存储同一行中列 <code>1</code> 和 <code>2</code> 的值的总和。</li>
<li>列 <code>4</code> 表示开大开小，若列 <code>3</code> 点数大于7，开大（如用1表示）；小于等于7开小（如用0表示）。</li>
</ul>
<p>例如，第一行中可能会包含以下值：</p>
<ul>
<li>列 <code>1</code> 存储 <code>4</code></li>
<li>列 <code>2</code> 存储 <code>3</code></li>
<li>列 <code>3</code> 存储 <code>7</code></li>
<li>列 <code>4</code> 存储 <code>0</code></li>
</ul>
<p>要完成此任务，可能需要浏览 <a href="https://www.tensorflow.org/api_guides/python/array_ops" target="_blank" rel="noopener">TensorFlow 文档</a>。</p>
<p><strong>问题</strong>：<br><em>如何随机并分配值给变量？（TensorFlow不支持动态计算图）</em><br><em>如何赋值十次，循环？最后张量结果如何表示？</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import numpy as np</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">g = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g.as_default():</span><br><span class="line">    <span class="comment"># 使用随机均匀分布 tf.random_uniform 来模拟投掷 n 次, 不需要循环。</span></span><br><span class="line">    dice1 = tf.Variable(tf.random_uniform([<span class="number">10</span>, <span class="number">1</span>],</span><br><span class="line">                                         minval=<span class="number">1</span>,</span><br><span class="line">                                         maxval=<span class="number">7</span>,</span><br><span class="line">                                         dtype=tf.int32))</span><br><span class="line">    </span><br><span class="line">    dice2 = tf.Variable(tf.random_uniform([<span class="number">10</span>, <span class="number">1</span>],</span><br><span class="line">                                         minval=<span class="number">1</span>, </span><br><span class="line">                                         maxval=<span class="number">7</span>, </span><br><span class="line">                                         dtype=tf.int32))</span><br><span class="line">    </span><br><span class="line">    dice_sum = tf.add(dice1, dice2)</span><br><span class="line">    </span><br><span class="line">    seven = tf.constant(<span class="number">7</span>)</span><br><span class="line">    <span class="comment"># 关于TensorFlow条件控制</span></span><br><span class="line">    <span class="comment"># https://www.tensorflow.org/versions/r1.8/api_guides/python/control_flow_ops#Control_Flow_Operations</span></span><br><span class="line">    comp = tf.cast(tf.greater(dice_sum, seven), tf.int32)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用 tf.concat 连接向量，axis=1 水平方向连接</span></span><br><span class="line">    result = tf.concat(values=[dice1, dice2, dice_sum, comp], axis=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        </span><br><span class="line">        print(result.eval())</span><br></pre></td></tr></table></figure>
<pre><code>[[ 4  4  8  1]
 [ 6  1  7  0]
 [ 5  6 11  1]
 [ 4  2  6  0]
 [ 4  1  5  0]
 [ 5  3  8  1]
 [ 6  2  8  1]
 [ 4  2  6  0]
 [ 4  6 10  1]
 [ 1  3  4  0]]
</code></pre>
      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="https://www.blankspace.cn/2018/08/13/Tensor-Control/" data-id="cjktonkq4000omofiozsdsby3" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/Tensor/">Tensor</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/TensorFlow/">TensorFlow</a></li></ul>


    </footer>
  </div>
  
    
<ul id="article-nav" class="nav nav-pills nav-justified">
  
  <li role="presentation">
    <a href="../Tensor/" id="article-nav-older" class="article-nav-link-wrap">
      <i class="fa fa-chevron-left pull-left"></i>
      <span class="article-nav-link-title">Tensor</span>
    </a>
  </li>
  
  
  <li role="presentation">
    <a href="../placeholder/" id="article-nav-newer" class="article-nav-link-wrap">
      <span class="article-nav-link-title">Placeholder</span>
      <i class="fa fa-chevron-right pull-right"></i>
    </a>
  </li>
  
</ul>


  
</article>




        </div>
        <div class="col-sm-3 col-sm-offset-1 blog-sidebar">
          
  <div class="sidebar-module sidebar-module-inset">
  <h4>About</h4>
  <p>Etiam porta <em>sem malesuada magna</em> mollis euismod. Cras mattis consectetur purus sit amet fermentum. Aenean lacinia bibendum nulla sed consectetur.</p>

</div>


  
  <div class="sidebar-module">
    <h4>Categories</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../categories/Languages/">Languages</a><span class="sidebar-module-list-count">1</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../categories/Languages/Python/">Python</a><span class="sidebar-module-list-count">1</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../categories/Languages/Python/Numpy/">Numpy</a><span class="sidebar-module-list-count">1</span></li></ul></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../categories/Machine-Learning/">Machine Learning</a><span class="sidebar-module-list-count">8</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../categories/Machine-Learning/TensorFlow/">TensorFlow</a><span class="sidebar-module-list-count">8</span></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../categories/Math/">Math</a><span class="sidebar-module-list-count">1</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../categories/Math/MathJax/">MathJax</a><span class="sidebar-module-list-count">1</span></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../categories/Projects/">Projects</a><span class="sidebar-module-list-count">19</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../categories/Projects/hexo-theme-bootstrap-blog/">hexo-theme-bootstrap-blog</a><span class="sidebar-module-list-count">19</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../categories/Projects/hexo-theme-bootstrap-blog/Tutorial/">Tutorial</a><span class="sidebar-module-list-count">19</span></li></ul></li></ul></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Tags</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/Activation/">Activation</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/Code/">Code</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/Elements/">Elements</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/Emoji/">Emoji</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/Hexo/">Hexo</a><span class="sidebar-module-list-count">13</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/Images/">Images</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/MathJax/">MathJax</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/Numpy/">Numpy</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/Photos/">Photos</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/TeX/">TeX</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/Tensor/">Tensor</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/TensorFlow/">TensorFlow</a><span class="sidebar-module-list-count">8</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/Theme/">Theme</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/mnist/">mnist</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/placeholder/">placeholder</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../tags/random/">random</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Tag Cloud</h4>
    <p class="tagcloud">
      <a href="../../../../tags/Activation/" style="font-size: 10px;">Activation</a> <a href="../../../../tags/Code/" style="font-size: 10px;">Code</a> <a href="../../../../tags/Elements/" style="font-size: 10px;">Elements</a> <a href="../../../../tags/Emoji/" style="font-size: 10px;">Emoji</a> <a href="../../../../tags/Hexo/" style="font-size: 20px;">Hexo</a> <a href="../../../../tags/Images/" style="font-size: 10px;">Images</a> <a href="../../../../tags/MathJax/" style="font-size: 10px;">MathJax</a> <a href="../../../../tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="../../../../tags/Photos/" style="font-size: 10px;">Photos</a> <a href="../../../../tags/TeX/" style="font-size: 10px;">TeX</a> <a href="../../../../tags/Tensor/" style="font-size: 13.33px;">Tensor</a> <a href="../../../../tags/TensorFlow/" style="font-size: 16.67px;">TensorFlow</a> <a href="../../../../tags/Theme/" style="font-size: 10px;">Theme</a> <a href="../../../../tags/mnist/" style="font-size: 13.33px;">mnist</a> <a href="../../../../tags/placeholder/" style="font-size: 10px;">placeholder</a> <a href="../../../../tags/random/" style="font-size: 10px;">random</a>
    </p>
  </div>


  
  <div class="sidebar-module">
    <h4>Archives</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../archives/2018/08/">八月 2018</a><span class="sidebar-module-list-count">28</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="../../../../archives/2013/12/">十二月 2013</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Recents</h4>
    <ul class="sidebar-module-list">
      
        <li>
          <a href="../../14/MathJax-basic-tutorial/">MathJax basic tutorial and quick reference</a>
        </li>
      
        <li>
          <a href="../activation-function/">Activation function</a>
        </li>
      
        <li>
          <a href="../placeholder/">Placeholder</a>
        </li>
      
        <li>
          <a href="">Tensor Control</a>
        </li>
      
        <li>
          <a href="../Tensor/">Tensor</a>
        </li>
      
    </ul>
  </div>



        </div>
    </div>
  </div>
  <footer class="blog-footer">
  <div class="container">
    <div id="footer-info" class="inner">
      &copy; 2018 liuqidev<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

  

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>



<script src="../../../../js/script.js"></script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!--<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>
