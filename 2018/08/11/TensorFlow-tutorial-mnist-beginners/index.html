<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>TensorFlow tutorial mnist beginners | WizardLQ’s | 魔法师の小茶馆</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="从示例开始导入12import tensorflow as tfimport numpy as np # 和tf配合使用 D:\Anaconda3\Anaconda3_py36\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `flo">
<meta name="keywords" content="mnist,TensorFlow">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow tutorial mnist beginners">
<meta property="og:url" content="https://www.blankspace.cn/2018/08/11/TensorFlow-tutorial-mnist-beginners/index.html">
<meta property="og:site_name" content="WizardLQ’s | 魔法师の小茶馆">
<meta property="og:description" content="从示例开始导入12import tensorflow as tfimport numpy as np # 和tf配合使用 D:\Anaconda3\Anaconda3_py36\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `flo">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://www.tensorfly.cn/tfdoc/images/MNIST-Matrix.png">
<meta property="og:image" content="http://www.tensorfly.cn/tfdoc/images/mnist-train-xs.png">
<meta property="og:image" content="http://www.tensorfly.cn/tfdoc/images/mnist-train-ys.png">
<meta property="og:image" content="http://www.tensorfly.cn/tfdoc/images/mnist6.png">
<meta property="og:image" content="http://www.tensorfly.cn/tfdoc/images/softmax-regression-scalargraph.png">
<meta property="og:image" content="http://www.tensorfly.cn/tfdoc/images/mnist7.png">
<meta property="og:image" content="http://www.tensorfly.cn/tfdoc/images/mnist10.png">
<meta property="og:updated_time" content="2018-08-12T02:12:56.707Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorFlow tutorial mnist beginners">
<meta name="twitter:description" content="从示例开始导入12import tensorflow as tfimport numpy as np # 和tf配合使用 D:\Anaconda3\Anaconda3_py36\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `flo">
<meta name="twitter:image" content="http://www.tensorfly.cn/tfdoc/images/MNIST-Matrix.png">
<link rel="publisher" href="112373242775367340000">
  
    <link rel="alternate" href="/atom.xml" title="WizardLQ’s | 魔法师の小茶馆" type="application/atom+xml">
  
  
    <link rel="icon" href="/images/icon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
<!--
<link href="https://cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet"><link href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet">
-->
<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
<!--
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.slim.min.js"></script>
-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.slim.min.js"></script>

<!--
<script src="https://cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
-->
<!-- 最新的 Bootstrap 核心 JavaScript 文件 -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script type="text/javascript" src="//ajax.aspnetcdn.com/ajax/jQuery/jquery-2.0.3.min.js"></script>

<link rel="stylesheet" href="/css/styles.css">

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>
<!--
<script src="https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>


</head>

<body>

	

	
	<div class="container">
	<div class="article-wrapper">


<article id="post-TensorFlow-tutorial-mnist-beginners" class="article article-type-post" itemscope itemprop="blogPost">
	


<header class="article-header">

  
    <h1 class="article-title" itemprop="name">
      TensorFlow tutorial mnist beginners
    </h1>
  


	

 
	
	</hr>
	<div class="article-datetime">
	  <time datetime="2018-08-11T09:25:06.000Z" itemprop="datePublished">2018-08-11</time>
	</div>
	<div class="header-divider"></div>	

	   

</header>

<div class="article-inner">
<div class="article-entry" itemprop="articleBody">
  
  
	<!-- Table of Contents -->

	
	
	<h1 id="从示例开始"><a href="#从示例开始" class="headerlink" title="从示例开始"></a>从示例开始</h1><h3 id="导入"><a href="#导入" class="headerlink" title="导入"></a>导入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># 和tf配合使用</span></span><br></pre></td></tr></table></figure>
<pre><code>D:\Anaconda3\Anaconda3_py36\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
</code></pre><h3 id="构造线性模型"><a href="#构造线性模型" class="headerlink" title="构造线性模型"></a>构造线性模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generate phony data | 生成假数据</span></span><br><span class="line"><span class="comment"># 实际应用应该是面对真实的数据</span></span><br><span class="line"><span class="comment"># 100个点，（2x100）</span></span><br><span class="line">x_data = np.float32(np.random.rand(<span class="number">2</span>, <span class="number">100</span>))</span><br><span class="line">y_data = np.dot([<span class="number">0.100</span>, <span class="number">0.200</span>], x_data)+<span class="number">0.300</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造线性模型</span></span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">1</span>])) <span class="comment"># tensor of shape 1</span></span><br><span class="line">W = tf.Variable(tf.random_uniform([<span class="number">1</span>, <span class="number">2</span>], minval=<span class="number">-0.1</span>, maxval=<span class="number">1.0</span>)) <span class="comment"># tensor of shape 1x2 whose values are from a uniform distribution </span></span><br><span class="line"><span class="comment"># in the range of [minval, maxval)</span></span><br><span class="line">y = tf.matmul(W, x_data)+b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最小化方差</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(y-y_data))</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化变量</span></span><br><span class="line"><span class="comment"># init = tf.initialize_all_variables()</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动计算图(graph)</span></span><br><span class="line">sess = tf.Session() <span class="comment"># 创建会话</span></span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拟合平面</span></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">201</span>):</span><br><span class="line">    sess.run(train)</span><br><span class="line">    <span class="keyword">if</span> step%<span class="number">20</span>==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"Step: "</span>, step, <span class="string">" W= "</span>,sess.run(W), <span class="string">" b= "</span>, sess.run(b))</span><br></pre></td></tr></table></figure>
<pre><code>Step:  0  W=  [[0.4871506  0.41139394]]  b=  [-0.09778017]
Step:  20  W=  [[0.22539519 0.34252512]]  b=  [0.15573283]
Step:  40  W=  [[0.14763923 0.26675704]]  b=  [0.23892412]
Step:  60  W=  [[0.11975352 0.22945689]]  b=  [0.2737922]
Step:  80  W=  [[0.10842387 0.21279107]]  b=  [0.2887098]
Step:  100  W=  [[0.10362242 0.20552918]]  b=  [0.2951307]
Step:  120  W=  [[0.10156146 0.20238699]]  b=  [0.29789925]
Step:  140  W=  [[0.10067356 0.2010301 ]]  b=  [0.2990936]
Step:  160  W=  [[0.10029061 0.20044449]]  b=  [0.29960892]
Step:  180  W=  [[0.10012538 0.20019177]]  b=  [0.29983127]
Step:  200  W=  [[0.10005409 0.20008272]]  b=  [0.2999272]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭会话</span></span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure>
<h2 id="MNIST机器学习入门"><a href="#MNIST机器学习入门" class="headerlink" title="MNIST机器学习入门"></a>MNIST机器学习入门</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># http://yann.lecun.com/exdb/mnist/  to download mnist dataset</span></span><br><span class="line"><span class="comment"># https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/input_data.py</span></span><br><span class="line"><span class="comment"># to read dataset</span></span><br><span class="line"><span class="keyword">from</span> load_mnist <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow.examples.tutorials.mnist.input_data <span class="keyword">as</span> input_data</span><br><span class="line">minst_dir = <span class="string">"MNIST_data/"</span></span><br><span class="line">mnist = input_data.read_data_sets(minst_dir, one_hot=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From D:\Anaconda3\Anaconda3_py36\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
</code></pre><p>下载下来的数据集被分成两部分：60000行的训练数据集（mnist.train）和10000行的测试数据集（mnist.test）.</p>
<p>每一个MNIST数据单元有两部分组成：一张包含手写数字的图片和一个对应的标签。我们把这些图片设为“xs”，把这些标签设为“ys”。训练数据集和测试数据集都包含xs和ys，比如训练数据集的图片是 mnist.train.images ，训练数据集的标签是 mnist.train.labels.</p>
<p>每一张图片包含28像素X28像素。我们可以用一个数字数组来表示这张图片：<br><img src="http://www.tensorfly.cn/tfdoc/images/MNIST-Matrix.png" alt=""></p>
<p>我们把这个数组展开成一个向量，长度是 28x28 = 784。如何展开这个数组（数字间的顺序）不重要，只要保持各个图片采用相同的方式展开。从这个角度来看，MNIST数据集的图片就是在784维向量空间里面的点, 并且拥有比较复杂的结构 (提醒: 此类数据的可视化是计算密集型的)。</p>
<p>在MNIST训练数据集中，mnist.train.images 是一个形状为 <code>[60000, 784]</code>的张量，第一个维度数字用来索引图片，第二个维度数字用来索引每张图片中的像素点。在此张量里的每一个元素，都表示某张图片里的某个像素的强度值，值介于0和1之间。<br><img src="http://www.tensorfly.cn/tfdoc/images/mnist-train-xs.png" alt=""></p>
<p>相对应的MNIST数据集的标签是介于0到9的数字，用来描述给定图片里表示的数字。为了用于这个教程，我们使标签数据是”one-hot vectors”。 一个one-hot向量除了某一位的数字是1以外其余各维度数字都是0。所以在此教程中，数字n将表示成一个只有在第n维度（从0开始）数字为1的10维向量。比如，标签0将表示成(<code>[1,0,0,0,0,0,0,0,0,0,0])</code>。因此， mnist.train.labels 是一个<code>[60000, 10]</code>的数字矩阵。<br><img src="http://www.tensorfly.cn/tfdoc/images/mnist-train-ys.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># x represent the input</span></span><br><span class="line"><span class="comment"># None means number of images is adaptable</span></span><br><span class="line"><span class="comment"># a 28x28 image is flatten to a vector of 784</span></span><br><span class="line">x = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>, <span class="number">784</span>])</span><br><span class="line"></span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>, <span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br></pre></td></tr></table></figure>
<h3 id="Softmax-regression"><a href="#Softmax-regression" class="headerlink" title="Softmax regression"></a>Softmax regression</h3><p>关于Softmax可以阅读<a href="http://www.tensorfly.cn/tfdoc/tutorials/mnist_beginners.html" target="_blank" rel="noopener">这篇</a>或者<a href="http://neuralnetworksanddeeplearning.com/chap3.html" target="_blank" rel="noopener">这篇</a>.</p>
<p><img src="http://www.tensorfly.cn/tfdoc/images/mnist6.png" alt=""></p>
<p>整个回归模型：<br><img src="http://www.tensorfly.cn/tfdoc/images/softmax-regression-scalargraph.png" alt=""><br><img src="http://www.tensorfly.cn/tfdoc/images/mnist7.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># softmax</span></span><br><span class="line">y = tf.nn.softmax(tf.matmul(x, W)+b)</span><br></pre></td></tr></table></figure>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>使用交叉熵损失函数，更多介绍看<a href="https://colah.github.io/posts/2015-09-Visual-Information/" target="_blank" rel="noopener">这篇</a>.<br><img src="http://www.tensorfly.cn/tfdoc/images/mnist10.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_ = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意，这里的交叉熵不仅仅用来衡量单一的一对预测和真实值，而是所有100幅图片的交叉熵的总和</span></span><br><span class="line">cross_entropy = -tf.reduce_sum(y_*tf.log(y))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># gradient descent and backprapagation</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cross_entropy)</span><br></pre></td></tr></table></figure>
<p>更多优化算法点击<a href="http://www.tensorfly.cn/tfdoc/api_docs/python/train.html#optimizers" target="_blank" rel="noopener">这里</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># init graph</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1001</span>):</span><br><span class="line">        batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">        feed_dict =&#123;x: batch_xs, y_:batch_ys&#125;</span><br><span class="line">        sess.run(train_step, feed_dict)</span><br></pre></td></tr></table></figure>
<h3 id="评估我们的模型"><a href="#评估我们的模型" class="headerlink" title="评估我们的模型"></a>评估我们的模型</h3><p>tf.argmax 是一个非常有用的函数，它能给出某个tensor对象在某一维上的其数据最大值所在的索引值。由于标签向量是由0,1组成，因此最大值1所在的索引位置就是类别标签，比如tf.argmax(y,1)返回的是模型对于任一输入x预测到的标签值，而 tf.argmax(y_,1) 代表正确的标签，我们可以用 tf.equal 来检测我们的预测是否真实标签匹配(索引位置一样表示匹配)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1001</span>):</span><br><span class="line">        batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">        feed_dict =&#123;x: batch_xs, y_:batch_ys&#125;</span><br><span class="line">        sess.run(train_step, feed_dict)</span><br><span class="line">        <span class="keyword">if</span> step%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">            accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">            print(step, <span class="string">" train acc: "</span>, sess.run(accuracy, feed_dict))</span><br></pre></td></tr></table></figure>
<pre><code>0  train acc:  0.48
100  train acc:  0.94
200  train acc:  0.96
300  train acc:  0.93
400  train acc:  0.93
500  train acc:  0.89
600  train acc:  0.96
700  train acc:  0.94
800  train acc:  0.94
900  train acc:  0.95
1000  train acc:  0.98
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1001</span>):</span><br><span class="line">        batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">        feed_dict =&#123;x: batch_xs, y_:batch_ys&#125;</span><br><span class="line">        sess.run(train_step, feed_dict)</span><br><span class="line"><span class="comment">#         if step%100==0:</span></span><br><span class="line"><span class="comment">#             correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))</span></span><br><span class="line"><span class="comment">#             accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))</span></span><br><span class="line"><span class="comment">#             print(step, " train acc: ", sess.run(accuracy, feed_dict))</span></span><br><span class="line"><span class="comment">#   # for test set</span></span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">    print(<span class="string">"Test acc:"</span>, sess.run(accuracy, feed_dict=&#123;x:mnist.test.images, y_:mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure>
<pre><code>Test acc: 0.9138
</code></pre><p>更多内容<a href="https://www.tensorflow.org/tutorials/" target="_blank" rel="noopener">https://www.tensorflow.org/tutorials/</a></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文首先通过一个完整的线性回归的例子，展示了TensorFlow的基本使用，首先构造计算图graph，其中包含诸如<code>Variable</code>、<code>placeholder</code>等节点，以及节点之间的数学运算如矩阵乘法；接着对计算图初始化，<code>tf.global_variables_initializer()</code>，其中TensorFlow中很重要的就是回话session机制，通过会话来运行计算图；随后，通过会话进行训练，拟合并德大检测结果。</p>
<p>其次，使用TensorFlow完成了基于MNIST数据集，进行手写体识别的任务，并在测试集上实现了91%的正确率。<br>其完整过程，首先是准备数据，下载的数据被分为训练数据和测试数据。每种数据的基本单元都包含两部分，一部分是手写体图片，统一规格28x28，另一部分是对应的标记，来指出对应的数字，将原始图片展开向量表示，标记采用one-hot表示；<br>接着，构建softmax回归模型。使用梯度下降算法进行反向传播，最小化交叉熵损失进行训练。<br>最后，在测试机上测试，得到实验正确率指标，可以达到91%以上。</p>

	
  
</div>


  




</div>

</article>




	</div><!--end of article wrapper-->
	</div>






	


<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?70a761ba668ab8571ac79968adcf6078";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>









<!--
<script src="https://cdn.bootcss.com/jquery/2.1.4/jquery.min.js"></script>
-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>

  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>

<script src="/js/script.js"></script>

<!--Back to top-->
<body id="top">
<p id="back-to-top"><a href="#top"><span></span></a></p>
</body>


<script>
$(document).ready(function() {
    //首先将#back-to-top隐藏
    $("#back-to-top").hide();
 
    //当滚动条的位置处于距顶部3600像素以下时，跳转链接出现，否则消失
    $(function() {
        $(window).scroll(function() {
            if ($(window).scrollTop() > 3600) {
                $("#back-to-top").fadeIn(1500);
            }
            else {
                $("#back-to-top").fadeOut(1500);
            }
        });
        //当点击跳转链接后，回到页面顶部位置
        $("#back-to-top").click(function() {
            $('body,html').animate({
                scrollTop: 0
            },
            500);
			
            return false;
        });
    });
});
</script>


  <script src="/js/languages.js"></script>
  <script src="/js/calendar.js"></script>
  <script type="text/javascript">
  $(function() {
    $('#calendar').aCalendar('en', $.extend({"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"],"postsMonthTip":"Posts published in LMM yyyy","titleFormat":"yyyy LMM","titleLinkFormat":"/archives/yyyy/MM/","headArrows":{"previous":"<span class=\"cal-prev\"></span>","next":"<span class=\"cal-next\"></span>"},"footArrows":{"previous":" ","next":" "},"weekOffset":0,"single":false,"root":"/calendar/","url":"/calendar.json"}, {single:true, root:'calendar/'}));
  });
  </script>




</body>
</html>
