<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>WizardLQ’s | 魔法师の小茶馆</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="远不止魔法......">
<meta name="keywords" content="Blog">
<meta property="og:type" content="website">
<meta property="og:title" content="WizardLQ’s | 魔法师の小茶馆">
<meta property="og:url" content="https://www.blankspace.cn/index.html">
<meta property="og:site_name" content="WizardLQ’s | 魔法师の小茶馆">
<meta property="og:description" content="远不止魔法......">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="WizardLQ’s | 魔法师の小茶馆">
<meta name="twitter:description" content="远不止魔法......">
<link rel="publisher" href="112373242775367340000">
  
    <link rel="alternate" href="/atom.xml" title="WizardLQ’s | 魔法师の小茶馆" type="application/atom+xml">
  
  
    <link rel="icon" href="images/icon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
<link href="https://cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet"><link href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet">
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.slim.min.js"></script><script src="https://cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<link rel="stylesheet" href="css/styles.css">

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script src="https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body>

	<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="bg bg-blur"></div>
<nav class="navbar navbar-inverse navbar-fixed-top">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
    </div>
	

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class="active"
                 href="">Home</a></li>
        
          <li><a class=""
                 href="archives/">Archives</a></li>
        
          <li><a class=""
                 href="categories/">Categories</a></li>
        
          <li><a class=""
                 href="about/">About</a></li>
        

      </ul>
		


    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
  

</nav>


<div class="container">

<div class="blog-header">
 <h1 class="blog-title">WizardLQ’s | 魔法师の小茶馆</h1>
  
    <p class="lead blog-description">Keep moving, never give up. | 锲而不舍，金石可镂.</p>
  
</div>



<div class="row">
    <div class="col-sm-9 blog-main">
	
	
	  
		<article id="post-MathJax-basic-tutorial" class="article article-type-post" itemscope itemprop="blogPost">
	


<header class="article-header">

  
    <h1 itemprop="name">
      <a class="article-title" href="2018/08/14/MathJax-basic-tutorial/">MathJax basic tutorial and quick reference</a>
    </h1>
  


	

		<div class="article-meta"> 
			
	  
		   <div class="article-datetime">
  <a href="2018/08/14/MathJax-basic-tutorial/" class="article-date"><time datetime="2018-08-13T23:46:53.000Z" itemprop="datePublished">2018-08-14</time></a>
</div>



			
			  
			

 
			
  <div class="article-category">
    <a class="article-category-link" href="categories/Math/">Math</a> / <a class="article-category-link" href="categories/Math/MathJax/">MathJax</a>
  </div>


	    </div>
	   

</header>

<div class="article-inner">
<div class="article-entry" itemprop="articleBody">
  
	<p>更多内容，请看<a href="https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference?page=2&amp;tab=votes#tab-top" target="_blank" rel="noopener">这里</a>.本文是本人对其中部分的翻译，若有疏漏，还请联系作者更正。</p>
<p>(德语版本: <a href="https://www.mathelounge.de/509545/mathjax-latex-basic-tutorial-und-referenz-deutsch" target="_blank" rel="noopener">Deutsch: MathJax: LaTeX Basic Tutorial und Referenz</a>)</p>
<h2 id="基础部分"><a href="#基础部分" class="headerlink" title="基础部分"></a>基础部分</h2><ol>
<li><p><strong>对于行内公式，使用<code>$...$</code>括起来。对于整行显示公式，使用<code>$$...$$</code>括起来。</strong></p>
<p>比方说，键入<code>$\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}$</code>可以在一行内嵌入公式$\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}$ （这就是inline模式了），或者我们键入<code>$$\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}$$</code>就可以显示：</p>
<script type="math/tex; mode=display">
\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}</script><p>（这就是display模式了）。</p>
</li>
<li><p>对于<strong>希腊字母</strong>，使用诸如<code>\alpha</code>, <code>\beta</code>, …, <code>\omega</code> :$\alpha, \beta, …, \omega$.大写希腊字母，使用诸如<code>\Gamma</code>, <code>\Delta</code>, …, <code>\Omega</code>:  $\Gamma, \Delta, …, \Omega$.</p>
</li>
<li><p>对于<strong>上标还有下标</strong>，使用<code>^</code>和<code>_</code>.比如<code>x_i^2</code>:$x_i^2 $,<code>\log_2 x</code>:$\log_2 x$.</p>
</li>
<li><p><strong>组（Group）</strong>.被一对<code>{</code>…<code>}</code>包裹的部分就是一个组，里面可以是一个单一的字符，也可以是一串公式。比如输入<code>10^10</code>,得到的是$10^10$,而不是我们想要的<code>10^{10}</code>:$10^{10}$.使用花括号来对公式进行划界，否则例如:<code>x^5^6</code>就是一种错误的表示。<code>{x^y}^z</code>得到${x^y}^z$,而<code>x^{y^z}</code>得到$x^{y^z}$.还有比方说<code>x_i^2</code>:$x_i^2$,而<code>x_{i^2}</code>:$x_{i^2}$.</p>
</li>
<li><p><strong>括号</strong>。普通<code>()[]</code>分别生成圆括号和方括号。使用<code>\{</code>和<code>\}</code>来生成花括号：$\{ \}$.但是这样的括号并不能随着内部公式的高度来调整，所以写<code>(\frac{\sqrt x}{y^3})</code>时括号就显得有点装不下了$(\frac{\sqrt{x}}{y^3})$.使用<code>\left(</code>和<code>\right)</code>能使得括号根据括起来的公式自动调整<code>\left( \frac{\sqrt x)}{y^3} \right)</code>:$\left( \frac{\sqrt x}{y^3} \right)$.</p>
<p><code>\left</code>和<code>\right</code>可以应用于下列括号：<code>(</code>和<code>)</code>$\left(x \right)$, <code>[</code>和<code>]</code>$\left[ x \right]$. <code>\{</code>和<code>\}</code>，如<code>\left\{x\right\}</code>, $\left\{x\right\}$. <code>|</code>如<code>\left| x \right|</code>$\left| x \right|$, <code>\vert</code>$\left\vert x \right\vert$,<code>\Vert</code>$\left\Vert x \right\Vert$, <code>\langle</code>和<code>\rangle</code>$\left\langle x \right\rangle$, <code>\lcei;</code>和<code>\rceil</code>$\left\lceil x \right\rceil$, <code>\lfloor</code>和<code>\rfloor</code>$\left\lfloor x \right\rfloor$, <code>\middle</code>可以用了增加额外的分界。此外有隐藏括号，用<code>.</code>来标记: <code>\left.\frac12\right\rbrace</code>显示$\left.\frac12\right\rbrace$.</p>
<p>手动调整括号大小<code>\Biggl(\biggl(\Bigl(\bigl(x\bigr)\Bigr)\biggl)\Biggl)</code>显示为：$\Biggl(\biggl(\Bigl(\bigl(x\bigr)\Bigr)\biggl)\Biggl)$.</p>
</li>
<li><p><strong>累加与积分（sum and integral）</strong><code>\sum</code>与<code>\int</code>表示; 上标为上界，下标为下界，所以例如<code>\sum_x^n</code>$\sum_1^n$.若界超过一个字符表示，不要忘记使用<code>{</code>…<code>}</code>, 例如<code>\sum_{i=0}^\infty i^2</code>$\sum_{i=0}^\infty i^2$. 类似的还有累乘<code>\prod</code>$\prod$, 积分<code>\int</code>$\int$, 并集<code>\bigcup</code>$\bigcup$, 交集<code>\bigcap</code>$\bigcap$, 二重积分<code>\iint</code>$\iint$, 三重积分<code>\iiint</code>$\iiint$.</p>
</li>
<li><p><strong>分数（fraction）</strong>，<a href="https://math.meta.stackexchange.com/q/12978/3111" target="_blank" rel="noopener">创建分数的三种方法</a>. <code>\frac ab</code>得到$\frac ab$;对于更复杂分子和分母使用<code>{</code>…<code>}</code>: <code>\frac{a+1}{b+1}</code>$\frac{a+1}{b+1}$. 如果分数分子分母实在是复杂，我们可能会使用<code>\over</code>，将一个组分开：<code>{a+1 \over b+1}</code>${a+1 \over b+1}$. 对于连续的多个分数<code>\cfrac{a}{b}</code>$\cfrac{a}{b}$能派上用场。更多细节，见[后文]。</p>
</li>
<li><p><strong>字体</strong></p>
<ul>
<li><p>“Blackboard bold”,使用<code>\mathbb</code>或者<code>Bbb</code>：$\Bbb{ABCDEFGHIJKLMNOPQRSTUVWXYZ}$$\mathbb{abcdefghijklmnopqrstuvwxyz} $</p>
</li>
<li><p>“Boldface”,使用<code>\mathbf</code>：$\mathbf {ABCDEFGHIJKLMNOPQRSTUVWXYZ}$$\mathbf {abcdefghijklmnopqrstuvwxyz} $</p>
</li>
<li><p>“Typewriter”(打字机体),使用<code>\mathtt</code>：$\mathtt {ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ}$$\mathtt{abcdefghijklmnopqrstuvwxyz}$</p>
</li>
<li><p>“Roman”(罗马体), 使用<code>\mathrm</code>: $\mathrm ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ  $$\mathrm{abcdefghijklmnopqrstuvwxyz}$</p>
</li>
<li><p>“Sans-serif”, 使用<code>\mathsf</code>:$\mathsf {ABCDEFGHIJKLMNOPQRSTUVWXYZ}$$\mathsf abcdefghijklmnopqrstuvwxyz $</p>
</li>
<li><p>“Calligraphic”, 使用<code>\mathcal</code>:$\mathcal {ABCDEFGHIJKLMNOPQRSTUVWXYZ }$</p>
</li>
<li><p>“Script”(手写体), 使用<code>\mathscr</code>: $\mathscr {ABCDEFGHIJKLMNOPQRSTUVWXYZ}  $</p>
</li>
<li><p>“Fraktur”(古德语体), 使用<code>\mathfrak</code>: </p>
<p>$\mathfrak{ABCDEFGHIJKLMNOPQRSTUVWXYZ  }$$\mathfrak {abcdefghijklmnopqrstuvwxyz} $</p>
</li>
</ul>
</li>
<li><p><strong>开方</strong>，<code>\sqrt</code>,能根据根号内容调整：<code>\sqrt{x^3}</code>$\sqrt{x^3}$;$\sqrt[3]{\frac xy}$.对于更复杂的表达使用如<code>{...}^{1/2}</code>表示，${x}^{1/2}$和$\sqrt{x}$一样.</p>
</li>
<li><p><strong>特殊的函数</strong>，诸如，极限“lim”, 正弦“sin”, 最大值“max”, 自然对数”ln”等通常以罗马字体代替斜体来显示。比如使用<code>\lim</code>,<code>\sin</code>等，来显示<code>\sin</code>$\sin x$, 而不是<code>sin x</code>$sin x$.使用下标来对<code>\lim</code>进行标注：<code>\lim_{x\to0}</code>显示$\lim_{x\to0}$.</p>
</li>
<li><p>此外有很多的<strong>特别的标记符号</strong>，部分符号列表参考<a href="https://pic.plover.com/MISC/symbols.pdf" target="_blank" rel="noopener">这里</a>，完整的符号列表参考<a href="https://www.ctan.org/tex-archive/info/symbols/comprehensive/symbols-a4.pdf" target="_blank" rel="noopener">这里</a>.最常用的如下：</p>
<ul>
<li><strong>比较</strong>，<code>\lt \gt \le \leq \leqq \leqslant \ge \geq \geqq\geqslant \neq</code>$\lt \gt \le \leq \leqq \leqslant \ge \geq \geqq\geqslant \neq$. 可以使用<code>\not</code>给任何符号加上一道斜线<code>\not\lt</code>$\not\lt$, 通常这样效果并不佳。</li>
<li><code>+ - \times \div \pm \mp</code>$+-\times \div \pm \mp $.<code>\cdot</code>中心点，$x\cdot y$</li>
<li><strong>集合</strong>，<code>\cup \cap \setminus \subset \subseteq \subsetneq \supset \in \notin \emptyset \varnothing</code>, $\cup \cap \setminus \subset \subseteq \subsetneq \supset \in \notin \emptyset \varnothing $</li>
<li><code>{n+1 \choose 2k}</code>或<code>\binom{n+1}{2k}</code>$\binom{n+1}{2k} $</li>
<li><strong>箭头</strong>，<code>\to \rightarrow \leftarrow \Rightarrow \Leftarrow \mapsto</code>$\to \rightarrow \leftarrow \Rightarrow \Leftarrow \mapsto $</li>
<li><strong>逻辑</strong>，<code>\land \lor \lnot \forall \exists \top \bot \vdash \vDash</code>$\land \lor \lnot \forall \exists \top \bot \vdash \vDash $</li>
<li><strong>形状</strong>，<code>\star \ast \oplus \circ \bullet</code>$\star \ast \oplus \circ \bullet $</li>
<li><code>\approx \sim \simeq \cong \equiv \prec \lhd</code>$\approx \sim \simeq \cong \equiv \prec \lhd $</li>
<li><code>\infty \aleph_0</code>$\infty \aleph_0 $<code>\nabla \partial</code>$\nabla \partial$<code>\Im \Re</code>$\Im \Re$</li>
<li>对于取模相等使用<code>\pmod</code>例如：<code>a\equiv b\pmod n</code>$a\equiv b\pmod n$</li>
<li>$a_1, a_2, \ldots a_n$使用<code>\ldots</code>; $a_1+a_2+\cdots+a_n$使用<code>\cdots</code></li>
<li>一些希腊字母有多种形式：比如<code>\epsilon</code>和<code>\varepsilon</code>$\epsilon \varepsilon$, <code>\phi \varphi</code>$\phi \varphi$,等。手写体小写字母l<code>\ell</code>$\ell$</li>
</ul>
<p><a href="http://detexify.kirelabs.org/classify.html" target="_blank" rel="noopener">Detexif</a>能将你所绘制的图形识别成与之接近的$\TeX$符号。此外更多详情欢迎查看MathJax.org以及<a href="http://docs.mathjax.org/en/latest/tex.html#supported-latex-commands" target="_blank" rel="noopener"> list of currently supported $\LaTeX$ commands </a>和<a href="http://www.onemathematicalcat.org/MathJaxDocumentation/TeXSyntax.htm" target="_blank" rel="noopener">$\TeX$Commands Available in MathJax</a>.</p>
</li>
<li><p><strong>空格</strong>。在公式之间添加更多的空格数，不会增加显示的空格宽度，<code>a b</code>和<code>a        b</code>都会显示$a        b$.增加更多空格：<code>\,</code>增加小空格$a\,b$;<code>\;</code>增加更宽一点的空格$a\;b$;更宽的空格使用<code>\quad</code>$a\quad b$和<code>\qquad</code>$a\qquad b$.</p>
<p>增加纯文本，使用<code>\text{...}</code>:$\left\{ x\in s| \text{ x is exatra large}\right\}$.在<code>\text{...}</code>中亦可使用<code>$...$</code>.</p>
</li>
<li><p><strong>音标和变音符号</strong>，<code>\hat</code>对单个标记加<code>...帽</code>，对公式加<code>帽</code>使用<code>\widehat</code>$\widehat{xyz}$,不过如果太宽的话看起来就有点<code>哈巴</code>了。类似的<code>\bar</code>$\bar{x}$, <code>\overline</code>$\overline{xyz}$, <code>\vec</code>$\vec x$以及<code>\overrightarrow$\overrightarrow{xyz}$</code>还有<code>\overleftrightarrow</code>$\overleftrightarrow{xyz}$. 对于点符号，例如$\frac{d}{dx}x\dot x=\dot x^2+x\ddot x$分别使用的是<code>\dot</code>和<code>\ddot</code>.</p>
</li>
<li><p><strong>特殊符号转义</strong>，使用<code>\</code>转义符：<code>\$</code>$$$, <code>\{</code>$\{$, <code>\_</code>$_$等。假如我们想要输出<code>\</code>符号本身，使用<code>\backslash</code>$\backslash$，而<code>\\</code>被用于创建新的一行。</p>
</li>
</ol>
<h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><ol>
<li><p>使用<code>\begin{matrix}...\end{matrix}</code>表示矩阵。在<code>\begin</code>和<code>\end</code>之间放置矩阵元素。矩阵每一行用<code>\\</code>分隔，元素之间使用<code>&amp;</code>来分隔。例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$$</span><br><span class="line">    \begin&#123;matrix&#125;</span><br><span class="line">    1 &amp; x &amp; x^2 \\</span><br><span class="line">    4 &amp; y &amp; y^2 \\</span><br><span class="line">    7 &amp; z &amp; z^2 \\</span><br><span class="line">    \end&#123;matrix&#125;</span><br><span class="line">$$</span><br></pre></td></tr></table></figure>
<p>得到：</p>
</li>
</ol>
<script type="math/tex; mode=display">
\begin{matrix}
   1&x&x^2\\
   4&y&y^2\\
   7&z&z^2\\
   \end{matrix}</script><p>​    MathJax能够自动调整行和列的大小来自适应。</p>
<ol>
<li><p><strong>给矩阵增加括号</strong>使用上一节中的第5部分，或者将<code>matrix</code>替换成<code>pmatrix</code>$\begin{pmatrix}1&amp;2\\3&amp;4\\ \end{pmatrix}$, <code>bmatrix</code>$\begin{bmatrix}1&amp;2\\3&amp;4\\ \end{bmatrix}$, <code>Bmatrix</code>$\begin{Bmatrix}1&amp;2\\3&amp;4\\ \end{Bmatrix}$, <code>vmatrix</code>$\begin{vmatrix}1&amp;2\\3&amp;4\\ \end{vmatrix}$, <code>Vmatrix</code>$\begin{Vmatrix}1&amp;2\\3&amp;4\\ \end{Vmatrix}$.</p>
</li>
<li><p>使用<code>\cdots</code>$\cdots$, <code>\ddots</code>$\ddots$, <code>\vdots</code>$\vdots$, 来表示矩阵中被忽略的条目:</p>
<figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="formula">$$</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">begin</span><span class="string">&#123;pmatrix&#125;</span></span></span></span><br><span class="line"><span class="formula">1&amp;a_1&amp;a_1^2&amp;<span class="tag">\<span class="name">cdots</span></span>&amp;a_1^n<span class="tag">\<span class="name">\</span></span></span></span><br><span class="line"><span class="formula">1&amp;a_2&amp;a_2^2&amp;<span class="tag">\<span class="name">cdots</span></span>&amp;a_2^n<span class="tag">\<span class="name">\</span></span></span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">vdots</span></span>&amp;<span class="tag">\<span class="name">vdots</span></span>&amp;<span class="tag">\<span class="name">vodts</span></span>&amp;ddots&amp;<span class="tag">\<span class="name">vdots</span></span><span class="tag">\<span class="name">\</span></span></span></span><br><span class="line"><span class="formula">1&amp;a_m&amp;a_m^2&amp;<span class="tag">\<span class="name">cdots</span></span>&amp;a_m^n<span class="tag">\<span class="name">\</span></span></span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">end</span><span class="string">&#123;pmatrix&#125;</span></span></span></span><br><span class="line"><span class="formula">$$</span></span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">
\begin{pmatrix}
1&a_1&a_1^2&\cdots&a_1^n\\
1&a_2&a_2^2&\cdots&a_2^n\\
\vdots&\vdots&\vdots&\ddots&\vdots\\
1&a_m&a_m^2&\cdots&a_m^n\\
\end{pmatrix}</script></li>
</ol>
<ol>
<li><p>对于水平方向“增广“矩阵，用方括号或者圆括号将与之对应格式的表格括起来；详情见后文的<a href="_">数组</a>一节。举例如下：</p>
<script type="math/tex; mode=display">
\left[
\begin{array}{cc|c}
1&2&3\\
4&5&6
\end{array}
\right]</script><p>表达式为:</p>
<figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="formula">$$</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">left</span><span class="string">[</span></span></span></span><br><span class="line"><span class="formula"><span class="tag"><span class="string">\begin&#123;array&#125;&#123;cc|c&#125;</span></span></span></span><br><span class="line"><span class="formula"><span class="tag"><span class="string">1&amp;2&amp;3\\</span></span></span></span><br><span class="line"><span class="formula"><span class="tag"><span class="string">4&amp;5&amp;6</span></span></span></span><br><span class="line"><span class="formula"><span class="tag"><span class="string">\end&#123;array&#125;</span></span></span></span><br><span class="line"><span class="formula"><span class="tag"><span class="string">\right]</span></span></span></span><br><span class="line"><span class="formula">$$</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>对于垂直方向的“增广”矩阵，使用<code>\hline</code>，例如：</p>
<script type="math/tex; mode=display">
\begin{pmatrix}
a&b\\
c&d\\
\hline
1&0\\
0&1
\end{pmatrix}</script><p>表达式为:</p>
<figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="formula">$$</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">begin</span><span class="string">&#123;pmatrix&#125;</span></span></span></span><br><span class="line"><span class="formula">a&amp;b<span class="tag">\<span class="name">\</span></span></span></span><br><span class="line"><span class="formula">c&amp;d<span class="tag">\<span class="name">\</span></span></span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">hline</span></span></span></span><br><span class="line"><span class="formula">1&amp;0<span class="tag">\<span class="name">\</span></span></span></span><br><span class="line"><span class="formula">0&amp;1</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">end</span><span class="string">&#123;pmatrix&#125;</span></span></span></span><br><span class="line"><span class="formula">$$</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>对于小行内矩阵，使用<code>\bigl(\begin{smallmatrix}...\end{smallmatrix}\bigr)</code>, 例如：<code>\bigl(\begin{smallmatrix}a&amp;b\\c&amp;d\end{smallmatrix}\bigr)</code>$\bigl(\begin{smallmatrix}a&amp;b\\c&amp;d\end{smallmatrix}\bigr)$.</p>
</li>
</ol>
	
	  <p class="article-more-link">
		<a class="btn btn-primary" href="2018/08/14/MathJax-basic-tutorial/#more">Read more...</a>
	  </p>
	
  
</div>



<footer class="article-footer">
  <a data-url="https://www.blankspace.cn/2018/08/14/MathJax-basic-tutorial/" data-id="cjkzh6xuq0006l0figsdf5vnp" class="article-share-link">
	<i class="fa fa-share"></i> Share
  </a>
  
  
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="tags/MathJax/">MathJax</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="tags/TeX/">TeX</a></li></ul>


</footer>


</div>

</article>


	  
		<article id="post-activation-function" class="article article-type-post" itemscope itemprop="blogPost">
	


<header class="article-header">

  
    <h1 itemprop="name">
      <a class="article-title" href="2018/08/13/activation-function/">Activation function</a>
    </h1>
  


	

		<div class="article-meta"> 
			
	  
		   <div class="article-datetime">
  <a href="2018/08/13/activation-function/" class="article-date"><time datetime="2018-08-13T13:24:57.000Z" itemprop="datePublished">2018-08-13</time></a>
</div>



			
			  
			

 
			
  <div class="article-category">
    <a class="article-category-link" href="categories/Machine-Learning/">Machine Learning</a> / <a class="article-category-link" href="categories/Machine-Learning/TensorFlow/">TensorFlow</a>
  </div>


	    </div>
	   

</header>

<div class="article-inner">
<div class="article-entry" itemprop="articleBody">
  
	<p>Activation function（激活函数），是一类非线性函数，与之对应的就是线性函数。线性函数就是一条直线，形式化表示就是：</p>
<script type="math/tex; mode=display">
y=mx+b</script><p>$m$是直线的斜率，$y$通常是预测的值，$x$是输入的特征值，$b$是$y$轴的截距。</p>
<p>由于现实世界的复杂性，输入特征和预测之间的关系通常不是简单的线性关系，换言之就是非线性关系。然后就发现一些非线性函数，满足一定的性质（这个得看人家的论文），通过非线性函数多层的组合，可以来拟合非常复杂的非线性函数。</p>
<p>更过关于激活函数的介绍，请看<a href="https://en.wikipedia.org/wiki/Activation_function" target="_blank" rel="noopener">这里</a>.</p>
<p>TensorFlow中更多激活函数，请看<a href="https://www.tensorflow.org/api_guides/python/nn#Activation_Functions" target="_blank" rel="noopener">TensorFlow Activation Function</a>.</p>
<h3 id="Binary-step"><a href="#Binary-step" class="headerlink" title="Binary step"></a>Binary step</h3><script type="math/tex; mode=display">
f(x) =
\begin{cases}
0,  & \text{for x $\lt$ 0} \\
1, & \text{for x $\geq$ 0}
\end{cases}</script><p>阶跃函数是理想的激活函数，但是不可导。</p>
<p>下面对几种常见的激活函数进行可视化。</p>
<h3 id="ReLu-rectified-linear-unit-ReLu"><a href="#ReLu-rectified-linear-unit-ReLu" class="headerlink" title="ReLu(rectified linear unit, ReLu)"></a>ReLu(rectified linear unit, ReLu)</h3><script type="math/tex; mode=display">
f(x) =
\begin{cases}
0,  & \text{for x $\lt$ 0} \\
x, & \text{for x $\geq$ 0}
\end{cases}</script><h3 id="Logistic-Sigmoid-or-Soft-step"><a href="#Logistic-Sigmoid-or-Soft-step" class="headerlink" title="Logistic(Sigmoid or Soft step)"></a>Logistic(Sigmoid or Soft step)</h3><script type="math/tex; mode=display">
f(x)=\sigma{(x)} = \frac{1}{1+e^{-x}}</script><h3 id="TanH"><a href="#TanH" class="headerlink" title="TanH"></a>TanH</h3><script type="math/tex; mode=display">
f(x)= \tanh{(x)}= \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}</script><h3 id="Softplus"><a href="#Softplus" class="headerlink" title="Softplus"></a>Softplus</h3><script type="math/tex; mode=display">
f(x)= \ln{(1+e^x)}</script><h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><script type="math/tex; mode=display">
f_{i}(x)= \frac{e^{x_{i}}}{\sum_{j=1}^{J}e^{x_j}}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf <span class="comment"># machine learning framwork</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># scientific computation</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># data visualization</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Graph().as_default(), tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    x_data = np.linspace(<span class="number">-6</span>, <span class="number">6</span>, <span class="number">256</span>)</span><br><span class="line"></span><br><span class="line">    y_relu = tf.nn.relu(x_data)</span><br><span class="line">    y_sigmoid = tf.nn.sigmoid(x_data)</span><br><span class="line">    y_tanh = tf.nn.tanh(x_data)</span><br><span class="line">    y_softplus = tf.nn.softplus(x_data)</span><br><span class="line">    y_softmax = tf.nn.softmax(x_data) <span class="comment"># softmax is a special kind of activation function, it is about probablity</span></span><br><span class="line"></span><br><span class="line">    y_relu, y_sigmoid, y_tanh, y_softplus, y_softmax = sess.run([y_relu, y_sigmoid, y_tanh, y_softplus, y_softmax])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># plot</span></span><br><span class="line">    fig = plt.figure(<span class="number">1</span>, figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">    plt.subplot(<span class="number">221</span>)</span><br><span class="line">    plt.plot(x_data, y_relu, c=<span class="string">'red'</span>, label=<span class="string">'relu'</span>)</span><br><span class="line">    plt.ylim(<span class="number">-1</span>, <span class="number">6</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">222</span>)</span><br><span class="line">    plt.plot(x_data, y_sigmoid, c=<span class="string">'green'</span>, label=<span class="string">'sigmoid'</span>)</span><br><span class="line">    plt.ylim(<span class="number">-0.3</span>, <span class="number">1.5</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">223</span>)</span><br><span class="line">    plt.plot(x_data, y_tanh, c=<span class="string">'blue'</span>, label=<span class="string">'tanh'</span>)</span><br><span class="line">    plt.ylim(<span class="number">-1.2</span>, <span class="number">1.2</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">224</span>)</span><br><span class="line">    plt.plot(x_data, y_softplus, c=<span class="string">'yellow'</span>, label=<span class="string">'softplus'</span>)</span><br><span class="line">    plt.ylim(<span class="number">-0.3</span>, <span class="number">6</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2018/08/13/activation-function/output_1_0.png" alt="Activation Functions-1"></p>
	
	  <p class="article-more-link">
		<a class="btn btn-primary" href="2018/08/13/activation-function/#more">Read more...</a>
	  </p>
	
  
</div>



<footer class="article-footer">
  <a data-url="https://www.blankspace.cn/2018/08/13/activation-function/" data-id="cjkzh6xv2000el0fi9xqwfl8x" class="article-share-link">
	<i class="fa fa-share"></i> Share
  </a>
  
  
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="tags/Activation/">Activation</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="tags/TensorFlow/">TensorFlow</a></li></ul>


</footer>


</div>

</article>


	  
		<article id="post-placeholder" class="article article-type-post" itemscope itemprop="blogPost">
	


<header class="article-header">

  
    <h1 itemprop="name">
      <a class="article-title" href="2018/08/13/placeholder/">Placeholder</a>
    </h1>
  


	

		<div class="article-meta"> 
			
	  
		   <div class="article-datetime">
  <a href="2018/08/13/placeholder/" class="article-date"><time datetime="2018-08-13T07:05:47.000Z" itemprop="datePublished">2018-08-13</time></a>
</div>



			
			  
			

 
			
  <div class="article-category">
    <a class="article-category-link" href="categories/Machine-Learning/">Machine Learning</a> / <a class="article-category-link" href="categories/Machine-Learning/TensorFlow/">TensorFlow</a>
  </div>


	    </div>
	   

</header>

<div class="article-inner">
<div class="article-entry" itemprop="articleBody">
  
  
	<!-- Table of Contents -->

	
	
	<h3 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h3><p><strong>A placeholder is simply a variable that we will assign data to at a later date. It allows us to create our operations and build our computation graph, without needing the data.</strong></p>
<p>顾名思义，占位符，没有数据先占位。是一种变量。之后按照<code>sess.run(***, feed_dict={input: **})</code>形式传输数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Graph().as_default(), tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    x = tf.placeholder(tf.float32)</span><br><span class="line">    y = x**<span class="number">3</span></span><br><span class="line">    feed_dict = &#123;x:[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125;</span><br><span class="line">    print(sess.run(y, feed_dict=feed_dict))</span><br></pre></td></tr></table></figure>
<pre><code>[ 1.  8. 27. 64.]
</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>placeholder</code> 与 <code>feed_dict={}</code> 总是一起出现的。placeholder允许没有数据先占位创建计算图，运行时通过<code>feed_dict</code>传入数据。</p>

	
  
</div>


  



<footer class="article-footer">
  <a data-url="https://www.blankspace.cn/2018/08/13/placeholder/" data-id="cjkzh6xvu001kl0fi0o2tqrup" class="article-share-link">
	<i class="fa fa-share"></i> Share
  </a>
  
  
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="tags/TensorFlow/">TensorFlow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="tags/placeholder/">placeholder</a></li></ul>


</footer>


</div>

</article>


	  
		<article id="post-Tensor-Control" class="article article-type-post" itemscope itemprop="blogPost">
	


<header class="article-header">

  
    <h1 itemprop="name">
      <a class="article-title" href="2018/08/13/Tensor-Control/">Tensor Control</a>
    </h1>
  


	

		<div class="article-meta"> 
			
	  
		   <div class="article-datetime">
  <a href="2018/08/13/Tensor-Control/" class="article-date"><time datetime="2018-08-13T02:06:14.000Z" itemprop="datePublished">2018-08-13</time></a>
</div>



			
			  
			

 
			
  <div class="article-category">
    <a class="article-category-link" href="categories/Machine-Learning/">Machine Learning</a> / <a class="article-category-link" href="categories/Machine-Learning/TensorFlow/">TensorFlow</a>
  </div>


	    </div>
	   

</header>

<div class="article-inner">
<div class="article-entry" itemprop="articleBody">
  
  
	<!-- Table of Contents -->

	
	
	<h2 id="张量形状"><a href="#张量形状" class="headerlink" title="张量形状"></a>张量形状</h2><p>形状shape，用来描述张量的大小和数量。张量的形状表示为列表的形式，其中第i个元素表示维度i的大小，列表的长度标书张量的阶（维数）。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>阶</th>
<th>形状</th>
<th>维数</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>[]</td>
<td>0-D</td>
<td>0 维张量。标量。</td>
</tr>
<tr>
<td>1</td>
<td>[D0]</td>
<td>1-D</td>
<td>形状为 [6] 的 1 维张量。</td>
</tr>
<tr>
<td>2</td>
<td>[D0, D1]</td>
<td>2-D</td>
<td>形状为 [4, 3] 的 2 维张量。</td>
</tr>
<tr>
<td>3</td>
<td>[D0, D1, D2]</td>
<td>3-D</td>
<td>形状为 [1, 2, 3] 的 3 维张量。</td>
</tr>
<tr>
<td>n</td>
<td>[D0, D1, … Dn-1]</td>
<td>n 维</td>
<td>形状为 [D0, D1, … Dn-1] 的张量。</td>
</tr>
</tbody>
</table>
</div>
<p><a href="https://www.tensorflow.org/programmers_guide/tensors#shape" target="_blank" rel="noopener">文档</a>中介绍得更详细。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># show the shape of tensor</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">g = tf.Graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> g.as_default():</span><br><span class="line">    scalar = tf.ones([]) <span class="comment"># a scalar / 0-D tensor :1</span></span><br><span class="line">    vector = tf.ones([<span class="number">6</span>]) <span class="comment"># a vector with 6 elements: [1,1,1 ,1,1,1]</span></span><br><span class="line">    matrix = tf.ones([<span class="number">2</span>, <span class="number">3</span>]) <span class="comment"># a matrix with 2 rows and 3 columns</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment"># use tf.get_shape() </span></span><br><span class="line">        print(<span class="string">"Scalar shape: "</span>,scalar.get_shape(), <span class="string">" value: "</span>, sess.run(scalar))</span><br><span class="line">        print(<span class="string">"Vector shape: "</span>,vector.get_shape(), <span class="string">" value: "</span>, sess.run(vector))</span><br><span class="line">        print(<span class="string">"Matrix shape: "</span>,matrix.get_shape(), <span class="string">" value: "</span>, sess.run(matrix))</span><br></pre></td></tr></table></figure>
<pre><code>D:\Anaconda3\Anaconda3_py36\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters


Scalar shape:  ()  value:  1.0
Vector shape:  (6,)  value:  [1. 1. 1. 1. 1. 1.]
Matrix shape:  (2, 3)  value:  [[1. 1. 1.]
 [1. 1. 1.]]
</code></pre><h3 id="获取张量形状"><a href="#获取张量形状" class="headerlink" title="获取张量形状"></a>获取张量形状</h3><p>可以通过查看张量对象的<code>shape</code>属性来获取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vector.shape</span><br></pre></td></tr></table></figure>
<pre><code>TensorShape([Dimension(6)])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">matrix.shape[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<pre><code>Dimension(3)
</code></pre><h3 id="获取张量的数据类型"><a href="#获取张量的数据类型" class="headerlink" title="获取张量的数据类型"></a>获取张量的数据类型</h3><p>查看张量对象的<code>dtype</code>属性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">matrix.dtype</span><br></pre></td></tr></table></figure>
<pre><code>tf.float32
</code></pre><h3 id="改变张量数据类型"><a href="#改变张量数据类型" class="headerlink" title="改变张量数据类型"></a>改变张量数据类型</h3><p><code>tf.cast</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">c = tf.constant([<span class="number">1</span>,<span class="number">9</span>,<span class="number">8</span>,<span class="number">3</span>])</span><br><span class="line">print(c.dtype)</span><br><span class="line">f = tf.cast(c, dtype=tf.float32)</span><br><span class="line">print(f.dtype)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;dtype: &#39;int32&#39;&gt;
&lt;dtype: &#39;float32&#39;&gt;
</code></pre><h3 id="获取张量的阶"><a href="#获取张量的阶" class="headerlink" title="获取张量的阶"></a>获取张量的阶</h3><p><code>tf.rank()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.rank(scalar)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;tf.Tensor &#39;Rank:0&#39; shape=() dtype=int32&gt;
</code></pre><h3 id="张量切片"><a href="#张量切片" class="headerlink" title="张量切片"></a>张量切片</h3><p>对于n阶张量，要访问其中某一元素，需要制定n个索引。</p>
<p><code>:</code>是Python切片语法，也意味着<strong>不要变更该维度</strong>。可以帮助访问张量的子向量，子矩阵和子张量。</p>
<h2 id="Broadcasting-广播"><a href="#Broadcasting-广播" class="headerlink" title="Broadcasting | 广播"></a>Broadcasting | 广播</h2><p>tensorflow支持广播，借鉴了Numpy中的做法，<a href="https://docs.scipy.org/doc/numpy-1.10.1/user/basics.broadcasting.html" target="_blank" rel="noopener">Numpy Broadcasting</a>.</p>
<p>数学中，相同形状的张量才能进行元素级的运算，例如相加和等于。由于广播，使得不同形状的张量运算可以像对标量进行运算一样。</p>
<p>当张量被广播时，相当于对张量进行复制，实际上并不复制，广播专门为实现性能优化而设计。</p>
<p>举例，假设你和四个小伙伴，年龄分别为[18, 17, 20, 22, 21],每年年龄+1,模拟这个过程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 向量加法</span></span><br><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    <span class="comment"># method 1</span></span><br><span class="line">    ages = tf.constant([<span class="number">18</span>, <span class="number">17</span>, <span class="number">20</span>, <span class="number">22</span>, <span class="number">21</span>])</span><br><span class="line">    one = tf.constant([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    new_ages = tf.add(ages, one)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        print(new_ages.eval())</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># method 2</span></span><br><span class="line">    one_ = tf.constant(<span class="number">1</span>)</span><br><span class="line">    new_ages_ = tf.add(ages, one_)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        print(new_ages_.eval())</span><br></pre></td></tr></table></figure>
<pre><code>[19 18 21 23 22]
[19 18 21 23 22]
</code></pre><h3 id="张量变形"><a href="#张量变形" class="headerlink" title="张量变形"></a>张量变形</h3><p>可以使用<code>tf.reshape()</code>来改变张量的形状。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"></span><br><span class="line">arr = np.arange(<span class="number">1</span>, <span class="number">13</span>).reshape(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">np.random.shuffle(arr)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    x = tf.constant(arr, dtype=tf.int32) <span class="comment"># create a 3x4 matrix/ 2-D tensor</span></span><br><span class="line">    reshaped_4x3_x = tf.reshape(x, [<span class="number">4</span>, <span class="number">3</span>])</span><br><span class="line">    reshaped_2x6_x = tf.reshape(x, [<span class="number">2</span>, <span class="number">6</span>])</span><br><span class="line">    reshaped_3x2x2_x = tf.reshape(x, [<span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>]) <span class="comment"># reshape the rank </span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        print(<span class="string">"Original matrix (3x4):"</span>)</span><br><span class="line">        print(x.eval())</span><br><span class="line">        </span><br><span class="line">        print(<span class="string">"Reshaped matrix (4x3)"</span>)</span><br><span class="line">        print(reshaped_4x3_x.eval())</span><br><span class="line">        </span><br><span class="line">        print(<span class="string">"Reshaped matrix (2x6)"</span>)</span><br><span class="line">        print(reshaped_2x6_x.eval())</span><br><span class="line">        </span><br><span class="line">        print(<span class="string">"Reshaped matrix (3x2x2)"</span>)</span><br><span class="line">        print(reshaped_3x2x2_x.eval())</span><br></pre></td></tr></table></figure>
<pre><code>Original matrix (3x4):
[[ 9 10 11 12]
 [ 1  2  3  4]
 [ 5  6  7  8]]
Reshaped matrix (4x3)
[[ 9 10 11]
 [12  1  2]
 [ 3  4  5]
 [ 6  7  8]]
Reshaped matrix (2x6)
[[ 9 10 11 12  1  2]
 [ 3  4  5  6  7  8]]
Reshaped matrix (3x2x2)
[[[ 9 10]
  [11 12]]

 [[ 1  2]
  [ 3  4]]

 [[ 5  6]
  [ 7  8]]]
</code></pre><h2 id="变量、初始化和赋值"><a href="#变量、初始化和赋值" class="headerlink" title="变量、初始化和赋值"></a>变量、初始化和赋值</h2><p>TensorFlow变量初始化不是自动进行的，调用<code>tf.global_variables_initializer()</code>。不初始化就会报错。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    v = tf.Variable([<span class="number">3</span>])</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            sess.run(v)</span><br><span class="line">        <span class="keyword">except</span> tf.errors.FailedPreconditionError <span class="keyword">as</span> e:</span><br><span class="line">            print(<span class="string">"Caught excepted error: "</span>, e)</span><br></pre></td></tr></table></figure>
<pre><code>Caught excepted error:  Attempting to use uninitialized value Variable
     [[Node: _retval_Variable_0_0 = _Retval[T=DT_INT32, index=0, _device=&quot;/job:localhost/replica:0/task:0/device:CPU:0&quot;](Variable)]]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    v = tf.Variable([<span class="number">3</span>])</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        init = tf.global_variables_initializer()</span><br><span class="line">        sess.run(init)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            print(sess.run(v))</span><br><span class="line">        <span class="keyword">except</span> tf.errors.FailedPreconditionError <span class="keyword">as</span> e:</span><br><span class="line">            print(<span class="string">"Caught excepted error: "</span>, e)</span><br></pre></td></tr></table></figure>
<pre><code>[3]
</code></pre><h3 id="assign"><a href="#assign" class="headerlink" title="assign"></a>assign</h3><p>要变更变量的值，使用<code>tf.assign()</code>指令，仅仅创建assign指令也不能起作用。和初始化一样，也需要运行赋值指令才能变更变量值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    v = tf.Variable([<span class="number">3</span>])</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        init = tf.global_variables_initializer()</span><br><span class="line">        sess.run(init)</span><br><span class="line">        assignment = tf.assign(v, [<span class="number">9</span>])</span><br><span class="line">        print(v.eval()) <span class="comment"># the variable has not been changed yet.</span></span><br><span class="line">        sess.run(assignment)</span><br><span class="line">        print(v.eval()) <span class="comment"># now the variable is updated</span></span><br></pre></td></tr></table></figure>
<pre><code>[3]
[9]
</code></pre><h3 id="评估张量"><a href="#评估张量" class="headerlink" title="评估张量"></a>评估张量</h3><p><code>eval()</code>。<br>方法仅在默认 tf.Session 处于活动状态时才起作用。<code>Tensor.eval()</code>会返回一个和张量内容相同的Numpy数组。</p>
<p>仅仅只有占位符的情况下无法进行评估。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    p = tf.placeholder(tf.float32)</span><br><span class="line">    t = p+<span class="number">1.0</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment"># t.eval() # this will fail, since the placeholder did not give a value</span></span><br><span class="line">        print(t.eval(feed_dict=&#123;p:<span class="number">23.3</span>&#125;) )<span class="comment"># this will success, because a value is fed to the placeholder</span></span><br></pre></td></tr></table></figure>
<pre><code>24.3
</code></pre><h2 id="举例：模拟投掷两个骰子10次"><a href="#举例：模拟投掷两个骰子10次" class="headerlink" title="举例：模拟投掷两个骰子10次"></a>举例：模拟投掷两个骰子10次</h2><p>素材来自<a href="https://colab.research.google.com/notebooks/mlcc/creating_and_manipulating_tensors.ipynb?hl=zh-cn#scrollTo=iFIOcnfz_Oqw" target="_blank" rel="noopener">这里</a>.</p>
<p>模拟<a href="https://book.douban.com/subject/1082154/" target="_blank" rel="noopener">《活着》</a>中富贵儿赌钱投骰子（6个面，点数从1到6）的过程，在模拟中生成一个 <code>10x4</code> 二维张量，其中：</p>
<ul>
<li>列 <code>1</code> 和 <code>2</code> 均存储一个骰子的一次投掷值。</li>
<li>列 <code>3</code> 存储同一行中列 <code>1</code> 和 <code>2</code> 的值的总和。</li>
<li>列 <code>4</code> 表示开大开小，若列 <code>3</code> 点数大于7，开大（如用1表示）；小于等于7开小（如用0表示）。</li>
</ul>
<p>例如，第一行中可能会包含以下值：</p>
<ul>
<li>列 <code>1</code> 存储 <code>4</code></li>
<li>列 <code>2</code> 存储 <code>3</code></li>
<li>列 <code>3</code> 存储 <code>7</code></li>
<li>列 <code>4</code> 存储 <code>0</code></li>
</ul>
<p>要完成此任务，可能需要浏览 <a href="https://www.tensorflow.org/api_guides/python/array_ops" target="_blank" rel="noopener">TensorFlow 文档</a>。</p>
<p><strong>问题</strong>：<br><em>如何随机并分配值给变量？（TensorFlow不支持动态计算图）</em><br><em>如何赋值十次，循环？最后张量结果如何表示？</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import numpy as np</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">g = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g.as_default():</span><br><span class="line">    <span class="comment"># 使用随机均匀分布 tf.random_uniform 来模拟投掷 n 次, 不需要循环。</span></span><br><span class="line">    dice1 = tf.Variable(tf.random_uniform([<span class="number">10</span>, <span class="number">1</span>],</span><br><span class="line">                                         minval=<span class="number">1</span>,</span><br><span class="line">                                         maxval=<span class="number">7</span>,</span><br><span class="line">                                         dtype=tf.int32))</span><br><span class="line">    </span><br><span class="line">    dice2 = tf.Variable(tf.random_uniform([<span class="number">10</span>, <span class="number">1</span>],</span><br><span class="line">                                         minval=<span class="number">1</span>, </span><br><span class="line">                                         maxval=<span class="number">7</span>, </span><br><span class="line">                                         dtype=tf.int32))</span><br><span class="line">    </span><br><span class="line">    dice_sum = tf.add(dice1, dice2)</span><br><span class="line">    </span><br><span class="line">    seven = tf.constant(<span class="number">7</span>)</span><br><span class="line">    <span class="comment"># 关于TensorFlow条件控制</span></span><br><span class="line">    <span class="comment"># https://www.tensorflow.org/versions/r1.8/api_guides/python/control_flow_ops#Control_Flow_Operations</span></span><br><span class="line">    comp = tf.cast(tf.greater(dice_sum, seven), tf.int32)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用 tf.concat 连接向量，axis=1 水平方向连接</span></span><br><span class="line">    result = tf.concat(values=[dice1, dice2, dice_sum, comp], axis=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        </span><br><span class="line">        print(result.eval())</span><br></pre></td></tr></table></figure>
<pre><code>[[ 4  4  8  1]
 [ 6  1  7  0]
 [ 5  6 11  1]
 [ 4  2  6  0]
 [ 4  1  5  0]
 [ 5  3  8  1]
 [ 6  2  8  1]
 [ 4  2  6  0]
 [ 4  6 10  1]
 [ 1  3  4  0]]
</code></pre>
	
  
</div>


  



<footer class="article-footer">
  <a data-url="https://www.blankspace.cn/2018/08/13/Tensor-Control/" data-id="cjkzh6xur0007l0fi0zmj0tzy" class="article-share-link">
	<i class="fa fa-share"></i> Share
  </a>
  
  
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="tags/Tensor/">Tensor</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="tags/TensorFlow/">TensorFlow</a></li></ul>


</footer>


</div>

</article>


	  
		<article id="post-Tensor" class="article article-type-post" itemscope itemprop="blogPost">
	


<header class="article-header">

  
    <h1 itemprop="name">
      <a class="article-title" href="2018/08/13/Tensor/">Tensor</a>
    </h1>
  


	

		<div class="article-meta"> 
			
	  
		   <div class="article-datetime">
  <a href="2018/08/13/Tensor/" class="article-date"><time datetime="2018-08-13T02:05:48.000Z" itemprop="datePublished">2018-08-13</time></a>
</div>



			
			  
			

 
			
  <div class="article-category">
    <a class="article-category-link" href="categories/Machine-Learning/">Machine Learning</a> / <a class="article-category-link" href="categories/Machine-Learning/TensorFlow/">TensorFlow</a>
  </div>


	    </div>
	   

</header>

<div class="article-inner">
<div class="article-entry" itemprop="articleBody">
  
	<h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><p>TensorFlow中的Tensor就是张量，张量是任意维的数组。常用的张量有：</p>
<ul>
<li><strong>constant（标量/常量）</strong>：零维数组，零阶张量。例如，0或一个字符串常量。</li>
<li><strong>vector（向量/矢量）</strong>：一维数组，一阶张量。例如，[0]或[0, 1, 1, 2, 3, 5].</li>
<li><strong>matrix（矩阵）</strong>:二维数组，二阶张量。例如，[[4, 9, 2], [3, 5, 7], [8, 1, 6]]</li>
</ul>
<p>在TensorFlow中，张量的创建、销毁和控制由<strong>指令</strong>完成。典型的TensorFlow代码大多数都是指令。</p>
<h2 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h2><p>TensorFlow中的图，也叫作计算图或数据流图（<del>数据库原理和软件工程中的数据流图看似百无一用</del>），是一种<a href="https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/1450" target="_blank" rel="noopener">数据结构</a>。</p>
<p>TensorFlow程序可以选择创建一张或者多张图。</p>
<p><strong><em>图的节点是指令；图的边是张量。</em></strong>（张量就像是在图中的流动，所以称为Tensor Flow）.</p>
<p>张量流经图，在每个节点由一个指令控制。<strong>一个指令的输出张量通常会变成后续指令的输入张量</strong>。</p>
<p>TensorFlow实现<strong>延迟执行模型</strong>，系统仅会根据相关节点的需求在需要时计算节点。</p>
<p><strong><em>常量和张量都是图中的一种指令</em></strong>，<strong>常量是始终会返回同一张量值的指令</strong>，<strong>变量是会返回分配给它的任何张量的指令</strong>。</p>
<p><strong><em>图必须要在TensorFlow会话Session中运行，会话存储了被会话运行的图的状态</em></strong>.</p>
<p>会话可以将图发布到多台设备上（假如程序在某个分布式计算框架上运行）。官方提供的<a href="https://www.tensorflow.org/deploy/distributed" target="_blank" rel="noopener">分布式TensorFlow文档</a>.</p>
<p> TensorFlow 提供了一个<strong>默认图</strong>。不过，我们建议您明确创建自己的 <code>Graph</code>，以便跟踪状态（例如，您可能希望在每个单元格中使用一个不同的 <code>Graph</code>）。</p>
<h3 id="举例，“海伦-秦九韶公式”三斜求积"><a href="#举例，“海伦-秦九韶公式”三斜求积" class="headerlink" title="举例，“海伦-秦九韶公式”三斜求积"></a>举例，“海伦-秦九韶公式”三斜求积</h3><script type="math/tex; mode=display">
S = \sqrt{p\left( p-a\right)\left( p-b\right)\left( p-c\right)}</script><script type="math/tex; mode=display">
p=\frac{a+b+c}{2}</script><p>相关<a href="https://www.tensorflow.org/api_docs/python/tf" target="_blank" rel="noopener">API</a>.</p>
	
	  <p class="article-more-link">
		<a class="btn btn-primary" href="2018/08/13/Tensor/#more">Read more...</a>
	  </p>
	
  
</div>



<footer class="article-footer">
  <a data-url="https://www.blankspace.cn/2018/08/13/Tensor/" data-id="cjkzh6xut000al0fivffmmhzb" class="article-share-link">
	<i class="fa fa-share"></i> Share
  </a>
  
  
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="tags/Tensor/">Tensor</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="tags/TensorFlow/">TensorFlow</a></li></ul>


</footer>


</div>

</article>


	  
	
	
	
	  <div id="page-nav">
		<nav><ul class="pagination"><li class="disabled"><span class="page-prev"><i class="fa fa-chevron-left"></i> Prev</a></li><li class="active"><span class="page-number">1</span></li><li><a class="page-number" href="/page/2/">2</a></li><li><a class="page-number" href="/page/3/">3</a></li><li class="disabled"><span class="page-space">&hellip;</span></li><li><a class="page-number" href="/page/6/">6</a></li><li><a class="page-next" rel="next" href="/page/2/">Next <i class="fa fa-chevron-right"></i></a></li></ul></nav>
	  </div>
	

    </div>
    <div class="col-sm-3 col-sm-offset-0 blog-sidebar">
	  
  
  <div class="sidebar-module">
    <h4>Recents</h4>
    <ul class="sidebar-module-list">
      
        <li>
          <a href="2018/08/14/MathJax-basic-tutorial/">MathJax basic tutorial and quick reference</a>
        </li>
      
        <li>
          <a href="2018/08/13/activation-function/">Activation function</a>
        </li>
      
        <li>
          <a href="2018/08/13/placeholder/">Placeholder</a>
        </li>
      
        <li>
          <a href="2018/08/13/Tensor-Control/">Tensor Control</a>
        </li>
      
        <li>
          <a href="2018/08/13/Tensor/">Tensor</a>
        </li>
      
    </ul>
  </div>


  <div class="sidebar-module sidebar-module-inset">
  <h4>About</h4>
  <a target="_blank" href="about"> <img  id="avatar-logo" width=100%  alt="WizardLQ" src="http://www.gravatar.com/avatar/d14c7c7faf5e1f3001c070f3141d698f?s=512"> </a> <p>Hi,我是一名魔法师，目前自动化硕士在读.<em><strong>“科技是普通人眼中的魔法”</strong></em>.之前有在<a href="https://blog.csdn.net/icurious">CSDN</a>、博客园、简书等写过博客. 写博客一方面能够帮助自己查缺补漏，总结和反思，同时还能被他人看到和甚至对他人产生帮助，十分有意义.若有读者在阅读中发现问题或者有什么意见或者建议，欢迎联系我的邮箱， 或者在博客或者博文中留言，我会尽量回复.<em>(由于平时比较忙<s>我比较懒</s>，有些文章可能需要很长时间才能完善.)</em><br/><strong>你通过下列方式联系到我：</strong></br> <i class="iconfont">&#xe66e;</i><em>Email: <a>liuqidev#gmail.com</a></em>| <i class="iconfont">&#xe64f;</i><a href="https://blog.csdn.net/icurious">CSDN</a>| <i class="iconfont">&#xe655;</i><a href=“https://weibo.com/liuqidev/”>Weibo</a>| <i class="iconfont">&#xe6e1;</i><a href="https://space.bilibili.com/20204877/#/">BiliBili</a> </p>

</div>




  
  <div class="sidebar-module">
    <h4>Categories</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="categories/Languages/">Languages</a><span class="sidebar-module-list-count">1</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="categories/Languages/Python/">Python</a><span class="sidebar-module-list-count">1</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="categories/Languages/Python/Numpy/">Numpy</a><span class="sidebar-module-list-count">1</span></li></ul></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="categories/Machine-Learning/">Machine Learning</a><span class="sidebar-module-list-count">8</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="categories/Machine-Learning/TensorFlow/">TensorFlow</a><span class="sidebar-module-list-count">8</span></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="categories/Math/">Math</a><span class="sidebar-module-list-count">1</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="categories/Math/MathJax/">MathJax</a><span class="sidebar-module-list-count">1</span></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="categories/Projects/">Projects</a><span class="sidebar-module-list-count">19</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="categories/Projects/hexo-theme-bootstrap-blog/">hexo-theme-bootstrap-blog</a><span class="sidebar-module-list-count">19</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="categories/Projects/hexo-theme-bootstrap-blog/Tutorial/">Tutorial</a><span class="sidebar-module-list-count">19</span></li></ul></li></ul></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Archives</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="archives/2018/08/">八月 2018</a><span class="sidebar-module-list-count">28</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="archives/2013/12/">十二月 2013</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  <section>
	<h4>Search</h4>
	<div class="sidebar-module sidebar-module-inset">

	
	<div id="site_search">
	<input type="text" placeholder="Search in the site" class="form-control" id="local-search-input" results="0"/>
	<div id="local-search-result">
	</div>
	</div>
	
</section>


	</div>
		
</div>
	
	
</div>

<footer class="blog-footer">  
  <div class="container">
		<div >
	 <ul id="links" class="nav navbar-nav" style="display: inline-block;float: none;">
		<li><a href="https://weibo.com/liuqidev" title="Find me on Weibo" target="_blank"><i class="iconfont">&#xe655;</i></a></li>
		<li><a href="https://www.zhihu.com/people/wizardlq/" title="Find me on Zhihu" target="_blank"><i class="iconfont">&#xe61b;</i></a></li>
		<li><a href="https://blog.csdn.net/icurious" title="Find me on CSDN" target="_blank"><i class="iconfont">&#xe64f;</i></a></li>
		<li><a href="https://www.douban.com/people/icurious/" title="My Douban" target="_blank"><i class="iconfont">&#xe601;</i></a></li>
		<li><a href="https://space.bilibili.com/20204877/#/" title="Find me on Bilibili" target="_blank"><i class="iconfont">&#xe6b4;</i></a></li>
		<li><a href="https://github.com/liuqidev" title="My Linkedin" target="_blank"><i class="iconfont">&#xe663;</i></a></li>
		<li><a href="https://github.com/liuqidev" title="My Projects on Github" target="_blank"><i class="iconfont">&#xe7ab;</i></a></li>
		<li><a href="https://stackoverflow.com/users/9121113/qi-liu" title="My StackoverFlow" target="_blank"><i class="iconfont">&#xe711;</i></a></li>
		
		
		  <li><a href="/atom.xml" title="RSS Feed"><i class="fa fa-rss" target="_blank"></i></a></li>
		
	  </ul>
	 </div>
    <div id="footer-info" class="text-center">
        &copy; 2018. <em>All Rights Reserved by <a href="https://github.com/liuqidev" target="_blank">liuqidev</a></em><br>	
	</div>
	<div > 

	  </links>
  </div>

  
    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
  <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=XzXyQ1GOPdnOuiMHQmBZKolTWTBtRkFzmBoniAwXpMc&cl=ffffff&w=a"></script>

  <p>
  	<span id="busuanzi_container_site_uv">
  	    <span id="busuanzi_value_site_uv"></span> visitors  |  
  	</span>

      <span id="busuanzi_container_site_pv">
         <span id="busuanzi_value_site_pv"></span> visits
      </span>
	  
  </p>
    


</footer>






	


<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?70a761ba668ab8571ac79968adcf6078";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>








	
<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = 'Opps...●﹏●';
            clearTimeout(titleTime);
        } else {
            document.title = 'o(∩_∩)o Welcome!';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>




<script src="https://cdn.bootcss.com/jquery/2.1.4/jquery.min.js"></script>
  <link rel="stylesheet" href="fancybox/jquery.fancybox.css">
  <script src="fancybox/jquery.fancybox.pack.js"></script>

<script src="js/script.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->



</body>
</html>
